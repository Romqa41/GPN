{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6ieNum2CCMzDAMuGERhSI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Romqa41/GPN/blob/main/%D0%9E%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B0_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85_%D1%80%D0%B5%D0%B5%D1%81%D1%82%D1%80_FCA_R4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Блок импорта библиотек"
      ],
      "metadata": {
        "id": "OIyzBxXx5Kw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "kfVeNnTIAC9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Блок функций"
      ],
      "metadata": {
        "id": "btzjtJAk_6f0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция замены латинских букв на кириллические"
      ],
      "metadata": {
        "id": "TN4r78igJTNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_letters(text):\n",
        "  # создаем словарь соответствия латинских букв и кириллицы\n",
        "  mapping = {\n",
        "      'A': 'А',  # пример: латинская A -> кириллическая А\n",
        "      'E': 'Е',\n",
        "      'K': 'К',\n",
        "      'M': 'М',\n",
        "      'O': 'О',\n",
        "      'T': 'Т',\n",
        "      'C': 'С',\n",
        "      'P': 'Р',\n",
        "      'X': 'Х'\n",
        "      }\n",
        "  # заменяем каждую букву из текста, если она есть в словаре\n",
        "  return ''.join(mapping.get(char, char) for char in text)"
      ],
      "metadata": {
        "id": "cDcZPWEjGcku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция для поиска автомобильных номеров"
      ],
      "metadata": {
        "id": "GbA4HToMANe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transport_number(text):\n",
        "  # проверка на наличие данных\n",
        "  if pd.notna(text):\n",
        "    text = str(text)\n",
        "\n",
        "    # корректировка номеров ТС - удаление пробелов, (, ) и /, приведение к верхнему регистру\n",
        "    processed_text = re.sub(r'[\\s\\(\\)\\/\\-\\\\]', '', str(text)).upper()\n",
        "\n",
        "    processed_text = replace_letters(processed_text)\n",
        "\n",
        "    # паттерн для автомобильного номера\n",
        "    pattern = r'[А-ЯA-Z]\\d{3}[А-ЯA-Z]{2}\\d{0,3}'\n",
        "\n",
        "    # ищем совпадение по паттерну, если находим - функция возвращает весь номер\n",
        "    res = re.search(pattern, processed_text)\n",
        "    return res.group() if res else None\n",
        "\n",
        "  # в случае отсутствия искомого паттерна функция ничего не возвращает\n",
        "  return None"
      ],
      "metadata": {
        "id": "5CZ6dRRF7L6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция для поиска транспортных накладных"
      ],
      "metadata": {
        "id": "-PWp5SayARH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transport_invoice(text):\n",
        "  # проверка на наличие данных\n",
        "  if pd.notna(text):\n",
        "    text = str(text)\n",
        "\n",
        "    # удаляем id\n",
        "    text = re.sub(r'\\{\\d{10}\\}', '', text)\n",
        "    # удаляем пробелы внутри текста\n",
        "    text = re.sub(r'\\s+', '', text)\n",
        "    # удаляем {}\n",
        "    text = re.sub(r'[{}]', '', text)\n",
        "    # удаляем слово \"Накладная\", учитываем оба регистра\n",
        "    text = re.sub(r'накладная', '', text, flags=re.I)\n",
        "    # удаляем слово \"ТТН\", учитываем оба регистра\n",
        "    text = re.sub(r'ттн', '', text, flags=re.I)\n",
        "\n",
        "    # возвращаем данные без пробелов в верхнем регистре\n",
        "    if text == '':\n",
        "      return None\n",
        "    if text:\n",
        "      return text.upper()\n",
        "\n",
        "  # если не нашлось данных - возвращаем пустое значение\n",
        "  return None"
      ],
      "metadata": {
        "id": "SvE79c7c-oOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция для поиска номера трекера"
      ],
      "metadata": {
        "id": "Lon4tZYXWwA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tracker_number(text):\n",
        "  # проверка на наличие данных\n",
        "  if pd.notna(text):\n",
        "    text = str(text)\n",
        "\n",
        "    # убираем лишний текст (\" от ДД.ММ.ГГГГ\")\n",
        "    text = re.sub(r'\\s+[Оо][Тт].*$', '', text)\n",
        "    # удаляем id\n",
        "    text = re.sub(r'\\{\\d{10}\\}', '', text)\n",
        "    # удаляем слово \"ТТН\", учитываем оба регистра\n",
        "    text = re.sub(r'ттн', '', text, flags=re.I)\n",
        "    # удаляем тире\n",
        "    text = re.sub('-', '', text)\n",
        "    # удаляем пробелы\n",
        "    text = re.sub(r'\\s+', '', text)\n",
        "    # удаляем {}\n",
        "    text = re.sub(r'[{}]', '', text)\n",
        "\n",
        "    # если текста фактически не осталось - возвращаем пустое значение\n",
        "    if text == '':\n",
        "      return None\n",
        "\n",
        "    # возвращаем очищенный текст в верхнем регистре\n",
        "    return text.upper()\n",
        "\n",
        "  # заглушка\n",
        "  return None"
      ],
      "metadata": {
        "id": "T5zJgRffU79h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция преобразования приложений к договорам"
      ],
      "metadata": {
        "id": "cHm6XGPVAWkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def app_nums_processing(text):\n",
        "#   # проверка на наличие данных\n",
        "#   if pd.isna(text):\n",
        "#     return text\n",
        "\n",
        "#   # удаляем символ номера\n",
        "#   text = text.replace('№', '')\n",
        "\n",
        "#   # разделяем строку по запятым и точкам с запятой, сохраняя разделители\n",
        "#   apps_div = re.split(r'(;|,)', text)\n",
        "\n",
        "#   # обрабатываем каждое приложение - берем только первую часть до пробела\n",
        "#   apps = [(part.split()[0], div) for part, *_, div in zip(*[iter(apps_div)]*2)]\n",
        "\n",
        "#   # добавляем отдельно последний элемент, который остается без пары-разделителя\n",
        "#   if len(apps_div) % 2 == 1 and apps_div[-1]:\n",
        "#     apps.append((apps_div[-1].split()[0], None))\n",
        "\n",
        "#   # собираем результат, расставляя разделители\n",
        "#   res = ''\n",
        "#   for i, (number, div) in enumerate(apps):\n",
        "#     res += number\n",
        "#     if div is not None:\n",
        "#       res += div + ' '\n",
        "\n",
        "#   # заменяем разделители-точки на точки с запятыми\n",
        "#   res = res.replace('.', ';')\n",
        "\n",
        "#   return res"
      ],
      "metadata": {
        "id": "NjfrI1jf_-pH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def app_nums_processing(text):\n",
        "  # проверка на наличие данных\n",
        "  if pd.isna(text):\n",
        "    return text\n",
        "\n",
        "  # удаляем символ номера\n",
        "  text = text.replace('№', '').strip()\n",
        "\n",
        "  # функция ничего не выводит, если аргумент отсутствует\n",
        "  if not text:\n",
        "    return text\n",
        "\n",
        "  # сначала разбиваем на группы по точке с запятой\n",
        "  groups = [group.strip() for group in text.split(';') if group.strip()]\n",
        "\n",
        "  result_groups = []\n",
        "\n",
        "  for group in groups:\n",
        "    # внутри группы разбиваем по запятым\n",
        "    numbers = [num.strip() for num in group.split(',') if num.strip()]\n",
        "\n",
        "    # берем только первую часть до пробела для каждого номера\n",
        "    processed_numbers = []\n",
        "    for num in numbers:\n",
        "      # берем первую часть до пробела, если есть пробел\n",
        "      first_part = num.split()[0] if ' ' in num else num\n",
        "      processed_numbers.append(first_part)\n",
        "\n",
        "    # cобираем группу обратно через запятые\n",
        "    result_groups.append(', '.join(processed_numbers))\n",
        "\n",
        "  # cобираем все группы через точку с запятой\n",
        "  return '; '.join(result_groups)"
      ],
      "metadata": {
        "id": "Iz0DSXyb6UX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция преобразования договоров"
      ],
      "metadata": {
        "id": "e7sm6n-UAcK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def contracts_processing(text):\n",
        "#   # проверка на наличие данных\n",
        "#   if pd.isna(text):\n",
        "#     return text\n",
        "\n",
        "#   # удаляем лишнюю часть договора, представляющую собой номер приложения\n",
        "#   text = re.sub(r'_СП\\d+', '', text)\n",
        "\n",
        "#   # приводим данные к строковому типу и к верхнему регистру\n",
        "#   text = str(text).upper()\n",
        "\n",
        "#   # удаляем символ номера и точки, слеш заменяем на точку с запятой\n",
        "#   text = text.replace('№', '').replace('.', '').replace('\\\\', ';')\n",
        "\n",
        "#   # удаляем буквенную часть договора\n",
        "#   text = text.replace('ДП_', '').replace('Д_', '').replace('_Р', ' ') # ПЕРЕПРОВЕРИТЬ !!!\n",
        "\n",
        "#   # разделяем строку по запятым и точкам с запятой, сохраняя разделители\n",
        "#   conts_div = re.split(r'(;|,)', text)\n",
        "\n",
        "#   # обрабатываем каждое приложение - берем только первую часть до пробела\n",
        "#   conts = [(part.split()[0], div) for part, *_, div in zip(*[iter(conts_div)]*2)]\n",
        "\n",
        "#   # добавляем отдельно последний элемент, который остается без пары-разделителя\n",
        "#   if len(conts_div) % 2 == 1 and conts_div[-1].strip():\n",
        "#     conts.append((conts_div[-1].split()[0], None))\n",
        "\n",
        "#   # собираем результат, расставляя разделители\n",
        "#   res = ''\n",
        "#   for i, (number, div) in enumerate(conts):\n",
        "#     res += number\n",
        "#     if div is not None:\n",
        "#       res += div + ' '\n",
        "\n",
        "#   # дополнительно заменяем точки на точки с запятыми и удаляем слеши\n",
        "#   res = res.replace(',', ';').replace('/', '')\n",
        "\n",
        "#   return res"
      ],
      "metadata": {
        "id": "MzJrMz7u_-bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def contracts_processing(text):\n",
        "  # проверка на наличие данных\n",
        "  if pd.isna(text):\n",
        "    return text\n",
        "\n",
        "  # удаляем лишнюю часть договора, представляющую собой номер приложения\n",
        "  text = re.sub(r'_СП\\d+', '', text)\n",
        "\n",
        "  # приводим данные к строковому типу и к верхнему регистру\n",
        "  text = str(text).upper().strip()\n",
        "\n",
        "  # функция ничего не выводит, если аргумент отсутствует\n",
        "  if not text:\n",
        "    return text\n",
        "\n",
        "  # удаляем символ номера и точки, заменяем все возможные разделители на ;\n",
        "  text = text.replace('№', '').replace('.', '').replace('\\\\', ';').replace(',', ';')\n",
        "\n",
        "  # удаляем буквенную часть договора\n",
        "  text = text.replace('ДП_', '').replace('Д_', '').replace('_Р', ' ')\n",
        "\n",
        "  # заменяем двойные разделители на одинарные\n",
        "  while ';;' in text:\n",
        "    text = text.replace(';;', ';')\n",
        "\n",
        "  # разделяем по точке с запятой\n",
        "  contracts = [contract.strip() for contract in text.split(';') if contract.strip()]\n",
        "\n",
        "  # берем только первую часть до пробела для каждого договора\n",
        "  processed_contracts = []\n",
        "  for contract in contracts:\n",
        "    # берем первую часть до пробела, если есть пробел\n",
        "    first_part = contract.split()[0] if ' ' in contract else contract\n",
        "    # удаляем слеши, если остались\n",
        "    first_part = first_part.replace('/', '')\n",
        "    # проверяем, что строка не пустая\n",
        "    if first_part:\n",
        "      processed_contracts.append(first_part)\n",
        "\n",
        "  # собираем все договоры через точку с запятой\n",
        "  return '; '.join(processed_contracts)"
      ],
      "metadata": {
        "id": "YXPfvAVA7f_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция извлечения кода с учетом приоритетов столбцов"
      ],
      "metadata": {
        "id": "usHSBdNoAh1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_code(text):\n",
        "\n",
        "  # проверка на наличие данных в ячейке столбца - это необходимо для дальнейшего использования в лямбда-функции\n",
        "  if pd.notna(text):\n",
        "    text = str(text)\n",
        "\n",
        "    # поиск кода в тексте - извлекается группа из одной или более цифры подряд из скобок {}\n",
        "    res = re.search(r'\\{(\\d+)\\}', text)\n",
        "    if res:\n",
        "      # в случае нахождения совпадений возвращается первая извлеченная из скобок группа цифр\n",
        "      return res.group(1)\n",
        "\n",
        "    # поиск кода в тексте - извлекается группа из ровно 10 цифр подряд без скобок {}\n",
        "    res = re.search(r'\\b(\\d{10})\\b', text)\n",
        "    if res:\n",
        "      # в случае нахождения совпадений возвращается первая извлеченная из скобок группа цифр\n",
        "      return res.group(1)\n",
        "\n",
        "  # в случае отсутствия искомого паттерна функция ничего не возвращает\n",
        "  return None"
      ],
      "metadata": {
        "id": "IHMsvzkwAf5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция статуса проводки СФ"
      ],
      "metadata": {
        "id": "6SmOKgnUhA0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def colors(row):\n",
        "  if row['Статус документа счета'] == 'Проведено':\n",
        "    res = 'Зеленый'\n",
        "  elif row['Статус документа счета'] == 'Предварительно зарегистрировано' and pd.isna(row['Дата поступл.ТМЦ']) == True:\n",
        "    res = 'Красный'\n",
        "  else:\n",
        "    res = 'Желтый'\n",
        "  return res"
      ],
      "metadata": {
        "id": "DDU0SwTtgau9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция определения категории оприходования СФ"
      ],
      "metadata": {
        "id": "mzdpZ4vZ4mX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reg(df, sap_519, sap_521):\n",
        "\n",
        "  # разбираем полученные списки СФ на отдельные СФ\n",
        "  res = df[['Номер документа (сч.ф)']].explode('Номер документа (сч.ф)')\n",
        "\n",
        "  # удаляем строки без СФ\n",
        "  res = res[res['Номер документа (сч.ф)'].notna()]\n",
        "\n",
        "  # цепляем выгрузку SAP 519\n",
        "  res = res.merge(sap_519[[\n",
        "      'Номер документа (сч.ф)',\n",
        "      'Поставка',\n",
        "      'Статус проводки СФ',\n",
        "      'Документы проверены',\n",
        "      'Дата создания СчФ',\n",
        "      'ТС: Дата отправки',\n",
        "      'Дата ввода',\n",
        "      'Дата проводки',\n",
        "      'Дата поступл.ТМЦ'\n",
        "      ]].drop_duplicates(), how='left', on='Номер документа (сч.ф)')\n",
        "\n",
        "  # цепляем выгрузку SAP 521\n",
        "  res = res.merge(sap_521[['№ приходного ордера']].drop_duplicates(), how='left', left_on='Поставка', right_on='№ приходного ордера')\n",
        "\n",
        "  # прописываем категории для СФ\n",
        "  choices = ['Не оприходовано', 'Виртуальный склад', 'Физический склад']\n",
        "\n",
        "  # прописываем условия для определения СФ в конкретную категорию\n",
        "  conditions = [\n",
        "      (res['Статус проводки СФ'] == 'Красный'),\n",
        "      ~(res['Статус проводки СФ'] == 'Красный') & (res['№ приходного ордера'].notna()),\n",
        "      ~(res['Статус проводки СФ'] == 'Красный') & (res['№ приходного ордера'].isna())\n",
        "  ]\n",
        "\n",
        "  # формируем признак категории для СФ\n",
        "  res['Оприходование СФ'] = np.select(conditions, choices, default='ПРОВЕРИТЬ!!!')\n",
        "\n",
        "  # удаляем дубликаты, которые могут появиться после присоединения выгрузок\n",
        "  res = res.drop_duplicates()\n",
        "\n",
        "  return res"
      ],
      "metadata": {
        "id": "1aib57dj4m9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция подсчета СФ"
      ],
      "metadata": {
        "id": "hJFWI3LctuMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_list(lst):\n",
        "\n",
        "  # обеспечиваем, что lst — список\n",
        "  if not isinstance(lst, list):\n",
        "    lst = [lst]\n",
        "\n",
        "  # по умолчанию ставим метку False на наличие значений и пропусков\n",
        "  has_nan = False\n",
        "  has_values = False\n",
        "\n",
        "  # проверяем наличие и отсутствие пропусков\n",
        "  for item in lst:\n",
        "    if item is None or (isinstance(item, float) and np.isnan(item)):\n",
        "      has_nan = True\n",
        "    elif item is not None:\n",
        "      has_values = True\n",
        "\n",
        "  # найдены и пропуски и значения\n",
        "  if has_nan and has_values:\n",
        "    return 'Сч.ф. найдены частично'\n",
        "  # найдены только пропуски\n",
        "  elif has_nan and not has_values:\n",
        "    return 'Не найдено ни одной сч.ф.'\n",
        "  # найдены только значения\n",
        "  elif not has_nan:\n",
        "    return 'Найдены все сч.ф.'\n",
        "\n",
        "  # заглушка\n",
        "  return 'Найдены все сч.ф.'"
      ],
      "metadata": {
        "id": "w9eb7s1Rtti1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция создания ключей с логикой четности"
      ],
      "metadata": {
        "id": "CC0v0OErAoAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def generate_keys(contracts, applications, another):\n",
        "\n",
        "#   # приводим данные к строчному типу\n",
        "#   contracts = str(contracts)\n",
        "#   applications = str(applications)\n",
        "\n",
        "#   # убираем пробелы\n",
        "#   contracts = contracts.replace(' ', '')\n",
        "#   applications = applications.replace(' ', '')\n",
        "\n",
        "#   # формируем списки\n",
        "#   contracts = contracts.split(',')\n",
        "#   applications = applications.split(',')\n",
        "\n",
        "#   # это третий аргумент для любого столбца, ячейки которого содержат одно значение\n",
        "#   another_value = str(another).strip()\n",
        "\n",
        "#   # сюда будем складывать найденные ключи\n",
        "#   keys = []\n",
        "\n",
        "#   # правило 1: кол-во договоров = кол-во приложений\n",
        "#   if len(contracts) == len(applications):\n",
        "#     keys.extend([f'{c}_{a}_{another_value}' for c, a in zip(contracts, applications)])\n",
        "\n",
        "#   # правило 2: 1 договор и несколько приложений\n",
        "#   elif len(contracts) == 1 and len(applications) > 1:\n",
        "#     keys.extend([f'{contracts[0]}_{a}_{another_value}' for a in applications])\n",
        "\n",
        "#   # правило 3: несколько договоров и 1 приложение\n",
        "#   elif len(contracts) > 1 and len(applications) == 1:\n",
        "#     keys.extend([f'{c}_{applications[0]}_{another_value}' for c in contracts])\n",
        "\n",
        "#   # правило 4: кол-во договоров > 1, кол-во приложений > 1, кол-ва не равны\n",
        "#   elif len(contracts) > 1 and len(applications) > 1:\n",
        "#     # считаем кол-во приложений на договор с округлением вверх\n",
        "#     multiplicity = math.ceil(len(applications) / len(contracts))\n",
        "#     # определяем с помощью индексов каким договорам соответствуют какие приложения\n",
        "#     # начальный индекс - включительно, конечный - не включительно\n",
        "#     for i, contract in enumerate(contracts):\n",
        "#       start_idx = i * multiplicity\n",
        "#       end_idx = start_idx + multiplicity\n",
        "#       # если это последний договор, то для него берем все приложения с start_idx и до конца списка\n",
        "#       # чтобы не потерять приложения, если общее количество не делится ровно\n",
        "#       if i == len(contracts) - 1:\n",
        "#         for app in applications[start_idx:]:\n",
        "#           keys.append(f'{contract}_{app}_{another_value}')\n",
        "#       # для остальных договоров берем срез приложений с start_idx по end_idx\n",
        "#       else:\n",
        "#         for app in applications[start_idx:end_idx]:\n",
        "#           keys.append(f'{contract}_{app}_{another_value}')\n",
        "\n",
        "#   return keys"
      ],
      "metadata": {
        "id": "sipzfCkzAosI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция создания ключей с логикой разделения через \";\""
      ],
      "metadata": {
        "id": "DqT1yCG8-kV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_keys(contracts, applications, another):\n",
        "\n",
        "  # приводим данные к строчному типу\n",
        "  contracts = str(contracts)\n",
        "  applications = str(applications)\n",
        "\n",
        "  # убираем пробелы\n",
        "  contracts = contracts.replace(' ', '')#.replace(';', ',')\n",
        "  applications = applications.replace(' ', '').replace('.', ';')\n",
        "\n",
        "  # формируем списки\n",
        "  contracts = contracts.split(';')\n",
        "  applications = applications.split(';')\n",
        "\n",
        "  # формируем список с группами приложений (каждая группа - список, т.е. получаем список списков)\n",
        "  app_list = [[str(num.strip()) for num in lst.split(',')] for lst in applications]\n",
        "\n",
        "  # это третий аргумент для любого столбца, ячейки которого содержат одно значение\n",
        "  another_value = str(another).strip()\n",
        "\n",
        "  # сюда будем складывать найденные ключи\n",
        "  keys = []\n",
        "\n",
        "  # случай 1: кол-во договоров = кол-во групп приложений\n",
        "  if len(contracts) == len(app_list):\n",
        "    for contract, group_apps in zip(contracts, app_list):\n",
        "      for app in group_apps:\n",
        "        key = f'{contract}_{app}_{another_value}'\n",
        "        keys.append(key)\n",
        "\n",
        "  # случай 2: 1 договор и >= 1 групп приложений\n",
        "  elif len(contracts) == 1 and len(app_list) >= 1:\n",
        "    contract = contracts[0]\n",
        "    apps = sum(app_list, [])\n",
        "    for app in apps:\n",
        "      key = f'{contract}_{app}_{another_value}'\n",
        "      keys.append(key)\n",
        "\n",
        "  # случай 3: > 1 договоров и >= 1 групп приложений, при этом кол-во договоров != кол-во групп приложений\n",
        "  # таких случаев быть не должно, т.к. кол-во договоров должно соответствовать кол-ву групп приложений\n",
        "  # если такой случай выявлен, то запускается первый сценарий - соответствие будет идти по меньшему кол-ву Д или групп П\n",
        "  else:\n",
        "    for contract, group_apps in zip(contracts, app_list):\n",
        "      for app in group_apps:\n",
        "        key = f'{contract}_{app}_{another_value}'\n",
        "        keys.append(key)\n",
        "\n",
        "\n",
        "  return keys"
      ],
      "metadata": {
        "id": "2bt6xzmcnGLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция соединения данных"
      ],
      "metadata": {
        "id": "jISPQtv3RM4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dfs_merge(df_fca_start, df_fca, df_sap):\n",
        "\n",
        "  # шаг 1 - ищем соответствие по id\n",
        "  print('\\033[1mШаг первый:\\033[0m')\n",
        "\n",
        "  # копируем исходные реестры во избежание изменений в них\n",
        "  df_step_one = df_fca.copy()\n",
        "  sap_exp_one = df_sap.copy()\n",
        "\n",
        "  # комбинация ключа Д + П + id, попутно форматирование\n",
        "  df_step_one.loc[:, 'Ключ'] = df_step_one.apply(\n",
        "      lambda row: generate_keys(\n",
        "          contracts_processing(row['Договор']),\n",
        "          app_nums_processing(row['Номер приложения']),\n",
        "          row['Код']\n",
        "          ),\n",
        "      axis=1\n",
        "      )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  df_step_one = df_step_one.explode('Ключ').reset_index(drop=True)\n",
        "\n",
        "  # добавляем номер ключа\n",
        "  df_step_one['Номер ключа'] = df_step_one.groupby('Индекс перевозки').cumcount() + 1\n",
        "\n",
        "  # добавляем возможность фильтрации ключей\n",
        "  df_step_one['Фильтр'] = df_step_one['Индекс перевозки'].astype(str) + '_' + df_step_one['Номер ключа'].astype(str)\n",
        "\n",
        "  # считаем для каждой строки кол-во раз, которое встречается ключ по ней в таблице\n",
        "  df_step_one['Маркер Y'] = df_step_one['Ключ'].map(df_step_one['Ключ'].value_counts())\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  df_step_one = df_step_one[['Индекс перевозки', 'Ключ', 'Номер ключа', 'Фильтр', 'Маркер Y']]\n",
        "  df_step_one = df_step_one.drop_duplicates()\n",
        "\n",
        "  # комбинация ключа Д + П + id, попутно форматирование\n",
        "  sap_exp_one.loc[:, 'Ключ'] = sap_exp_one.apply(\n",
        "      lambda row: [\n",
        "          key for val in [extract_code(row[col]) for col in ['ТС: №ТранспДок', 'ТС: №ТранспСр-ва',\n",
        "                                                             'ТС: №ЕдОбр']]\n",
        "          for key in generate_keys(\n",
        "              contracts_processing(row['ЮрНомер договора на поставку']),\n",
        "              app_nums_processing(row['№ приложения к договору']),\n",
        "              val\n",
        "          )\n",
        "      ],\n",
        "      axis=1\n",
        "  )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  sap_exp_one = sap_exp_one.explode('Ключ')\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  sap_exp_one = sap_exp_one[['Ключ', 'Номер документа (сч.ф)', 'Дата проводки']]\n",
        "  sap_exp_one = sap_exp_one.drop_duplicates()\n",
        "\n",
        "  # соединяем по ключам итоговый на первом шаге датафрейм\n",
        "  df_step_one = df_step_one.merge(sap_exp_one, how='left', on='Ключ')\n",
        "\n",
        "  # сч.ф., которые найти не получилось, будем искать на дальнейших итерациях\n",
        "  df_step_one = df_step_one[~df_step_one['Номер документа (сч.ф)'].isna()]\n",
        "\n",
        "  # удаляем ключи с Nan на конце\n",
        "  df_step_one = df_step_one[~df_step_one['Ключ'].str.lower().str.endswith('none')]\n",
        "\n",
        "  # создаем список отработанных значений-фильтров\n",
        "  # это значит, что такие индексы ключа для каждой строки больше не будут проверяться, т.к. была найдена сч.ф.\n",
        "  filter = list(df_step_one['Фильтр'])\n",
        "\n",
        "  print('Длина полученного датафрейма, ключ - id:', len(df_step_one))\n",
        "\n",
        "  # кол-во задействованных на шаге индексов\n",
        "  first_step_len = df_step_one['Индекс перевозки'].nunique()\n",
        "  # кол-во задействованных накопительным итогом индексов\n",
        "  sum_len = first_step_len\n",
        "\n",
        "  # тип соединения\n",
        "  df_step_one['Тип соединения'] = 'по договору + приложению + id'\n",
        "\n",
        "  # кол-во найденных на первой итерации уникальных сч.ф.\n",
        "  num_one = df_step_one['Номер документа (сч.ф)'].nunique()\n",
        "\n",
        "  print('Кол-во использованных индексов:', first_step_len)\n",
        "  print('Кол-во найденных сч.ф.:', num_one)\n",
        "  print('Кол-во строк, которые осталось найти:', len(fca)-sum_len)\n",
        "  print('Кол-во найденных строк накопительным итогом:', sum_len)\n",
        "  print('% нахождения накопительным итогом:', round(sum_len / len(fca) * 100, 2))\n",
        "  print('\\033[1m----------------------------------------\\033[0m')\n",
        "\n",
        "  # шаг 2 - ищем соответствие по договору + приложению + ТТН\n",
        "  print('\\033[1mШаг второй:\\033[0m')\n",
        "\n",
        "  # копируем исходные реестры во избежание изменений в них\n",
        "  df_step_two = df_fca.copy()\n",
        "  sap_exp_two = df_sap.copy()\n",
        "\n",
        "  # форматируем датафрейм FCA\n",
        "  df_step_two.loc[:, 'Ключ'] = df_step_two.apply(\n",
        "      lambda row: generate_keys(\n",
        "          contracts_processing(row['Договор']),\n",
        "          app_nums_processing(row['Номер приложения']),\n",
        "          transport_invoice(row['№ТН'])\n",
        "          ),\n",
        "      axis=1\n",
        "      )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  df_step_two = df_step_two.explode('Ключ').reset_index(drop=True)\n",
        "\n",
        "  # добавляем номер ключа\n",
        "  df_step_two['Номер ключа'] = df_step_two.groupby('Индекс перевозки').cumcount() + 1\n",
        "\n",
        "  # добавляем возможность фильтрации ключей\n",
        "  df_step_two['Фильтр'] = df_step_two['Индекс перевозки'].astype(str) + '_' + df_step_two['Номер ключа'].astype(str)\n",
        "\n",
        "  # считаем для каждой строки кол-во раз, которое встречается ключ по ней в таблице\n",
        "  df_step_two['Маркер Y'] = df_step_two['Ключ'].map(df_step_two['Ключ'].value_counts())\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  df_step_two = df_step_two[['Индекс перевозки', 'Ключ', 'Номер ключа', 'Фильтр', 'Маркер Y']]\n",
        "  df_step_two = df_step_two.drop_duplicates()\n",
        "\n",
        "  # форматируем копию датафрейма SAP, созданную для второго шага\n",
        "  sap_exp_two.loc[:, 'Ключ'] = sap_exp_two.apply(\n",
        "      lambda row: [\n",
        "          key for val in [transport_invoice(row[col]) for col in ['ТС: №ТранспДок', 'ТС: №ТранспСр-ва']]\n",
        "          for key in generate_keys(\n",
        "              contracts_processing(row['ЮрНомер договора на поставку']),\n",
        "              app_nums_processing(row['№ приложения к договору']),\n",
        "              val\n",
        "          )\n",
        "      ],\n",
        "      axis=1\n",
        "  )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  sap_exp_two = sap_exp_two.explode('Ключ')\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  sap_exp_two = sap_exp_two[['Ключ', 'Номер документа (сч.ф)', 'Дата проводки']]\n",
        "  sap_exp_two = sap_exp_two.drop_duplicates()\n",
        "\n",
        "  # соединяем по ключам итоговый на втором шаге датафрейм\n",
        "  df_step_two = df_step_two.merge(sap_exp_two, how='left', on='Ключ')\n",
        "\n",
        "  # сч.ф., которые найти не получилось, будем искать на дальнейших итерациях\n",
        "  df_step_two = df_step_two[~df_step_two['Номер документа (сч.ф)'].isna()]\n",
        "\n",
        "  # удаляем ключи с Nan на конце\n",
        "  df_step_two = df_step_two[~df_step_two['Ключ'].str.lower().str.endswith('none')]\n",
        "\n",
        "  # выводим индексы с найденными ключами для строки из поиска\n",
        "  df_step_two = df_step_two[~df_step_two['Фильтр'].isin(filter)]\n",
        "\n",
        "  # дополняем список отработанных значений-фильтров\n",
        "  filter += list(df_step_two['Фильтр'])\n",
        "\n",
        "  print('Длина полученного датафрейма, ключ - договор + приложение + ТТН:', len(df_step_two))\n",
        "\n",
        "  # кол-во задействованных на шаге индексов\n",
        "  second_step_len = df_step_two['Индекс перевозки'].nunique()\n",
        "  # кол-во задействованных накопительным итогом индексов\n",
        "  sum_len += second_step_len\n",
        "\n",
        "  # тип соединения\n",
        "  df_step_two['Тип соединения'] = 'по договору + приложению + ТТН'\n",
        "\n",
        "  # кол-во найденных на первой итерации уникальных сч.ф.\n",
        "  num_two = df_step_two['Номер документа (сч.ф)'].nunique()\n",
        "\n",
        "  print('Кол-во использованных индексов:', second_step_len)\n",
        "  print('Кол-во найденных сч.ф.:', num_two)\n",
        "  print('Кол-во строк, которые осталось найти:', len(fca)-sum_len)\n",
        "  print('Кол-во найденных строк накопительным итогом:', sum_len)\n",
        "  print('% нахождения накопительным итогом:', round(sum_len / len(fca) * 100, 2))\n",
        "  print('\\033[1m----------------------------------------\\033[0m')\n",
        "\n",
        "  # шаг 3 - ищем соответствие по договору + приложению + номер трекера\n",
        "  print('\\033[1mШаг третий:\\033[0m')\n",
        "\n",
        "  # копируем исходные реестры во избежание изменений в них\n",
        "  df_step_three = df_fca.copy()\n",
        "  sap_exp_three = df_sap.copy()\n",
        "\n",
        "  # форматируем датафрейм FCA\n",
        "  df_step_three = df_step_three.copy()\n",
        "  df_step_three.loc[:, 'Ключ'] = df_step_three.apply(\n",
        "      lambda row: generate_keys(\n",
        "          contracts_processing(row['Договор']),\n",
        "          app_nums_processing(row['Номер приложения']),\n",
        "          tracker_number(row['Номер трекера'])\n",
        "          ),\n",
        "      axis=1\n",
        "      )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  df_step_three = df_step_three.explode('Ключ').reset_index(drop=True)\n",
        "\n",
        "  # добавляем номер ключа\n",
        "  df_step_three['Номер ключа'] = df_step_three.groupby('Индекс перевозки').cumcount() + 1\n",
        "\n",
        "  # добавляем возможность фильтрации ключей\n",
        "  df_step_three['Фильтр'] = df_step_three['Индекс перевозки'].astype(str) + '_' + df_step_three['Номер ключа'].astype(str)\n",
        "\n",
        "  # считаем для каждой строки кол-во раз, которое встречается ключ по ней в таблице\n",
        "  df_step_three['Маркер Y'] = df_step_three['Ключ'].map(df_step_three['Ключ'].value_counts())\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  df_step_three = df_step_three[['Индекс перевозки', 'Ключ', 'Номер ключа', 'Фильтр', 'Маркер Y']]\n",
        "  df_step_three = df_step_three.drop_duplicates()\n",
        "\n",
        "  # форматируем копию датафрейма SAP, созданную для третьего шага\n",
        "  sap_exp_three.loc[:, 'Ключ'] = sap_exp_three.apply(\n",
        "      lambda row: [\n",
        "          key for val in [tracker_number(row[col]) for col in ['ТС: №ТранспСр-ва', 'ТС: №ТранспДок', 'ТС: №ЕдОбр']]\n",
        "          for key in generate_keys(\n",
        "              contracts_processing(row['ЮрНомер договора на поставку']),\n",
        "              app_nums_processing(row['№ приложения к договору']),\n",
        "              val\n",
        "          )\n",
        "      ],\n",
        "      axis=1\n",
        "  )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  sap_exp_three = sap_exp_three.explode('Ключ')\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  sap_exp_three = sap_exp_three[['Ключ', 'Номер документа (сч.ф)', 'Дата проводки']]\n",
        "  sap_exp_three = sap_exp_three.drop_duplicates()\n",
        "\n",
        "  # соединяем по ключам итоговый на третьем шаге датафрейм\n",
        "  df_step_three = df_step_three.merge(sap_exp_three, how='left', on='Ключ')\n",
        "\n",
        "  # сч.ф., которые найти не получилось, будем искать на дальнейших итерациях\n",
        "  df_step_three = df_step_three[~df_step_three['Номер документа (сч.ф)'].isna()]\n",
        "\n",
        "  # # удаляем ключи с Nan на конце\n",
        "  df_step_three = df_step_three[~df_step_three['Ключ'].str.lower().str.endswith('none')]\n",
        "\n",
        "  # выводим индексы с найденными ключами для строки из поиска\n",
        "  df_step_three = df_step_three[~df_step_three['Фильтр'].isin(filter)]\n",
        "\n",
        "  # дополняем список отработанных значений-фильтров\n",
        "  filter += list(df_step_three['Фильтр'])\n",
        "\n",
        "  print('Длина полученного датафрейма, ключ - договор + приложение + номер трекера:', len(df_step_three))\n",
        "\n",
        "  # кол-во задействованных на шаге индексов\n",
        "  third_step_len = df_step_three['Индекс перевозки'].nunique()\n",
        "  # кол-во задействованных накопительным итогом индексов\n",
        "  sum_len += third_step_len\n",
        "\n",
        "  # тип соединения\n",
        "  df_step_three['Тип соединения'] = 'по договору + приложению + номеру трекера'\n",
        "\n",
        "  # кол-во найденных на первой итерации уникальных сч.ф.\n",
        "  num_three = df_step_three['Номер документа (сч.ф)'].nunique()\n",
        "\n",
        "  print('Кол-во использованных индексов:', third_step_len)\n",
        "  print('Кол-во найденных сч.ф.:', num_three)\n",
        "  print('Кол-во строк, которые осталось найти:', len(fca)-sum_len)\n",
        "  print('Кол-во найденных строк накопительным итогом:', sum_len)\n",
        "  print('% нахождения накопительным итогом:', round(sum_len / len(fca) * 100, 2))\n",
        "  print('\\033[1m----------------------------------------\\033[0m')\n",
        "\n",
        "  # шаг 4 - ищем соответствие по договору + приложению + номер ТС\n",
        "  print('\\033[1mШаг четвертый:\\033[0m')\n",
        "\n",
        "  # копируем исходные реестры во избежание изменений в них\n",
        "  df_step_four = df_fca.copy()\n",
        "  sap_exp_four = df_sap.copy()\n",
        "\n",
        "  # форматируем датафрейм FCA\n",
        "  df_step_four = df_step_four.copy()\n",
        "  df_step_four.loc[:, 'Ключ'] = df_step_four.apply(\n",
        "      lambda row: generate_keys(\n",
        "          contracts_processing(row['Договор']),\n",
        "          app_nums_processing(row['Номер приложения']),\n",
        "          transport_number(row['Номер ТС / накладной'])\n",
        "          ),\n",
        "      axis=1\n",
        "      )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  df_step_four = df_step_four.explode('Ключ').reset_index(drop=True)\n",
        "\n",
        "  # добавляем номер ключа\n",
        "  df_step_four['Номер ключа'] = df_step_four.groupby('Индекс перевозки').cumcount() + 1\n",
        "\n",
        "  # добавляем возможность фильтрации ключей\n",
        "  df_step_four['Фильтр'] = df_step_four['Индекс перевозки'].astype(str) + '_' + df_step_four['Номер ключа'].astype(str)\n",
        "\n",
        "  # считаем для каждой строки кол-во раз, которое встречается ключ по ней в таблице\n",
        "  df_step_four['Маркер Y'] = df_step_four['Ключ'].map(df_step_four['Ключ'].value_counts())\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  df_step_four = df_step_four[['Индекс перевозки', 'Ключ', 'Номер ключа', 'Фильтр', 'Маркер Y']]\n",
        "  df_step_four = df_step_four.drop_duplicates()\n",
        "\n",
        "  # форматируем копию датафрейма SAP, созданную для четвертого шага\n",
        "  sap_exp_four.loc[:, 'Ключ'] = sap_exp_four.apply(\n",
        "      lambda row: [\n",
        "          key for val in [transport_number(row[col]) for col in ['ТС: №ТранспСр-ва', 'ТС: №ТранспДок']]\n",
        "          for key in generate_keys(\n",
        "              contracts_processing(row['ЮрНомер договора на поставку']),\n",
        "              app_nums_processing(row['№ приложения к договору']),\n",
        "              val\n",
        "          )\n",
        "      ],\n",
        "      axis=1\n",
        "      )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  sap_exp_four = sap_exp_four.explode('Ключ')\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  sap_exp_four = sap_exp_four[['Ключ', 'Номер документа (сч.ф)', 'Дата проводки']]\n",
        "  sap_exp_four = sap_exp_four.drop_duplicates()\n",
        "\n",
        "  # соединяем по ключам итоговый на четвертом шаге датафрейм\n",
        "  df_step_four = df_step_four.merge(sap_exp_four, how='left', on='Ключ')\n",
        "\n",
        "  # сч.ф., которые найти не получилось, будем искать на дальнейших итерациях\n",
        "  df_step_four = df_step_four[~df_step_four['Номер документа (сч.ф)'].isna()]\n",
        "\n",
        "  # удаляем ключи с Nan на конце\n",
        "  df_step_four = df_step_four[~df_step_four['Ключ'].str.lower().str.endswith('none')]\n",
        "\n",
        "  # выводим индексы с найденными ключами для строки из поиска\n",
        "  df_step_four = df_step_four[~df_step_four['Фильтр'].isin(filter)]\n",
        "\n",
        "  # дополняем список отработанных значений-фильтров\n",
        "  filter += list(df_step_four['Фильтр'])\n",
        "\n",
        "  print('Длина полученного датафрейма, ключ - договор + приложение + номер ТС:', len(df_step_four))\n",
        "\n",
        "  # кол-во задействованных на шаге индексов\n",
        "  fourth_step_len = df_step_four['Индекс перевозки'].nunique()\n",
        "  # кол-во задействованных накопительным итогом индексов\n",
        "  sum_len += fourth_step_len\n",
        "\n",
        "  # тип соединения\n",
        "  df_step_four['Тип соединения'] = 'по договору + приложению + номеру ТС'\n",
        "\n",
        "  # кол-во найденных на четвертой итерации уникальных сч.ф.\n",
        "  num_four = df_step_four['Номер документа (сч.ф)'].nunique()\n",
        "\n",
        "  print('Кол-во использованных индексов:', fourth_step_len)\n",
        "  print('Кол-во найденных сч.ф.:', num_four)\n",
        "  print('Кол-во строк, которые осталось найти:', len(fca)-sum_len)\n",
        "  print('Кол-во найденных строк накопительным итогом:', sum_len)\n",
        "  print('% нахождения накопительным итогом:', round(sum_len / len(fca) * 100, 2))\n",
        "  print('\\033[1m----------------------------------------\\033[0m')\n",
        "\n",
        "  # шаг 5 - ищем соответствие по договору + приложению + дата отправки ТС\n",
        "  print('\\033[1mШаг пятый:\\033[0m')\n",
        "\n",
        "  # копируем исходные реестры во избежание изменений в них\n",
        "  df_step_five = df_fca.copy()\n",
        "  sap_exp_five = df_sap.copy()\n",
        "\n",
        "  # форматируем датафрейм FCA\n",
        "  df_step_five = df_step_five.copy()\n",
        "  df_step_five.loc[:, 'Ключ'] = df_step_five.apply(\n",
        "      lambda row: generate_keys(\n",
        "          contracts_processing(row['Договор']),\n",
        "          app_nums_processing(row['Номер приложения']),\n",
        "          row['Дата отгрузки ФАКТ']\n",
        "          ),\n",
        "      axis=1\n",
        "      )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  df_step_five = df_step_five.explode('Ключ').reset_index(drop=True)\n",
        "\n",
        "  # добавляем номер ключа\n",
        "  df_step_five['Номер ключа'] = df_step_five.groupby('Индекс перевозки').cumcount() + 1\n",
        "\n",
        "  # добавляем возможность фильтрации ключей\n",
        "  df_step_five['Фильтр'] = df_step_five['Индекс перевозки'].astype(str) + '_' + df_step_five['Номер ключа'].astype(str)\n",
        "\n",
        "  # считаем для каждой строки кол-во раз, которое встречается ключ по ней в таблице\n",
        "  df_step_five['Маркер Y'] = df_step_five['Ключ'].map(df_step_five['Ключ'].value_counts())\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  df_step_five = df_step_five[['Индекс перевозки', 'Ключ', 'Номер ключа', 'Фильтр', 'Маркер Y']]\n",
        "  df_step_five = df_step_five.drop_duplicates()\n",
        "\n",
        "  # форматируем копию датафрейма SAP, созданную для пятого шага\n",
        "  sap_exp_five.loc[:, 'Ключ'] = sap_exp_five.apply(\n",
        "      lambda row: generate_keys(\n",
        "          contracts_processing(row['ЮрНомер договора на поставку']),\n",
        "          app_nums_processing(row['№ приложения к договору']),\n",
        "          row['ТС: Дата отправки']\n",
        "          ),\n",
        "      axis=1\n",
        "      )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  sap_exp_five = sap_exp_five.explode('Ключ')\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  sap_exp_five = sap_exp_five[['Ключ', 'Номер документа (сч.ф)', 'Дата проводки']]\n",
        "  sap_exp_five = sap_exp_five.drop_duplicates()\n",
        "\n",
        "  # соединяем по ключам итоговый на пятом шаге датафрейм\n",
        "  df_step_five = df_step_five.merge(sap_exp_five, how='left', on='Ключ')\n",
        "\n",
        "  # сч.ф., которые найти не получилось, будем искать на дальнейших итерациях\n",
        "  df_step_five = df_step_five[~df_step_five['Номер документа (сч.ф)'].isna()]\n",
        "\n",
        "  # удаляем ключи с Nan на конце\n",
        "  df_step_five = df_step_five[~df_step_five['Ключ'].str.lower().str.endswith('none')]\n",
        "\n",
        "  # выводим индексы с найденными ключами для строки из поиска\n",
        "  df_step_five = df_step_five[~df_step_five['Фильтр'].isin(filter)]\n",
        "\n",
        "  # дополняем список отработанных значений-фильтров\n",
        "  filter += list(df_step_five['Фильтр'])\n",
        "\n",
        "  print('Длина полученного датафрейма, ключ - договор + приложение + дата отправки ТС:', len(df_step_five))\n",
        "\n",
        "  # кол-во задействованных на шаге индексов\n",
        "  fifth_step_len = df_step_five.loc[df_step_five['Номер документа (сч.ф)'].notna(), 'Индекс перевозки'].nunique()\n",
        "  # кол-во задействованных накопительным итогом индексов\n",
        "  sum_len += fifth_step_len\n",
        "\n",
        "  # тип соединения\n",
        "  df_step_five['Тип соединения'] = 'по договору + приложению + дате отправки ТС'\n",
        "\n",
        "  # кол-во найденных на пятой итерации уникальных сч.ф.\n",
        "  num_five = df_step_five['Номер документа (сч.ф)'].nunique()\n",
        "\n",
        "  print('Кол-во использованных индексов:', fifth_step_len)\n",
        "  print('Кол-во найденных сч.ф.:', num_five)\n",
        "  print('Кол-во строк, которые осталось найти:', len(fca)-sum_len)\n",
        "  print('Кол-во найденных строк накопительным итогом:', sum_len)\n",
        "  print('% нахождения накопительным итогом:', round(sum_len / len(fca) * 100, 2))\n",
        "  print('\\033[1m----------------------------------------\\033[0m')\n",
        "\n",
        "\n",
        "\n",
        "  # шаг 6 - ищем соответствие по договору + приложению + стоимости материала\n",
        "  print('\\033[1mШаг шестой:\\033[0m')\n",
        "\n",
        "  # копируем исходные реестры во избежание изменений в них\n",
        "  df_step_six = df_fca.copy()\n",
        "  sap_exp_six = df_sap.copy()\n",
        "\n",
        "  # форматируем датафрейм FCA\n",
        "  df_step_six = df_step_six.copy()\n",
        "  df_step_six.loc[:, 'Ключ'] = df_step_six.apply(\n",
        "      lambda row: generate_keys(\n",
        "          contracts_processing(row['Договор']),\n",
        "          app_nums_processing(row['Номер приложения']),\n",
        "          str(round(row['Стоимость материала, без НДС'] * 1.2, 2))\n",
        "          ),\n",
        "      axis=1\n",
        "      )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  df_step_six = df_step_six.explode('Ключ').reset_index(drop=True)\n",
        "\n",
        "  # добавляем номер ключа\n",
        "  df_step_six['Номер ключа'] = df_step_six.groupby('Индекс перевозки').cumcount() + 1\n",
        "\n",
        "  # добавляем возможность фильтрации ключей\n",
        "  df_step_six['Фильтр'] = df_step_six['Индекс перевозки'].astype(str) + '_' + df_step_six['Номер ключа'].astype(str)\n",
        "\n",
        "  # считаем для каждой строки кол-во раз, которое встречается ключ по ней в таблице\n",
        "  df_step_six['Маркер Y'] = df_step_six['Ключ'].map(df_step_six['Ключ'].value_counts())\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  df_step_six = df_step_six[['Индекс перевозки', 'Ключ', 'Номер ключа', 'Фильтр', 'Маркер Y']]\n",
        "  df_step_six = df_step_six.drop_duplicates()\n",
        "\n",
        "  # форматируем копию датафрейма SAP, созданную для шестого шага\n",
        "  sap_exp_six.loc[:, 'Ключ'] = sap_exp_six.apply(\n",
        "      lambda row: generate_keys(\n",
        "          contracts_processing(row['ЮрНомер договора на поставку']),\n",
        "          app_nums_processing(row['№ приложения к договору']),\n",
        "          str(round(row['Сумма брутто'], 2))\n",
        "          ),\n",
        "      axis=1\n",
        "      )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  sap_exp_six = sap_exp_six.explode('Ключ')\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  sap_exp_six = sap_exp_six[['Ключ', 'Номер документа (сч.ф)', 'Дата проводки']]\n",
        "  sap_exp_six = sap_exp_six.drop_duplicates()\n",
        "\n",
        "  # соединяем по ключам итоговый на шестом шаге датафрейм\n",
        "  df_step_six = df_step_six.merge(sap_exp_six, how='left', on='Ключ')\n",
        "\n",
        "  # удаляем ключи с Nan на конце\n",
        "  df_step_six = df_step_six[~df_step_six['Ключ'].str.lower().str.endswith('none')]\n",
        "\n",
        "  # выводим индексы с найденными ключами для строки из поиска\n",
        "  df_step_six = df_step_six[~df_step_six['Фильтр'].isin(filter)]\n",
        "\n",
        "  # дополняем список отработанных значений-фильтров\n",
        "  filter += list(df_step_six['Фильтр'])\n",
        "\n",
        "  print('Длина полученного датафрейма, ключ - договор + приложение + стоимость материала:', len(df_step_six))\n",
        "\n",
        "  # кол-во задействованных на шаге индексов\n",
        "  sixth_step_len = df_step_six.loc[df_step_six['Номер документа (сч.ф)'].notna(), 'Индекс перевозки'].nunique()\n",
        "  # кол-во задействованных накопительным итогом индексов\n",
        "  sum_len += sixth_step_len\n",
        "\n",
        "  # тип соединения\n",
        "  df_step_six['Тип соединения'] = 'по договору + приложению + стоимости материала'\n",
        "\n",
        "  # кол-во найденных на шестой итерации уникальных сч.ф.\n",
        "  num_six = df_step_six['Номер документа (сч.ф)'].nunique()\n",
        "\n",
        "  print('Кол-во использованных индексов:', sixth_step_len)\n",
        "  print('Кол-во найденных сч.ф.:', num_six)\n",
        "  print('Кол-во строк, которые осталось найти:', len(fca)-sum_len)\n",
        "  print('Кол-во найденных строк накопительным итогом:', sum_len)\n",
        "  print('% нахождения накопительным итогом:', round(sum_len / len(fca) * 100, 2))\n",
        "  print('\\033[1m----------------------------------------\\033[0m')\n",
        "\n",
        "  print('\\033[1mИТОГО:\\033[0m')\n",
        "\n",
        "  # соединяем найденные на предыдущих шагах датафреймы\n",
        "  res = pd.concat([df_step_one, df_step_two, df_step_three, df_step_four, df_step_five, df_step_six], axis=0, ignore_index=True)\n",
        "\n",
        "  # сортируем по индексам строк и индексам ключей в строках для корректного порядке при нахождении сч.ф.\n",
        "  res = res.sort_values(by=['Индекс перевозки', 'Номер ключа'])\n",
        "\n",
        "  # смотрим по каким ключам сколько соединилось строк\n",
        "  print(\n",
        "      res.groupby('Тип соединения')['Номер документа (сч.ф)']\n",
        "       .size()\n",
        "       .reset_index(name='Кол-во строк')\n",
        "       .sort_values(by='Кол-во строк', ascending=False)\n",
        "       .reset_index(drop=True)\n",
        "       )\n",
        "\n",
        "\n",
        "  # создаем таблицу с индексами и сч.ф., которую будем цеплять к исходному реестру FCA, попутно меняет float на int\n",
        "  res = res.groupby(['Индекс перевозки', 'Маркер Y'], sort=False).agg({\n",
        "    'Номер документа (сч.ф)': lambda x: [int(val) if pd.notna(val) else val for val in x],\n",
        "    'Дата проводки': 'max'\n",
        "    }).reset_index()\n",
        "\n",
        "  # окончательно схлопываем строки (из наличия маркера Y некоторые строки задублировались)\n",
        "  res = res.groupby('Индекс перевозки').agg({\n",
        "    'Маркер Y': 'sum',  # сумма по повтору\n",
        "    'Номер документа (сч.ф)': 'sum',  # объединение списков\n",
        "    'Дата проводки': 'max' # дата самой поздней СФ для расчета месяца оприходования поставки\n",
        "    }).reset_index()\n",
        "\n",
        "  # переименовываем столбец последней проводки\n",
        "  res = res.rename(columns={'Дата проводки': 'Дата последней проводки'})\n",
        "\n",
        "  # цепляем к реестру FCA найденные сч.ф.\n",
        "  result = df_fca_start.merge(res, how='left', on='Индекс перевозки')\n",
        "\n",
        "  print('\\033[1m----------------------------------------\\033[0m')\n",
        "\n",
        "  # общее кол-во найденных сч.ф.\n",
        "  invoices = res.explode('Номер документа (сч.ф)')\n",
        "  n = invoices['Номер документа (сч.ф)'].nunique()\n",
        "  print(f'\\033[1mОбщее кол-во найденных сч.ф.:\\033[0m {n}')\n",
        "  print(f'\\033[1m% найденных строк\\033[0m {round(sum_len / len(fca) * 100, 2)}')\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "qs9fAkraRLyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка и предобработка данных"
      ],
      "metadata": {
        "id": "FfquPgt__ufo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка данных"
      ],
      "metadata": {
        "id": "XpxLWai147-9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYTIdF-W_jbe",
        "outputId": "06921ad9-4ef4-4c5f-b438-553f554e11f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Длина FCA: 1690\n",
            "Длина SAP 519: 3671\n"
          ]
        }
      ],
      "source": [
        "# загрузка данных\n",
        "fca = pd.read_excel('Ноябрь 2025.xlsx', usecols=[\n",
        "    'Код',\n",
        "    'Дата отгрузки ФАКТ',\n",
        "    'Номер приложения',\n",
        "    'Договор',\n",
        "    'Номер ТС / накладной',\n",
        "    'Номер трекера',\n",
        "    'Ставка перевозчика с НДС, руб',\n",
        "    '№ТН',\n",
        "    'Стоимость материала, без НДС',\n",
        "    ])\n",
        "\n",
        "sap_519 = pd.read_excel('519 мес.XLSX', usecols = [\n",
        "    'ЮрНомер договора на поставку',\n",
        "    '№ приложения к договору',\n",
        "    'Номер документа (сч.ф)',\n",
        "    'ТС: №ТранспСр-ва',\n",
        "    'ТС: №ТранспДок',\n",
        "    'ТС: Дата отправки',\n",
        "    'ТС: №ЕдОбр',\n",
        "    'Поставка',\n",
        "    'Статус документа счета',\n",
        "    'Дата поступл.ТМЦ',\n",
        "    'Документы проверены',\n",
        "    'Дата создания СчФ',\n",
        "    'Дата ввода',\n",
        "    'Дата проводки',\n",
        "    'Сумма брутто'\n",
        "    ])\n",
        "\n",
        "# sap_519_ed = pd.read_excel('519 ЭД мес.XLSX', usecols=[\n",
        "#     'ЮрНомер договора на поставку',\n",
        "#     '№ приложения к договору',\n",
        "#     'Номер документа (сч.ф)',\n",
        "#     'ТС: №ТранспСр-ва',\n",
        "#     'ТС: №ТранспДок',\n",
        "#     'ТС: Дата отправки',\n",
        "#     'ТС: №ЕдОбр',\n",
        "#     'Счет-фактура',\n",
        "#     'Поставка',\n",
        "#     'Статус документа счета',\n",
        "#     'Дата поступл.ТМЦ',\n",
        "#     'Документы проверены',\n",
        "#     'Дата создания СчФ',\n",
        "#     'Дата ввода',\n",
        "#     'Дата проводки',\n",
        "#     'Сумма брутто'\n",
        "# ])\n",
        "\n",
        "sap_521 = pd.read_excel('521 мес.XLSX')\n",
        "\n",
        "logs = pd.read_excel('логи ноябрь.XLSX')\n",
        "\n",
        "print('Длина FCA:', len(fca))\n",
        "print('Длина SAP 519:', len(sap_519))\n",
        "# print('Длина SAP 519 ЭД:', len(sap_519_ed))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выбор периода для расчета"
      ],
      "metadata": {
        "id": "WqFXzxzoe5sP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# строго\n",
        "period = input('Выберите период формирования файлов (введите МЕСЯЦ или ГОД): ').strip().lower()\n",
        "\n",
        "# контроль\n",
        "if period == 'год':\n",
        "  print('Выбранный период - ГОД')\n",
        "elif period == 'месяц':\n",
        "  print('ВЫбранный период - Месяц')\n",
        "else:\n",
        "  raise ValueError(f'❌ Неизвестный период: {period}. Допустимые значения: МЕСЯЦ, ГОД')"
      ],
      "metadata": {
        "id": "nWKJDNNeYtRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a16b78cd-5dc2-4c43-f03a-07c4d2deba53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Выберите период формирования файлов (введите МЕСЯЦ или ГОД): месяц\n",
            "ВЫбранный период - Месяц\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# выбор месяца (при необходимости)\n",
        "if period == 'месяц':\n",
        "  month = input('Выберите МЕСЯЦ: ').strip().lower()\n",
        "\n",
        "  if month == 'январь':\n",
        "    mm = '02'\n",
        "  elif month == 'февраль':\n",
        "    mm = '03'\n",
        "  elif month == 'март':\n",
        "    mm = '04'\n",
        "  elif month == 'апрель':\n",
        "    mm = '05'\n",
        "  elif month == 'май':\n",
        "    mm = '06'\n",
        "  elif month == 'июнь':\n",
        "    mm = '07'\n",
        "  elif month == 'июль':\n",
        "    mm = '08'\n",
        "  elif month == 'август':\n",
        "    mm = '09'\n",
        "  elif month == 'сентябрь':\n",
        "    mm = '10'\n",
        "  elif month == 'октябрь':\n",
        "    mm = '11'\n",
        "  elif month == 'ноябрь':\n",
        "    mm = '12'\n",
        "  elif month == 'декабрь':\n",
        "    mm = '01'\n",
        "  else:\n",
        "    raise ValueError(f'❌ Ошибка при выборе месяца: {month}. Необходимо полностью и корректно ввести месяц')\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "eLWjExb0fT4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b773399-6e64-449a-d9f9-c2135e801fd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Выберите МЕСЯЦ: ноябрь\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'месяц':\n",
        "\n",
        "  # исключаем данные за следующий месяц\n",
        "  fca = fca[~(fca['Код'].str[2:4] == mm)]\n",
        "  print('Длина после перепроверки FCA:', len(fca))\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "-Lfo-Q4Vg49Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87c1f958-e3ef-47ca-b601-fe7c8b25af13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Длина после перепроверки FCA: 1690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# добавляем индекс каждой строке реестра FCA\n",
        "fca.insert(0, 'Индекс перевозки', np.arange(0, len(fca)))"
      ],
      "metadata": {
        "id": "35qoERFy9ZPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# поля, которые блок FCA должен заполнить данными\n",
        "cols_revision = [\n",
        "    'Код',\n",
        "    'Договор',\n",
        "    'Номер приложения',\n",
        "    'Дата отгрузки ФАКТ',\n",
        "    'Ставка перевозчика с НДС, руб'\n",
        "    ]\n",
        "\n",
        "# таблица, которая будет направлена блоку FCA на дозаполнение\n",
        "fca_revision = fca[fca[cols_revision].isnull().any(axis=1)]"
      ],
      "metadata": {
        "id": "FekeWxie6X9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преобразование реестра FCA"
      ],
      "metadata": {
        "id": "SzMJFYZEX3nH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# избавляемся от лишних скобок в поле id, ограничиваем длину id 10 символами\n",
        "fca['Код'] = fca['Код'].str.replace(r'[{}]', '', regex=True).str[:10]\n",
        "\n",
        "# приводим данные по стоимостям в текстовый тип данных (техническое решение, чтобы привести цифры в единый вид)\n",
        "fca['Стоимость материала, без НДС'] = fca['Стоимость материала, без НДС'].astype(str)\n",
        "fca['Ставка перевозчика с НДС, руб'] = fca['Ставка перевозчика с НДС, руб'].astype(str)\n",
        "\n",
        "# избавляемся от лишних пробелов и приводим цифры в единый вид\n",
        "fca['Стоимость материала, без НДС'] = fca['Стоимость материала, без НДС'].str.replace(',', '.').str.replace(r'\\s+', '', regex=True).str.replace(r'[^\\d.]+', '', regex=True)\n",
        "fca['Ставка перевозчика с НДС, руб'] = fca['Ставка перевозчика с НДС, руб'].str.replace(',', '.').str.replace(r'\\s+', '', regex=True).str.replace(r'[^\\d.]+', '', regex=True)\n",
        "\n",
        "# меняем тип данных на числовой\n",
        "fca['Стоимость материала, без НДС'] = pd.to_numeric(fca['Стоимость материала, без НДС'], errors='coerce')\n",
        "fca['Ставка перевозчика с НДС, руб'] = pd.to_numeric(fca['Ставка перевозчика с НДС, руб'], errors='coerce')\n",
        "\n",
        "# подстраховка\n",
        "fca['Стоимость материала, без НДС'] = fca['Стоимость материала, без НДС'].astype(float)\n",
        "fca['Ставка перевозчика с НДС, руб'] = fca['Ставка перевозчика с НДС, руб'].astype(float)"
      ],
      "metadata": {
        "id": "zWqjsQ5lX7bF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преобразование выгрузки SAP 519"
      ],
      "metadata": {
        "id": "5LqfUpcqHEjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # корректировка сч.ф. в выгрузке SAP 519 ЭД\n",
        "# mask = sap_519_ed['Номер документа (сч.ф)'] == 1\n",
        "# sap_519_ed.loc[mask, 'Номер документа (сч.ф)'] = sap_519_ed.loc[mask, 'Счет-фактура']\n",
        "\n",
        "# # данный столбец более не нужен, удаляем его\n",
        "# sap_519_ed = sap_519_ed.drop('Счет-фактура', axis=1)\n",
        "\n",
        "# приводим в единый вид выгрузки SAP 519 и SAP 519 ЭД, должен соблюдаться порядок столбцов\n",
        "sap_519 = sap_519[[\n",
        "    'ЮрНомер договора на поставку',\n",
        "    '№ приложения к договору',\n",
        "    'ТС: Дата отправки',\n",
        "    'Номер документа (сч.ф)',\n",
        "    'ТС: №ЕдОбр',\n",
        "    'ТС: №ТранспДок',\n",
        "    'ТС: №ТранспСр-ва',\n",
        "    'Поставка',\n",
        "    'Статус документа счета',\n",
        "    'Дата поступл.ТМЦ',\n",
        "    'Документы проверены',\n",
        "    'Дата создания СчФ',\n",
        "    'Дата ввода',\n",
        "    'Дата проводки',\n",
        "    'Сумма брутто'\n",
        "    ]]\n",
        "\n",
        "# sap_519_ed = sap_519_ed[[\n",
        "#     'ЮрНомер договора на поставку',\n",
        "#     '№ приложения к договору',\n",
        "#     'ТС: Дата отправки',\n",
        "#     'Номер документа (сч.ф)',\n",
        "#     'ТС: №ЕдОбр',\n",
        "#     'ТС: №ТранспДок',\n",
        "#     'ТС: №ТранспСр-ва',\n",
        "#     'Поставка',\n",
        "#     'Статус документа счета',\n",
        "#     'Дата поступл.ТМЦ',\n",
        "#     'Документы проверены',\n",
        "#     'Дата создания СчФ',\n",
        "#     'Дата ввода',\n",
        "#     'Дата проводки',\n",
        "#     'Сумма брутто'\n",
        "#     ]]\n",
        "\n",
        "# соединяем реестры SAP по вертикали\n",
        "sap_519_full = pd.concat([\n",
        "    sap_519,\n",
        "    # sap_519_ed\n",
        "    ], axis=0, ignore_index=True)\n",
        "\n",
        "# избавляемся от всех строк SAP 519, где нет СФ\n",
        "sap_519_full = sap_519_full[sap_519_full['Номер документа (сч.ф)'].notna()]\n",
        "\n",
        "# добавляем статус проводки\n",
        "sap_519_full['Статус проводки СФ'] = sap_519_full.apply(colors, axis=1)\n",
        "\n",
        "# приводим столбец статуса документов в единый регистр\n",
        "sap_519_full['Документы проверены'] = sap_519_full['Документы проверены'].str.lower()\n",
        "\n",
        "# меняем тип данных на текстовый\n",
        "# это дополнительная мера, т.к. тип данных в любом случае меняется внутри функций\n",
        "cols_fca_str = ['Номер ТС / накладной', 'Номер приложения', 'Номер трекера', '№ТН']\n",
        "for col in cols_fca_str:\n",
        "  fca[col] = fca[col].where(fca[col].isna(), fca[col].astype('str'))\n",
        "\n",
        "cols_sap_str = [\n",
        "    'ТС: №ТранспСр-ва',\n",
        "    'ТС: №ТранспДок',\n",
        "    'ТС: №ЕдОбр',\n",
        "    'ЮрНомер договора на поставку',\n",
        "    '№ приложения к договору',\n",
        "    ]\n",
        "for col in cols_sap_str:\n",
        "  sap_519_full[col] = sap_519_full[col].where(sap_519_full[col].isna(), sap_519_full[col].astype('str'))\n",
        "\n",
        "# на всякий случай присваиваем СФ тип данных int\n",
        "sap_519_full['Номер документа (сч.ф)'] = sap_519_full['Номер документа (сч.ф)'].astype(int)\n",
        "\n",
        "# будущий ключ SAP 519 приводим к целочисленному типу данных\n",
        "sap_519_full['Поставка'] = pd.to_numeric(sap_519_full['Поставка'], errors='coerce')\n",
        "sap_519_full['Поставка'] = sap_519_full['Поставка'].astype('Int64')\n",
        "\n",
        "# преобразуем поля из текствого формата в списки\n",
        "col_list = ['ТС: №ТранспСр-ва', 'ТС: №ТранспДок', 'ТС: №ЕдОбр']\n",
        "sap_519_full[col_list] = sap_519_full[col_list].applymap(\n",
        "    lambda x: [item.strip() for item in x.split(',')] if pd.notna(x) else []\n",
        ")\n",
        "\n",
        "# растаскиваем по строкам\n",
        "sap_519_exp = sap_519_full.explode('ТС: №ТранспСр-ва').explode('ТС: №ТранспДок').explode('ТС: №ЕдОбр')\n",
        "\n",
        "# приводим данные по стоимостям в текстовый тип данных (техническое решение, чтобы привести цифры в единый вид)\n",
        "sap_519_exp['Сумма брутто'] = sap_519_exp['Сумма брутто'].astype(str)\n",
        "\n",
        "# избавляемся от лишних пробелов и приводим цифры в единый вид\n",
        "sap_519_exp['Сумма брутто'] = sap_519_exp['Сумма брутто'].str.replace(',', '.').str.replace(r'\\s+', '', regex=True).str.replace(r'[^\\d.]+', '', regex=True)\n",
        "\n",
        "# меняем тип данных на числовой\n",
        "sap_519_exp['Сумма брутто'] = pd.to_numeric(sap_519_exp['Сумма брутто'], errors='coerce')\n",
        "\n",
        "# подстраховка\n",
        "sap_519_exp['Сумма брутто'] = sap_519_exp['Сумма брутто'].astype(float)\n",
        "\n",
        "# чистим столбцы\n",
        "for col in col_list:\n",
        "    mask = sap_519_exp[col].str.lower() == 'нет данных'\n",
        "    sap_519_exp.loc[mask, col] = None"
      ],
      "metadata": {
        "id": "UlYFiM9S_453",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d85bb7ef-471a-420f-f396-6578bb0fa2f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1750475490.py:85: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  sap_519_full[col_list] = sap_519_full[col_list].applymap(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преобразование выгрузки SAP 521"
      ],
      "metadata": {
        "id": "gR0qgRo7HJ4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# избавляемся от строк без необходимого в дальнейшем ключа\n",
        "sap_521 = sap_521[sap_521['№ приходного ордера'].notna()]\n",
        "\n",
        "# будущий ключ SAP 521 приводим к типу данных float\n",
        "sap_521['№ приходного ордера'] = pd.to_numeric(sap_521['№ приходного ордера'], errors='coerce')\n",
        "\n",
        "# Прямое преобразование в int (без промежуточного float)\n",
        "sap_521['№ приходного ордера'] = sap_521['№ приходного ордера'].astype('Int64')"
      ],
      "metadata": {
        "id": "LWkAh-8MHNna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преобразование логов"
      ],
      "metadata": {
        "id": "c_4iLRkvuwUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# во избежание присоединения лишних строк из логов выделяем самые поздние для каждой СФ\n",
        "logs = logs.rename(columns={'№ докум.':'BELNR', 'ДатаИзм':'CHDAT'})\n",
        "logs = logs.groupby('BELNR')['CHDAT'].max().reset_index()"
      ],
      "metadata": {
        "id": "mnEHCsDquuZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# исключаем часть реестра FCA, отправленную на доработку\n",
        "fca_clean = fca[~fca['Индекс перевозки'].isin(fca_revision['Индекс перевозки'])]"
      ],
      "metadata": {
        "id": "hqTXAIFp-x3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# соединяем реестры\n",
        "df_res = dfs_merge(fca, fca_clean, sap_519_exp)"
      ],
      "metadata": {
        "id": "28lMBpI6nlF8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fa84449-f242-441c-8591-037904154f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mШаг первый:\u001b[0m\n",
            "Длина полученного датафрейма, ключ - id: 617\n",
            "Кол-во использованных индексов: 504\n",
            "Кол-во найденных сч.ф.: 615\n",
            "Кол-во строк, которые осталось найти: 1186\n",
            "Кол-во найденных строк накопительным итогом: 504\n",
            "% нахождения накопительным итогом: 29.82\n",
            "\u001b[1m----------------------------------------\u001b[0m\n",
            "\u001b[1mШаг второй:\u001b[0m\n",
            "Длина полученного датафрейма, ключ - договор + приложение + ТТН: 16\n",
            "Кол-во использованных индексов: 9\n",
            "Кол-во найденных сч.ф.: 16\n",
            "Кол-во строк, которые осталось найти: 1177\n",
            "Кол-во найденных строк накопительным итогом: 513\n",
            "% нахождения накопительным итогом: 30.36\n",
            "\u001b[1m----------------------------------------\u001b[0m\n",
            "\u001b[1mШаг третий:\u001b[0m\n",
            "Длина полученного датафрейма, ключ - договор + приложение + номер трекера: 32\n",
            "Кол-во использованных индексов: 23\n",
            "Кол-во найденных сч.ф.: 32\n",
            "Кол-во строк, которые осталось найти: 1154\n",
            "Кол-во найденных строк накопительным итогом: 536\n",
            "% нахождения накопительным итогом: 31.72\n",
            "\u001b[1m----------------------------------------\u001b[0m\n",
            "\u001b[1mШаг четвертый:\u001b[0m\n",
            "Длина полученного датафрейма, ключ - договор + приложение + номер ТС: 270\n",
            "Кол-во использованных индексов: 202\n",
            "Кол-во найденных сч.ф.: 254\n",
            "Кол-во строк, которые осталось найти: 952\n",
            "Кол-во найденных строк накопительным итогом: 738\n",
            "% нахождения накопительным итогом: 43.67\n",
            "\u001b[1m----------------------------------------\u001b[0m\n",
            "\u001b[1mШаг пятый:\u001b[0m\n",
            "Длина полученного датафрейма, ключ - договор + приложение + дата отправки ТС: 763\n",
            "Кол-во использованных индексов: 536\n",
            "Кол-во найденных сч.ф.: 643\n",
            "Кол-во строк, которые осталось найти: 416\n",
            "Кол-во найденных строк накопительным итогом: 1274\n",
            "% нахождения накопительным итогом: 75.38\n",
            "\u001b[1m----------------------------------------\u001b[0m\n",
            "\u001b[1mШаг шестой:\u001b[0m\n",
            "Длина полученного датафрейма, ключ - договор + приложение + стоимость материала: 510\n",
            "Кол-во использованных индексов: 47\n",
            "Кол-во найденных сч.ф.: 51\n",
            "Кол-во строк, которые осталось найти: 369\n",
            "Кол-во найденных строк накопительным итогом: 1321\n",
            "% нахождения накопительным итогом: 78.17\n",
            "\u001b[1m----------------------------------------\u001b[0m\n",
            "\u001b[1mИТОГО:\u001b[0m\n",
            "                                   Тип соединения  Кол-во строк\n",
            "0     по договору + приложению + дате отправки ТС           763\n",
            "1                   по договору + приложению + id           617\n",
            "2  по договору + приложению + стоимости материала           510\n",
            "3            по договору + приложению + номеру ТС           270\n",
            "4       по договору + приложению + номеру трекера            32\n",
            "5                  по договору + приложению + ТТН            16\n",
            "\u001b[1m----------------------------------------\u001b[0m\n",
            "\u001b[1mОбщее кол-во найденных сч.ф.:\u001b[0m 1577\n",
            "\u001b[1m% найденных строк\u001b[0m 78.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Преобразование полученных данных"
      ],
      "metadata": {
        "id": "v_yawGLwhbFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# маркер Y\n",
        "\n",
        "# это метка для случая, когда M одинаковых ключей и N сч.ф.\n",
        "# т.е. проблема, что нельзя установить точное соответствие между сч.ф. и ключом\n",
        "# в идеале такое должно быть только на итерациях 4 и 5 - по номеру ТС и дате отправки\n",
        "df_res['Маркер Y'] = np.where((df_res['Маркер Y'] == 1) | (df_res['Маркер Y'].isna()), 'N', 'Y')"
      ],
      "metadata": {
        "id": "7QIjcjGjhsHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# маркер X\n",
        "\n",
        "# это проверка того, найдены ли все сч.ф. или нет\n",
        "df_res['Маркер X'] = df_res['Номер документа (сч.ф)'].apply(analyze_list)\n",
        "\n",
        "# корректируем маркер Y - не будем помечать им строки без сч.ф.\n",
        "df_res.loc[df_res['Маркер X'] == 'Не найдено ни одной сч.ф.', 'Маркер Y'] = 'N'"
      ],
      "metadata": {
        "id": "p8NHDOE8p0WW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# найденные в FCA перевозки\n",
        "df_res['Зарегистрировано'] = np.where(df_res['Маркер X'] == 'Не найдено ни одной сч.ф.', 0, 1)\n",
        "\n",
        "# не найденные в FCA перевозки\n",
        "df_res['Не зарег. / Не найд.'] = np.where(df_res['Маркер X'] == 'Не найдено ни одной сч.ф.', 1, 0)"
      ],
      "metadata": {
        "id": "9ZM_DXSEXHd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# соединяем найденные СФ с выгрузками SAP 519 и SAP 521\n",
        "inv_reg = reg(df_res, sap_519_full, sap_521)"
      ],
      "metadata": {
        "id": "tz8nOWE4aJRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# оприходована ли поставка (найдены все СФ)\n",
        "df_res['Оприходование поставки'] = np.where(df_res['Маркер X'] == 'Найдены все сч.ф.', 1, 0)\n",
        "\n",
        "# указываем статус перевозки в FCA\n",
        "df_res['Статус перевозки'] = np.where(\n",
        "    df_res['Не зарег. / Не найд.'] == 1,\n",
        "    'Не зарег. / Не найд.',\n",
        "    np.where(df_res['Оприходование поставки'] == 1, 'Оприходовано', 'Не оприходовано')\n",
        "    )"
      ],
      "metadata": {
        "id": "Wzk8Z0dDam-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# указываем месяц реестра FCA\n",
        "df_res['Месяц'] = df_res['Дата отгрузки ФАКТ'].dt.month\n",
        "\n",
        "# словарь соответствия\n",
        "month_dict = {\n",
        "    1: 'Январь', 2: 'Февраль', 3: 'Март', 4: 'Апрель',\n",
        "    5: 'Май', 6: 'Июнь', 7: 'Июль', 8: 'Август',\n",
        "    9: 'Сентябрь', 10: 'Октябрь', 11: 'Ноябрь', 12: 'Декабрь'\n",
        "}\n",
        "\n",
        "# указываем наименование месяца реестра FCA\n",
        "df_res['Месяц наименование'] = df_res['Месяц'].map(month_dict)"
      ],
      "metadata": {
        "id": "XICvCOK267MS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# цепляем логи к списку найденных СФ\n",
        "inv_log = inv_reg.merge(logs, how='left', left_on='Номер документа (сч.ф)', right_on='BELNR')"
      ],
      "metadata": {
        "id": "nhX3WtltcKYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# рассчитываем время проверки документов в днях\n",
        "inv_log['Время проверки документов'] = np.where(\n",
        "    inv_log['CHDAT'].isna(),\n",
        "    (inv_log['Дата создания СчФ'] - inv_log['ТС: Дата отправки']).dt.days,\n",
        "    (inv_log['CHDAT'] - inv_log['ТС: Дата отправки']).dt.days\n",
        "    ).astype(int)"
      ],
      "metadata": {
        "id": "sb3jVbWDcYmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# рассчитываем время проводки документов в днях\n",
        "inv_log['Время проводки документов'] = np.where(\n",
        "    inv_log['CHDAT'].isna(),\n",
        "    (inv_log['Дата ввода'] - inv_log['Дата создания СчФ']).dt.days,\n",
        "    (inv_log['Дата ввода'] - inv_log['CHDAT']).dt.days\n",
        "    ).astype(int)"
      ],
      "metadata": {
        "id": "1QuSgd0AcmtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# факт оприходования СФ\n",
        "inv_log['Оприходование СФ факт'] = np.where(inv_log['Оприходование СФ'].isin(['Физический склад', 'Виртуальный склад']), 1, 0)"
      ],
      "metadata": {
        "id": "_m-zctZpWPMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# виртуальный склад (да/нет)\n",
        "inv_log['Виртуальный склад'] = np.where(inv_log['Оприходование СФ'] == 'Виртуальный склад', 1, 0)\n",
        "\n",
        "# физический склад (да/нет)\n",
        "inv_log['Физический склад'] = np.where(inv_log['Оприходование СФ'] == 'Физический склад', 1, 0)"
      ],
      "metadata": {
        "id": "aTfBmX114R_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# переименовываем понятным образом столбцы\n",
        "inv_log = inv_log.rename(columns={'CHDAT':'ДатаИзм', 'BELNR':'№ докум.'})"
      ],
      "metadata": {
        "id": "z0ha6XFYJUHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Дополнительно проверяем корректность указания id в реестре FCA"
      ],
      "metadata": {
        "id": "H8d4K3Cv33YW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# побочные датафреймы для отлавливания ошибок\n",
        "for_errors_df_one = fca_clean.copy()\n",
        "for_errors_sap_one = sap_519_exp.copy()\n",
        "\n",
        "# форматируем побочный датафрейм, по которому будем искать разночтения по id\n",
        "# на данном шаге можно использовать merge по полю \"Код\"\n",
        "# но для получения одинакого кол-ва полей у побочных датафреймов лучше использовать функцию\n",
        "for_errors_df_one['Ключ'] = for_errors_df_one.apply(\n",
        "    lambda row: generate_keys(\n",
        "        contracts_processing(row['Код']),\n",
        "        app_nums_processing(row['Код']),\n",
        "        row['Код']\n",
        "        ), axis=1\n",
        "    )\n",
        "\n",
        "# растаскиваем по строкам\n",
        "for_errors_df_one = for_errors_df_one.explode('Ключ')\n",
        "\n",
        "# форматируем побочный датафрейм, по которому будем искать разночтения по id\n",
        "for_errors_sap_one['Ключ'] = for_errors_sap_one.apply(\n",
        "    lambda row: [\n",
        "        key for val in [extract_code(row[col]) for col in ['ТС: №ТранспДок', 'ТС: №ТранспСр-ва', 'ТС: №ЕдОбр']]\n",
        "        for key in generate_keys(\n",
        "            val,\n",
        "            val,\n",
        "            val\n",
        "        )\n",
        "    ],\n",
        "    axis=1\n",
        "    )\n",
        "\n",
        "# растаскиваем по строкам\n",
        "for_errors_sap_one = for_errors_sap_one.explode('Ключ')\n",
        "\n",
        "# соединяем по ключам датафреймы для поиска ошибок\n",
        "for_errors_df_one = for_errors_df_one.merge(for_errors_sap_one, how='inner', on='Ключ')\n",
        "\n",
        "# удаляем ключи с Nan на конце\n",
        "for_errors_df_one = for_errors_df_one[~for_errors_df_one['Ключ'].str.lower().str.endswith('none')]"
      ],
      "metadata": {
        "id": "Pz-Ty_8J2Ej-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Формирование дополнительного реестра на проверку FCA"
      ],
      "metadata": {
        "id": "fvmbKYsRuHRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ищем строки с одинаковым id и разными номерами договора\n",
        "erros_df = for_errors_df_one[\n",
        "    (for_errors_df_one['Договор'].str.strip() != for_errors_df_one['ЮрНомер договора на поставку'].str.strip()) &\n",
        "    (~for_errors_df_one['ЮрНомер договора на поставку'].fillna('').str.contains(r'[\\;\\,\\/\\\\]')) &\n",
        "    (for_errors_df_one['ЮрНомер договора на поставку'].str.count('Д') < 2) &\n",
        "    (~for_errors_df_one['Договор'].str.contains(r'[\\;\\,\\/\\\\]')) &\n",
        "    (for_errors_df_one['Договор'].str.count('Д') < 2)\n",
        "    ]\n",
        "\n",
        "erros_df = erros_df[[\n",
        "    'Договор',\n",
        "    'Номер приложения',\n",
        "    'ЮрНомер договора на поставку',\n",
        "    '№ приложения к договору'\n",
        "    ]].drop_duplicates()"
      ],
      "metadata": {
        "id": "VAvAzrD9uH6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Формирование Excel-файла на доработку FCA"
      ],
      "metadata": {
        "id": "1jflyR4TheSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# формируем файл для возврата на проверку блоку FCA\n",
        "# первый лист - не до конца заполненные обязательные данные\n",
        "# второй лист - строки, сцепившиеся по одному id, но с разными номерами договоров и приложениями; это на уточнение\n",
        "\n",
        "datasets = [fca_revision, erros_df]\n",
        "sheet_names = ['Нет данных', 'На уточнение']\n",
        "excel_filename = 'FCA реестр на проверку.xlsx'\n",
        "\n",
        "with pd.ExcelWriter(excel_filename) as writer:\n",
        "  for data, sheet in zip(datasets, sheet_names):\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_excel(writer, sheet_name=sheet, header=True, index=False)"
      ],
      "metadata": {
        "id": "w-qRiIx9fUAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Расчеты для первой страницы дашборда \"МТР в пути\" (месяц)"
      ],
      "metadata": {
        "id": "zvY0SC9RtxqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Информация о перевозках за соответствующий месяц**"
      ],
      "metadata": {
        "id": "_wXexRx4Vbev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'месяц':\n",
        "\n",
        "  # кол-во найденных перевозок\n",
        "  fnd_tr = sum(df_res['Зарегистрировано'])\n",
        "\n",
        "  # кол-во не найденных перевозок\n",
        "  nt_fnd_tr = sum(df_res['Не зарег. / Не найд.'])\n",
        "\n",
        "  print(f'Общее кол-во перевозок FCA: {len(fca)} шт.;')\n",
        "  print(f'Возвращено на доработку: {len(fca_revision)} шт., {round(len(fca_revision) / len(fca) * 100, 2)} %;')\n",
        "  print('')\n",
        "  print(f'Зарегистрировано: {fnd_tr} шт., {round(fnd_tr / len(fca) * 100, 2)} %;')\n",
        "  print(f'Не найдено / Не зарегистрировано: {nt_fnd_tr} шт., {round(nt_fnd_tr / len(fca) * 100, 2)} %;')\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "rsOeI4JaVcA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d0372a1-2e90-4689-b03e-b24c9ca125a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Общее кол-во перевозок FCA: 1690 шт.;\n",
            "Возвращено на доработку: 6 шт., 0.36 %;\n",
            "\n",
            "Зарегистрировано: 1311 шт., 77.57 %;\n",
            "Не найдено / Не зарегистрировано: 379 шт., 22.43 %;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Определение категории оприходования СФ**"
      ],
      "metadata": {
        "id": "Xnv3BtN1-aai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'месяц':\n",
        "\n",
        "  # статусы оприходования по СФ\n",
        "  print(inv_log.groupby('Оприходование СФ')['Номер документа (сч.ф)'].nunique().reset_index(name='Кол-во СФ'))\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "Vg_FfzpRvB1w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae5d8642-ae52-4b0d-ff92-5d9246ad8059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Оприходование СФ  Кол-во СФ\n",
            "0  Виртуальный склад        145\n",
            "1    Не оприходовано        518\n",
            "2   Физический склад        914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Статусы СФ по документам зарегистрированных в SAP поставок**"
      ],
      "metadata": {
        "id": "ZRsKRvXsSCUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'месяц':\n",
        "\n",
        "  # фиксируем получение статусов проверки документов для отражения в дашборде\n",
        "  print(inv_log.groupby('Документы проверены')['Номер документа (сч.ф)'].nunique().reset_index(name='Кол-во СФ'))\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "B3EplaHhR6kW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aa7517c-afcd-455c-f868-1a3588170595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Документы проверены  Кол-во СФ\n",
            "0                  да       1538\n",
            "1                 нет         39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Расчет стоимости перевозок по оприходованным МТР**"
      ],
      "metadata": {
        "id": "6-TMWWUTcBsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'месяц':\n",
        "\n",
        "  # суммарная стоимость перевозок, руб\n",
        "  print(\n",
        "      df_res.groupby('Статус перевозки')['Ставка перевозчика с НДС, руб'].sum().apply(\n",
        "          lambda x: f'{x:,.0f}'.replace(',', ' ')).reset_index(name='Суммарная стоимость перевозок (с НДС), руб'\n",
        "          )\n",
        "      )\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "3muNtsq0TbWv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2da1ad0b-7945-453a-89d6-327e9494583e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Статус перевозки Суммарная стоимость перевозок (с НДС), руб\n",
            "0  Не зарег. / Не найд.                                 90 891 323\n",
            "1       Не оприходовано                                  5 746 720\n",
            "2          Оприходовано                                162 849 391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Определение категорий времени для СФ с проверенными документами (с момента отправки ТС)**"
      ],
      "metadata": {
        "id": "ugd6ScjMNU7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'месяц':\n",
        "\n",
        "  # прописываем категории для времени проверки документов\n",
        "  choices_check = ['1.До 5 дней', '2.От 6 до 10 дней', '3.От 11 до 14 дней', '4.Более 14 дней']\n",
        "\n",
        "  # прописываем условия для определения СФ в конкретную категорию времени проверки документов\n",
        "  conditions_check = [\n",
        "      inv_log['Время проверки документов'] <= 5,\n",
        "      (inv_log['Время проверки документов'] <= 10) & (inv_log['Время проверки документов'] > 5),\n",
        "      (inv_log['Время проверки документов'] <= 14) & (inv_log['Время проверки документов'] > 10),\n",
        "      inv_log['Время проверки документов'] > 14\n",
        "  ]\n",
        "\n",
        "  # формируем признак категории для СФ\n",
        "  inv_log['Время проверки документов (группы)'] = np.select(conditions_check, choices_check, default='ПРОВЕРИТЬ!!!')\n",
        "\n",
        "  print(\n",
        "      inv_log.groupby('Время проверки документов (группы)')['Номер документа (сч.ф)'].nunique()\n",
        "  )\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "bpg3XB89C8Is",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95d7b7db-8617-477c-ae9d-87b2980a3bb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время проверки документов (группы)\n",
            "1.До 5 дней           1232\n",
            "2.От 6 до 10 дней      226\n",
            "3.От 11 до 14 дней      61\n",
            "4.Более 14 дней         58\n",
            "Name: Номер документа (сч.ф), dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Определение категорий времени для оприходованных СФ (на склад с момента проверки документов)**"
      ],
      "metadata": {
        "id": "r6-gjZcLOBRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'месяц':\n",
        "\n",
        "  # прописываем категории для времени проводки документов\n",
        "  choices_post = ['1.Без задержек', '2.От 1 до 3 дней', '3.От 4 до 5 дней', '4.От 6 до 10 дней', '5.От 11 до 14 дней', '6.Более 14 дней']\n",
        "\n",
        "  # прописываем условия для определения СФ в конкретную категорию времени проводки документов\n",
        "  conditions_post = [\n",
        "      inv_log['Время проводки документов'] <= 0,\n",
        "      (inv_log['Время проводки документов'] <= 3) & (inv_log['Время проводки документов'] > 0),\n",
        "      (inv_log['Время проводки документов'] <= 5) & (inv_log['Время проводки документов'] > 3),\n",
        "      (inv_log['Время проводки документов'] <= 10) & (inv_log['Время проводки документов'] > 5),\n",
        "      (inv_log['Время проводки документов'] <= 14) & (inv_log['Время проводки документов'] > 10),\n",
        "      inv_log['Время проводки документов'] > 14\n",
        "  ]\n",
        "\n",
        "  # формируем признак категории для СФ\n",
        "  inv_log['Время проводки документов (группы)'] = np.select(conditions_post, choices_post, default='ПРОВЕРИТЬ!!!')\n",
        "\n",
        "  print(\n",
        "      inv_log.groupby('Время проводки документов (группы)')['Номер документа (сч.ф)'].nunique()\n",
        "  )\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "Nx7g9VHaN5p6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a657380b-2b1e-4c8b-ae45-de879efc9ef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время проводки документов (группы)\n",
            "1.Без задержек        605\n",
            "2.От 1 до 3 дней      159\n",
            "3.От 4 до 5 дней      114\n",
            "4.От 6 до 10 дней     286\n",
            "5.От 11 до 14 дней    182\n",
            "6.Более 14 дней       231\n",
            "Name: Номер документа (сч.ф), dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Сохранение результатов (месяц)**"
      ],
      "metadata": {
        "id": "MLtTl8Ju5jFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'месяц':\n",
        "\n",
        "  datasets = [df_res, inv_log]\n",
        "  sheet_names = ['FCA мес', 'SAP мес']\n",
        "  excel_filename = 'Модель данных месяц.xlsx'\n",
        "\n",
        "  with pd.ExcelWriter(excel_filename) as writer:\n",
        "    for data, sheet in zip(datasets, sheet_names):\n",
        "      df = pd.DataFrame(data)\n",
        "      df.to_excel(writer, sheet_name=sheet, header=True, index=False)\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "P4C0hGnp5mGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Расчеты для второй страницы дашборда \"МТР в пути\" (год)"
      ],
      "metadata": {
        "id": "4LL8T8-_zNoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Динамика оприходования перевозок после закрытия месяца**"
      ],
      "metadata": {
        "id": "BK-FLsSDeGiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'год':\n",
        "\n",
        "  # категории оприходования\n",
        "  fca_cat = ['В рамках месяца', 'После закрытия месяца', 'Не оприходовано']\n",
        "\n",
        "  # условия для категорий оприходования\n",
        "  fca_cond = [\n",
        "      (df_res['Оприходование поставки'] == 1) & (\n",
        "          (df_res['Дата последней проводки'].dt.month - df_res['Месяц'] <= 0) | (\n",
        "              (df_res['Дата последней проводки'].dt.month - df_res['Месяц'] == 1) & (df_res['Дата последней проводки'].dt.day <= 6)\n",
        "          )\n",
        "          ),\n",
        "      (df_res['Оприходование поставки'] == 1) & (\n",
        "          (\n",
        "              (df_res['Дата последней проводки'].dt.month - df_res['Месяц'] == 1) & (df_res['Дата последней проводки'].dt.day > 6)\n",
        "              ) |\n",
        "              (df_res['Дата последней проводки'].dt.month - df_res['Месяц'] > 1)\n",
        "              ),\n",
        "      (df_res['Оприходование поставки'] == 0)\n",
        "      ]\n",
        "\n",
        "  # данный столбец нужен для определения своевременности оприходования поставки в рамках года\n",
        "  df_res['Категория оприходования'] = np.select(fca_cond, fca_cat, default='ПРОВЕРИТЬ!!!')\n",
        "\n",
        "  # в рамках месяца (да/нет)\n",
        "  df_res['В рамках месяца'] = np.where(df_res['Категория оприходования'] == 'В рамках месяца', 1, 0)\n",
        "\n",
        "  # после закрытия месяца (да/нет)\n",
        "  df_res['После закрытия месяца'] = np.where(df_res['Категория оприходования'] == 'После закрытия месяца', 1, 0)\n",
        "\n",
        "  print(\n",
        "      df_res.groupby(['Месяц наименование', 'Категория оприходования'])['Индекс перевозки'].nunique()\n",
        "  )\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "u8dvfB9BS8Qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Стоимость перевозок по оприходованным МТР**"
      ],
      "metadata": {
        "id": "9DtsMCrieRcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'год':\n",
        "\n",
        "  # суммарная стоимость перевозок, руб\n",
        "  print(\n",
        "      df_res.groupby('Категория оприходования')['Ставка перевозчика с НДС, руб'].sum().apply(\n",
        "          lambda x: f'{x:,.0f}'.replace(',', ' ')).reset_index(name='Суммарная стоимость перевозок (с НДС), руб'\n",
        "          )\n",
        "      )\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "cduKK0WUS-OL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Оприходованные перевозки (на склад с момента отправки ТС)**"
      ],
      "metadata": {
        "id": "REgs9N2WeWJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'год':\n",
        "\n",
        "  # прописываем категории для времени оприходования перевозки\n",
        "  choices_post = ['1.До 5 дней', '2.6-10 дней', '3.11-20 дней', '4.21-30 дней', '5.Более 30 дней']\n",
        "\n",
        "  # прописываем условия для определения СФ в конкретную категорию времени проводки документов\n",
        "  conditions_post = [\n",
        "      (df_res['Дата последней проводки'] - df_res['Дата отгрузки ФАКТ']).dt.days <= 5,\n",
        "      ((df_res['Дата последней проводки'] - df_res['Дата отгрузки ФАКТ']).dt.days <= 10) & ((df_res['Дата последней проводки'] - df_res['Дата отгрузки ФАКТ']).dt.days > 5),\n",
        "      ((df_res['Дата последней проводки'] - df_res['Дата отгрузки ФАКТ']).dt.days <= 20) & ((df_res['Дата последней проводки'] - df_res['Дата отгрузки ФАКТ']).dt.days > 10),\n",
        "      ((df_res['Дата последней проводки'] - df_res['Дата отгрузки ФАКТ']).dt.days <= 30) & ((df_res['Дата последней проводки'] - df_res['Дата отгрузки ФАКТ']).dt.days > 20),\n",
        "      (df_res['Дата последней проводки'] - df_res['Дата отгрузки ФАКТ']).dt.days > 30\n",
        "  ]\n",
        "\n",
        "  # формируем признак категории для СФ\n",
        "  df_res['Оприходование поставки (категории)'] = np.select(conditions_post, choices_post, default='Не оприходовано')\n",
        "\n",
        "  print(\n",
        "      df_res.groupby('Оприходование поставки (категории)')['Оприходование поставки'].sum()\n",
        "  )\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "YUKSXUa5TC7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Оприходованные СФ (на склад с момента проверки документов)**"
      ],
      "metadata": {
        "id": "vhZO13dBebfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'год':\n",
        "\n",
        "  # прописываем категории для времени проводки документов\n",
        "  choices_post = ['1.До 5 дней', '2.6-10 дней', '3.11-20 дней', '4.21-30 дней', '5.Более 30 дней']\n",
        "\n",
        "  # прописываем условия для определения СФ в конкретную категорию времени проводки документов\n",
        "  conditions_post = [\n",
        "      inv_log['Время проводки документов'] <= 5,\n",
        "      (inv_log['Время проводки документов'] <= 10) & (inv_log['Время проводки документов'] > 5),\n",
        "      (inv_log['Время проводки документов'] <= 20) & (inv_log['Время проводки документов'] > 10),\n",
        "      (inv_log['Время проводки документов'] <= 30) & (inv_log['Время проводки документов'] > 20),\n",
        "      inv_log['Время проводки документов'] > 30\n",
        "  ]\n",
        "\n",
        "  # формируем признак категории для СФ\n",
        "  inv_log['Время проводки документов (группы)'] = np.select(conditions_post, choices_post, default='Не оприходовано')\n",
        "\n",
        "  print(\n",
        "      inv_log[inv_log['Оприходование СФ'] != 'Не оприходовано'].groupby(['Время проводки документов (группы)', 'Оприходование СФ'])['Номер документа (сч.ф)'].nunique()\n",
        "  )\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "VVUAipmlTDpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'год':\n",
        "\n",
        "    current_max_idx = df_res['Индекс перевозки'].max()\n",
        "    year = 2025\n",
        "\n",
        "    # добавляем по одной пустой строке с каждым недостающим месяцем\n",
        "    for idx, month_name in enumerate(['Январь', 'Февраль', 'Март', 'Апрель', 'Май', 'Июнь', 'Июль', 'Август', 'Сентябрь', 'Октябрь', 'Ноябрь', 'Декабрь']):\n",
        "        if month_name not in df_res['Месяц наименование'].values:\n",
        "            # определяем номер месяца (январь = 1, февраль = 2 и т.д.)\n",
        "            month_number = idx + 1\n",
        "\n",
        "            # создаем дату и время в формате Timestamp\n",
        "            timestamp_date = pd.Timestamp(f\"{year}-{month_number:02d}-01\")\n",
        "\n",
        "            # создаем новую строку\n",
        "            new_row = {\n",
        "                'Месяц наименование': month_name,\n",
        "                'В рамках месяца': 0,\n",
        "                'После закрытия месяца': 0,\n",
        "                'Дата отгрузки ФАКТ': timestamp_date,\n",
        "                'Индекс перевозки': current_max_idx+1,\n",
        "                'Зарегистрировано': 0,\n",
        "                'Оприходование поставки': 0,\n",
        "                'Оприходование поставки (категории)': 'Другое'\n",
        "            }\n",
        "\n",
        "            # добавляем новую строку в датафрейм\n",
        "            df_res = df_res._append(new_row, ignore_index=True)\n",
        "            current_max_idx += 1\n",
        "\n",
        "else:\n",
        "    pass"
      ],
      "metadata": {
        "id": "-VnNz4tqUcf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Сохранение результатов (год)**"
      ],
      "metadata": {
        "id": "AxQl8-KWerv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'год':\n",
        "\n",
        "  datasets = [df_res, inv_log]\n",
        "  sheet_names = ['FCA год', 'SAP год']\n",
        "  excel_filename = 'Модель данных год.xlsx'\n",
        "\n",
        "  with pd.ExcelWriter(excel_filename) as writer:\n",
        "    for data, sheet in zip(datasets, sheet_names):\n",
        "      df = pd.DataFrame(data)\n",
        "      df.to_excel(writer, sheet_name=sheet, header=True, index=False)\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "DX3lVQaFTEMK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}