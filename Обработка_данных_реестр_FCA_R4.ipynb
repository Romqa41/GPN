{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Блок импорта библиотек"
      ],
      "metadata": {
        "id": "OIyzBxXx5Kw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import re"
      ],
      "metadata": {
        "id": "kfVeNnTIAC9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Блок функций"
      ],
      "metadata": {
        "id": "btzjtJAk_6f0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция замены латинских букв на кириллические"
      ],
      "metadata": {
        "id": "TN4r78igJTNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_letters(text):\n",
        "  # создаем словарь соответствия латинских букв и кириллицы\n",
        "  mapping = {\n",
        "      'A': 'А',  # пример: латинская A -> кириллическая А\n",
        "      'E': 'Е',\n",
        "      'K': 'К',\n",
        "      'M': 'М',\n",
        "      'O': 'О',\n",
        "      'T': 'Т',\n",
        "      'C': 'С',\n",
        "      'P': 'Р',\n",
        "      'X': 'Х'\n",
        "      }\n",
        "  # заменяем каждую букву из текста, если она есть в словаре\n",
        "  return ''.join(mapping.get(char, char) for char in text)"
      ],
      "metadata": {
        "id": "cDcZPWEjGcku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция для поиска автомобильных номеров"
      ],
      "metadata": {
        "id": "GbA4HToMANe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transport_number(text):\n",
        "  # проверка на наличие данных\n",
        "  if pd.notna(text):\n",
        "    text = str(text)\n",
        "\n",
        "    # корректировка номеров ТС - удаление пробелов, (, ) и /, приведение к верхнему регистру\n",
        "    processed_text = re.sub(r'[\\s\\(\\)\\/\\-\\\\]', '', str(text)).upper()\n",
        "\n",
        "    processed_text = replace_letters(processed_text)\n",
        "\n",
        "    # паттерн для автомобильного номера\n",
        "    pattern = r'[А-ЯA-Z]\\d{3}[А-ЯA-Z]{2}\\d{0,3}'\n",
        "\n",
        "    # ищем совпадение по паттерну, если находим - функция возвращает весь номер\n",
        "    res = re.search(pattern, processed_text)\n",
        "    return res.group() if res else None\n",
        "\n",
        "  # в случае отсутствия искомого паттерна функция ничего не возвращает\n",
        "  return None"
      ],
      "metadata": {
        "id": "5CZ6dRRF7L6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция для поиска транспортных накладных"
      ],
      "metadata": {
        "id": "-PWp5SayARH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transport_invoice(text):\n",
        "  # проверка на наличие данных\n",
        "  if pd.notna(text):\n",
        "    text = str(text)\n",
        "\n",
        "    # удаляем id\n",
        "    text = re.sub(r'\\{\\d{10}\\}', '', text)\n",
        "    # удаляем пробелы внутри текста\n",
        "    text = re.sub(r'\\s+', '', text)\n",
        "    # удаляем {}\n",
        "    text = re.sub(r'[{}]', '', text)\n",
        "    # удаляем слово \"Накладная\", учитываем оба регистра\n",
        "    text = re.sub(r'накладная', '', text, flags=re.I)\n",
        "    # удаляем слово \"ТТН\", учитываем оба регистра\n",
        "    text = re.sub(r'ттн', '', text, flags=re.I)\n",
        "\n",
        "    # возвращаем данные без пробелов в верхнем регистре\n",
        "    if text == '':\n",
        "      return None\n",
        "    if text:\n",
        "      return text.upper()\n",
        "\n",
        "  # если не нашлось данных - возвращаем пустое значение\n",
        "  return None"
      ],
      "metadata": {
        "id": "SvE79c7c-oOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция для поиска номера трекера"
      ],
      "metadata": {
        "id": "Lon4tZYXWwA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tracker_number(text):\n",
        "  # проверка на наличие данных\n",
        "  if pd.notna(text):\n",
        "    text = str(text)\n",
        "\n",
        "    # убираем лишний текст (\" от ДД.ММ.ГГГГ\")\n",
        "    text = re.sub(r'\\s+[Оо][Тт].*$', '', text)\n",
        "    # удаляем id\n",
        "    text = re.sub(r'\\{\\d{10}\\}', '', text)\n",
        "    # удаляем слово \"ТТН\", учитываем оба регистра\n",
        "    text = re.sub(r'ттн', '', text, flags=re.I)\n",
        "    # удаляем тире\n",
        "    text = re.sub('-', '', text)\n",
        "    # удаляем пробелы\n",
        "    text = re.sub(r'\\s+', '', text)\n",
        "    # удаляем {}\n",
        "    text = re.sub(r'[{}]', '', text)\n",
        "\n",
        "    # если текста фактически не осталось - возвращаем пустое значение\n",
        "    if text == '':\n",
        "      return None\n",
        "\n",
        "    # возвращаем очищенный текст в верхнем регистре\n",
        "    return text.upper()\n",
        "\n",
        "  # заглушка\n",
        "  return None"
      ],
      "metadata": {
        "id": "T5zJgRffU79h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция преобразования приложений к договорам"
      ],
      "metadata": {
        "id": "cHm6XGPVAWkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def app_nums_processing(text):\n",
        "  # проверка на наличие данных\n",
        "  if pd.isna(text):\n",
        "    return text\n",
        "\n",
        "  # приводим данные к строковому типу и к верхнему регистру\n",
        "  text = str(text).upper()\n",
        "\n",
        "  # убираем лишний текст (\" от ДД.ММ.ГГГГ\")\n",
        "  text = re.sub(r'\\s+[Оо][Тт].*$', '', text)\n",
        "  # заменяем все разделители на запятые\n",
        "  text = re.sub(r'[;\\s\\.]+', ',', str(text))\n",
        "  # удаляем лишние запятые и пробелы\n",
        "  text = re.sub(r',+', ',', text).strip(', ')\n",
        "  # добавляем пробелы после запятых\n",
        "  text = re.sub(r',', ', ', text)\n",
        "  # удаляем возможные пробелы перед запятыми\n",
        "  text = re.sub(r'\\s*,', ',', text)\n",
        "\n",
        "  # разделяем приложения по запятым и записываем в массив\n",
        "  applications = re.split(',', text.strip())\n",
        "  applications = [a for a in applications if a]\n",
        "\n",
        "  # склеиваем массив обратно в строку\n",
        "  return ', '.join(applications) if applications else text"
      ],
      "metadata": {
        "id": "NjfrI1jf_-pH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция преобразования договоров"
      ],
      "metadata": {
        "id": "e7sm6n-UAcK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def contracts_processing(text):\n",
        "  # проверка на наличие данных\n",
        "  if pd.isna(text):\n",
        "    return text\n",
        "\n",
        "  # приводим данные к строковому типу и к верхнему регистру\n",
        "  text = str(text).upper()\n",
        "\n",
        "  # отдельно приводим формат \"Д-р\" в нормальный вид\n",
        "  text = re.sub(r'[Дд]-[Рр]\\s+', 'Д_', text)\n",
        "  # убираем лишний текст (\" от ДД.ММ.ГГГГ\")\n",
        "  text = re.sub(r'\\s+[Оо][Тт].*$', '', text)\n",
        "\n",
        "  # ищем пробелы перед типовыми названиями договоров\n",
        "  pattern = r'\\s(?=(Д_|ДП_|ИТС-))'\n",
        "\n",
        "  # заменяем их на запятые\n",
        "  text = re.sub(pattern, ',', text)\n",
        "  # удаляем пробелы внутри договоров\n",
        "  text = re.sub(' ', '', text)\n",
        "  # заменяем ; и \\ на ,\n",
        "  text = re.sub(r'[;\\\\]', ',', text)\n",
        "\n",
        "  # разделяем договоры по запятым и записываем в массив\n",
        "  contracts = re.split(',', text.strip())\n",
        "  contracts = [c for c in contracts if c]\n",
        "\n",
        "  # склеиваем массив обратно в строку\n",
        "  return ', '.join(contracts) if contracts else text"
      ],
      "metadata": {
        "id": "MzJrMz7u_-bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция извлечения кода с учетом приоритетов столбцов"
      ],
      "metadata": {
        "id": "usHSBdNoAh1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_code(text):\n",
        "\n",
        "  # проверка на наличие данных в ячейке столбца - это необходимо для дальнейшего использования в лямбда-функции\n",
        "  if pd.notna(text):\n",
        "    text = str(text)\n",
        "\n",
        "    # поиск кода в тексте - извлекается группа из одной или более цифры подряд из скобок {}\n",
        "    res = re.search(r'\\{(\\d+)\\}', text)\n",
        "    if res:\n",
        "      # в случае нахождения совпадений возвращается первая извлеченная из скобок группа цифр\n",
        "      return res.group(1)\n",
        "\n",
        "    # поиск кода в тексте - извлекается группа из ровно 10 цифр подряд без скобок {}\n",
        "    res = re.search(r'\\b(\\d{10})\\b', text)\n",
        "    if res:\n",
        "      # в случае нахождения совпадений возвращается первая извлеченная из скобок группа цифр\n",
        "      return res.group(1)\n",
        "\n",
        "  # в случае отсутствия искомого паттерна функция ничего не возвращает\n",
        "  return None"
      ],
      "metadata": {
        "id": "IHMsvzkwAf5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция статуса проводки СФ"
      ],
      "metadata": {
        "id": "6SmOKgnUhA0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def colors(row):\n",
        "  if row['Статус документа счета'] == 'Проведено':\n",
        "    res = 'Зеленый'\n",
        "  elif row['Статус документа счета'] == 'Предварительно зарегистрировано' and pd.isna(row['Дата поступл.ТМЦ']) == True:\n",
        "    res = 'Красный'\n",
        "  else:\n",
        "    res = 'Желтый'\n",
        "  return res"
      ],
      "metadata": {
        "id": "DDU0SwTtgau9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция определения категории оприходования СФ"
      ],
      "metadata": {
        "id": "mzdpZ4vZ4mX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reg(df, sap_519, sap_521):\n",
        "\n",
        "  # разбираем полученные списки СФ на отдельные СФ\n",
        "  res = df[['Номер документа (сч.ф)']].explode('Номер документа (сч.ф)')\n",
        "\n",
        "  # удаляем строки без СФ\n",
        "  res = res[res['Номер документа (сч.ф)'].notna()]\n",
        "\n",
        "  # цепляем выгрузку SAP 519\n",
        "  res = res.merge(sap_519[[\n",
        "      'Номер документа (сч.ф)',\n",
        "      'Поставка',\n",
        "      'Статус проводки СФ',\n",
        "      'Документы проверены',\n",
        "      'Дата создания СчФ',\n",
        "      'ТС: Дата отправки',\n",
        "      'Дата ввода',\n",
        "      'Дата проводки',\n",
        "      'Дата поступл.ТМЦ'\n",
        "      ]].drop_duplicates(), how='left', on='Номер документа (сч.ф)')\n",
        "\n",
        "  # цепляем выгрузку SAP 521\n",
        "  res = res.merge(sap_521[['№ приходного ордера']].drop_duplicates(), how='left', left_on='Поставка', right_on='№ приходного ордера')\n",
        "\n",
        "  # прописываем категории для СФ\n",
        "  choices = ['Не оприходовано', 'Виртуальный склад', 'Физический склад']\n",
        "\n",
        "  # прописываем условия для определения СФ в конкретную категорию\n",
        "  conditions = [\n",
        "      (res['Статус проводки СФ'] == 'Красный'),\n",
        "      ~(res['Статус проводки СФ'] == 'Красный') & (res['№ приходного ордера'].notna()),\n",
        "      ~(res['Статус проводки СФ'] == 'Красный') & (res['№ приходного ордера'].isna())\n",
        "  ]\n",
        "\n",
        "  # формируем признак категории для СФ\n",
        "  res['Оприходование СФ'] = np.select(conditions, choices, default='ПРОВЕРИТЬ!!!')\n",
        "\n",
        "  # удаляем дубликаты, которые могут появиться после присоединения выгрузок\n",
        "  res = res.drop_duplicates()\n",
        "\n",
        "  return res"
      ],
      "metadata": {
        "id": "1aib57dj4m9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция подсчета СФ"
      ],
      "metadata": {
        "id": "hJFWI3LctuMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_list(lst):\n",
        "\n",
        "  # обеспечиваем, что lst — список\n",
        "  if not isinstance(lst, list):\n",
        "    lst = [lst]\n",
        "\n",
        "  # по умолчанию ставим метку False на наличие значений и пропусков\n",
        "  has_nan = False\n",
        "  has_values = False\n",
        "\n",
        "  # проверяем наличие и отсутствие пропусков\n",
        "  for item in lst:\n",
        "    if item is None or (isinstance(item, float) and np.isnan(item)):\n",
        "      has_nan = True\n",
        "    elif item is not None:\n",
        "      has_values = True\n",
        "\n",
        "  # найдены и пропуски и значения\n",
        "  if has_nan and has_values:\n",
        "    return 'Сч.ф. найдены частично'\n",
        "  # найдены только пропуски\n",
        "  elif has_nan and not has_values:\n",
        "    return 'Не найдено ни одной сч.ф.'\n",
        "  # найдены только значения\n",
        "  elif not has_nan:\n",
        "    return 'Найдены все сч.ф.'\n",
        "\n",
        "  # заглушка\n",
        "  return 'Найдены все сч.ф.'"
      ],
      "metadata": {
        "id": "w9eb7s1Rtti1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция создания ключей с логикой четности"
      ],
      "metadata": {
        "id": "CC0v0OErAoAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_keys(contracts, applications, another):\n",
        "\n",
        "  # приводим данные к строчному типу\n",
        "  contracts = str(contracts)\n",
        "  applications = str(applications)\n",
        "\n",
        "  # убираем пробелы\n",
        "  contracts = contracts.replace(' ', '')\n",
        "  applications = applications.replace(' ', '')\n",
        "\n",
        "  # формируем списки\n",
        "  contracts = contracts.split(',')\n",
        "  applications = applications.split(',')\n",
        "\n",
        "  # это третий аргумент для любого столбца, ячейки которого содержат одно значение\n",
        "  another_value = str(another).strip()\n",
        "\n",
        "  # сюда будем складывать найденные ключи\n",
        "  keys = []\n",
        "\n",
        "  # правило 1: кол-во договоров = кол-во приложений\n",
        "  if len(contracts) == len(applications):\n",
        "    keys.extend([f'{c}_{a}_{another_value}' for c, a in zip(contracts, applications)])\n",
        "\n",
        "  # правило 2: 1 договор и несколько приложений\n",
        "  elif len(contracts) == 1 and len(applications) > 1:\n",
        "    keys.extend([f'{contracts[0]}_{a}_{another_value}' for a in applications])\n",
        "\n",
        "  # правило 3: несколько договоров и 1 приложение\n",
        "  elif len(contracts) > 1 and len(applications) == 1:\n",
        "    keys.extend([f'{c}_{applications[0]}_{another_value}' for c in contracts])\n",
        "\n",
        "  # правило 4: кол-во договоров > 1, кол-во приложений > 1, кол-ва не равны\n",
        "  elif len(contracts) > 1 and len(applications) > 1:\n",
        "    # считаем кол-во приложений на договор с округлением вверх\n",
        "    multiplicity = math.ceil(len(applications) / len(contracts))\n",
        "    # определяем с помощью индексов каким договорам соответствуют какие приложения\n",
        "    # начальный индекс - включительно, конечный - не включительно\n",
        "    for i, contract in enumerate(contracts):\n",
        "      start_idx = i * multiplicity\n",
        "      end_idx = start_idx + multiplicity\n",
        "      # если это последний договор, то для него берем все приложения с start_idx и до конца списка\n",
        "      # чтобы не потерять приложения, если общее количество не делится ровно\n",
        "      if i == len(contracts) - 1:\n",
        "        for app in applications[start_idx:]:\n",
        "          keys.append(f'{contract}_{app}_{another_value}')\n",
        "      # для остальных договоров берем срез приложений с start_idx по end_idx\n",
        "      else:\n",
        "        for app in applications[start_idx:end_idx]:\n",
        "          keys.append(f'{contract}_{app}_{another_value}')\n",
        "\n",
        "  return keys"
      ],
      "metadata": {
        "id": "sipzfCkzAosI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция создания ключей с логикой разделения через \";\""
      ],
      "metadata": {
        "id": "DqT1yCG8-kV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_keys2(contracts, applications, another):\n",
        "\n",
        "  # приводим данные к строчному типу\n",
        "  contracts = str(contracts)\n",
        "  applications = str(applications)\n",
        "\n",
        "  # убираем пробелы\n",
        "  contracts = contracts.replace(' ', '').replace(';', ',')\n",
        "  applications = applications.replace(' ', '')\n",
        "\n",
        "  # формируем списки\n",
        "  contracts = contracts.split(',')\n",
        "  applications = applications.split(';')\n",
        "\n",
        "  # формируем список с группами приложений (каждая группа - список, т.е. получаем список списков)\n",
        "  app_list = [[str(num.strip()) for num in lst.split(',')] for lst in applications]\n",
        "\n",
        "  # это третий аргумент для любого столбца, ячейки которого содержат одно значение\n",
        "  another_value = str(another).strip()\n",
        "\n",
        "  # сюда будем складывать найденные ключи\n",
        "  keys = []\n",
        "\n",
        "  # обрабатываем каждую пару \"договор - группа приложений\"\n",
        "  for contract, application_list in zip(contracts, app_list):\n",
        "    for application in application_list:\n",
        "      key = f'{contract}_{application}_{another_value}'\n",
        "      keys.append(key)\n",
        "\n",
        "  return keys"
      ],
      "metadata": {
        "id": "2bt6xzmcnGLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def generate_keys_auto(contracts, applications, another):\n",
        "#     contracts = str(contracts)\n",
        "#     contracts = contracts.replace(',', ';')\n",
        "#     # Автоматический вызов нужной функции\n",
        "#     if ';' in contracts:\n",
        "#         return generate_keys2(contracts, applications, another)\n",
        "#     else:\n",
        "#         return generate_keys(contracts, applications, another)"
      ],
      "metadata": {
        "id": "56SwqfsLp40A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция соединения данных"
      ],
      "metadata": {
        "id": "jISPQtv3RM4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dfs_merge(df_fca_start, df_fca, df_sap):\n",
        "\n",
        "  # шаг 1 - ищем соответствие по id\n",
        "  print('\\033[1mШаг первый:\\033[0m')\n",
        "\n",
        "  # копируем исходные реестры во избежание изменений в них\n",
        "  df_step_one = df_fca.copy()\n",
        "  sap_exp_one = df_sap.copy()\n",
        "\n",
        "  # комбинация ключа Д + П + id, попутно форматирование\n",
        "  df_step_one.loc[:, 'Ключ'] = df_step_one.apply(\n",
        "      lambda row: generate_keys(\n",
        "          contracts_processing(row['Договор']),\n",
        "          app_nums_processing(row['Номер приложения']),\n",
        "          row['Код']\n",
        "          ),\n",
        "      axis=1\n",
        "      )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  df_step_one = df_step_one.explode('Ключ').reset_index(drop=True)\n",
        "\n",
        "  # добавляем номер ключа\n",
        "  df_step_one['Номер ключа'] = df_step_one.groupby('Индекс перевозки').cumcount() + 1\n",
        "\n",
        "  # добавляем возможность фильтрации ключей\n",
        "  df_step_one['Фильтр'] = df_step_one['Индекс перевозки'].astype(str) + '_' + df_step_one['Номер ключа'].astype(str)\n",
        "\n",
        "  # считаем для каждой строки кол-во раз, которое встречается ключ по ней в таблице\n",
        "  df_step_one['Маркер Y'] = df_step_one['Ключ'].map(df_step_one['Ключ'].value_counts())\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  df_step_one = df_step_one[['Индекс перевозки', 'Ключ', 'Номер ключа', 'Фильтр', 'Маркер Y']]\n",
        "  df_step_one = df_step_one.drop_duplicates()\n",
        "\n",
        "  # комбинация ключа Д + П + id, попутно форматирование\n",
        "  sap_exp_one.loc[:, 'Ключ'] = sap_exp_one.apply(\n",
        "      lambda row: [\n",
        "          key for val in [extract_code(row[col]) for col in ['ТС: №ТранспДок', 'ТС: №ТранспСр-ва',\n",
        "                                                             'ТС: №ЕдОбр']]\n",
        "          for key in generate_keys(\n",
        "              contracts_processing(row['ЮрНомер договора на поставку']),\n",
        "              app_nums_processing(row['№ приложения к договору']),\n",
        "              val\n",
        "          )\n",
        "      ],\n",
        "      axis=1\n",
        "  )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  sap_exp_one = sap_exp_one.explode('Ключ')\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  sap_exp_one = sap_exp_one[['Ключ', 'Номер документа (сч.ф)', 'Дата проводки']]\n",
        "  sap_exp_one = sap_exp_one.drop_duplicates()\n",
        "\n",
        "  # соединяем по ключам итоговый на первом шаге датафрейм\n",
        "  df_step_one = df_step_one.merge(sap_exp_one, how='left', on='Ключ')\n",
        "\n",
        "  # сч.ф., которые найти не получилось, будем искать на дальнейших итерациях\n",
        "  df_step_one = df_step_one[~df_step_one['Номер документа (сч.ф)'].isna()]\n",
        "\n",
        "  # удаляем ключи с Nan на конце\n",
        "  df_step_one = df_step_one[~df_step_one['Ключ'].str.lower().str.endswith('none')]\n",
        "\n",
        "  # создаем список отработанных значений-фильтров\n",
        "  # это значит, что такие индексы ключа для каждой строки больше не будут проверяться, т.к. была найдена сч.ф.\n",
        "  filter = list(df_step_one['Фильтр'])\n",
        "\n",
        "  print('Длина полученного датафрейма, ключ - id:', len(df_step_one))\n",
        "\n",
        "  # кол-во задействованных на шаге индексов\n",
        "  first_step_len = df_step_one['Индекс перевозки'].nunique()\n",
        "  # кол-во задействованных накопительным итогом индексов\n",
        "  sum_len = first_step_len\n",
        "\n",
        "  # тип соединения\n",
        "  df_step_one['Тип соединения'] = 'по договору + приложению + id'\n",
        "\n",
        "  # кол-во найденных на первой итерации уникальных сч.ф.\n",
        "  num_one = df_step_one['Номер документа (сч.ф)'].nunique()\n",
        "\n",
        "  print('Кол-во использованных индексов:', first_step_len)\n",
        "  print('Кол-во найденных сч.ф.:', num_one)\n",
        "  print('Кол-во строк, которые осталось найти:', len(fca)-sum_len)\n",
        "  print('Кол-во найденных строк накопительным итогом:', sum_len)\n",
        "  print('% нахождения накопительным итогом:', round(sum_len / len(fca) * 100, 2))\n",
        "  print('\\033[1m----------------------------------------\\033[0m')\n",
        "\n",
        "  # шаг 2 - ищем соответствие по договору + приложению + ТТН\n",
        "  print('\\033[1mШаг второй:\\033[0m')\n",
        "\n",
        "  # копируем исходные реестры во избежание изменений в них\n",
        "  df_step_two = df_fca.copy()\n",
        "  sap_exp_two = df_sap.copy()\n",
        "\n",
        "  # форматируем датафрейм FCA\n",
        "  df_step_two.loc[:, 'Ключ'] = df_step_two.apply(\n",
        "      lambda row: generate_keys(\n",
        "          contracts_processing(row['Договор']),\n",
        "          app_nums_processing(row['Номер приложения']),\n",
        "          transport_invoice(row['№ТН'])\n",
        "          ),\n",
        "      axis=1\n",
        "      )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  df_step_two = df_step_two.explode('Ключ').reset_index(drop=True)\n",
        "\n",
        "  # добавляем номер ключа\n",
        "  df_step_two['Номер ключа'] = df_step_two.groupby('Индекс перевозки').cumcount() + 1\n",
        "\n",
        "  # добавляем возможность фильтрации ключей\n",
        "  df_step_two['Фильтр'] = df_step_two['Индекс перевозки'].astype(str) + '_' + df_step_two['Номер ключа'].astype(str)\n",
        "\n",
        "  # считаем для каждой строки кол-во раз, которое встречается ключ по ней в таблице\n",
        "  df_step_two['Маркер Y'] = df_step_two['Ключ'].map(df_step_two['Ключ'].value_counts())\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  df_step_two = df_step_two[['Индекс перевозки', 'Ключ', 'Номер ключа', 'Фильтр', 'Маркер Y']]\n",
        "  df_step_two = df_step_two.drop_duplicates()\n",
        "\n",
        "  # форматируем копию датафрейма SAP, созданную для второго шага\n",
        "  sap_exp_two.loc[:, 'Ключ'] = sap_exp_two.apply(\n",
        "      lambda row: [\n",
        "          key for val in [transport_invoice(row[col]) for col in ['ТС: №ТранспДок', 'ТС: №ТранспСр-ва']]\n",
        "          for key in generate_keys(\n",
        "              contracts_processing(row['ЮрНомер договора на поставку']),\n",
        "              app_nums_processing(row['№ приложения к договору']),\n",
        "              val\n",
        "          )\n",
        "      ],\n",
        "      axis=1\n",
        "  )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  sap_exp_two = sap_exp_two.explode('Ключ')\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  sap_exp_two = sap_exp_two[['Ключ', 'Номер документа (сч.ф)', 'Дата проводки']]\n",
        "  sap_exp_two = sap_exp_two.drop_duplicates()\n",
        "\n",
        "  # соединяем по ключам итоговый на втором шаге датафрейм\n",
        "  df_step_two = df_step_two.merge(sap_exp_two, how='left', on='Ключ')\n",
        "\n",
        "  # сч.ф., которые найти не получилось, будем искать на дальнейших итерациях\n",
        "  df_step_two = df_step_two[~df_step_two['Номер документа (сч.ф)'].isna()]\n",
        "\n",
        "  # удаляем ключи с Nan на конце\n",
        "  df_step_two = df_step_two[~df_step_two['Ключ'].str.lower().str.endswith('none')]\n",
        "\n",
        "  # выводим индексы с найденными ключами для строки из поиска\n",
        "  df_step_two = df_step_two[~df_step_two['Фильтр'].isin(filter)]\n",
        "\n",
        "  # дополняем список отработанных значений-фильтров\n",
        "  filter += list(df_step_two['Фильтр'])\n",
        "\n",
        "  print('Длина полученного датафрейма, ключ - договор + приложение + ТТН:', len(df_step_two))\n",
        "\n",
        "  # кол-во задействованных на шаге индексов\n",
        "  second_step_len = df_step_two['Индекс перевозки'].nunique()\n",
        "  # кол-во задействованных накопительным итогом индексов\n",
        "  sum_len += second_step_len\n",
        "\n",
        "  # тип соединения\n",
        "  df_step_two['Тип соединения'] = 'по договору + приложению + ТТН'\n",
        "\n",
        "  # кол-во найденных на первой итерации уникальных сч.ф.\n",
        "  num_two = df_step_two['Номер документа (сч.ф)'].nunique()\n",
        "\n",
        "  print('Кол-во использованных индексов:', second_step_len)\n",
        "  print('Кол-во найденных сч.ф.:', num_two)\n",
        "  print('Кол-во строк, которые осталось найти:', len(fca)-sum_len)\n",
        "  print('Кол-во найденных строк накопительным итогом:', sum_len)\n",
        "  print('% нахождения накопительным итогом:', round(sum_len / len(fca) * 100, 2))\n",
        "  print('\\033[1m----------------------------------------\\033[0m')\n",
        "\n",
        "  # шаг 3 - ищем соответствие по договору + приложению + номер трекера\n",
        "  print('\\033[1mШаг третий:\\033[0m')\n",
        "\n",
        "  # копируем исходные реестры во избежание изменений в них\n",
        "  df_step_three = df_fca.copy()\n",
        "  sap_exp_three = df_sap.copy()\n",
        "\n",
        "  # форматируем датафрейм FCA\n",
        "  df_step_three = df_step_three.copy()\n",
        "  df_step_three.loc[:, 'Ключ'] = df_step_three.apply(\n",
        "      lambda row: generate_keys(\n",
        "          contracts_processing(row['Договор']),\n",
        "          app_nums_processing(row['Номер приложения']),\n",
        "          tracker_number(row['Номер трекера'])\n",
        "          ),\n",
        "      axis=1\n",
        "      )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  df_step_three = df_step_three.explode('Ключ').reset_index(drop=True)\n",
        "\n",
        "  # добавляем номер ключа\n",
        "  df_step_three['Номер ключа'] = df_step_three.groupby('Индекс перевозки').cumcount() + 1\n",
        "\n",
        "  # добавляем возможность фильтрации ключей\n",
        "  df_step_three['Фильтр'] = df_step_three['Индекс перевозки'].astype(str) + '_' + df_step_three['Номер ключа'].astype(str)\n",
        "\n",
        "  # считаем для каждой строки кол-во раз, которое встречается ключ по ней в таблице\n",
        "  df_step_three['Маркер Y'] = df_step_three['Ключ'].map(df_step_three['Ключ'].value_counts())\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  df_step_three = df_step_three[['Индекс перевозки', 'Ключ', 'Номер ключа', 'Фильтр', 'Маркер Y']]\n",
        "  df_step_three = df_step_three.drop_duplicates()\n",
        "\n",
        "  # форматируем копию датафрейма SAP, созданную для третьего шага\n",
        "  sap_exp_three.loc[:, 'Ключ'] = sap_exp_three.apply(\n",
        "      lambda row: [\n",
        "          key for val in [tracker_number(row[col]) for col in ['ТС: №ТранспСр-ва', 'ТС: №ТранспДок', 'ТС: №ЕдОбр']]\n",
        "          for key in generate_keys(\n",
        "              contracts_processing(row['ЮрНомер договора на поставку']),\n",
        "              app_nums_processing(row['№ приложения к договору']),\n",
        "              val\n",
        "          )\n",
        "      ],\n",
        "      axis=1\n",
        "  )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  sap_exp_three = sap_exp_three.explode('Ключ')\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  sap_exp_three = sap_exp_three[['Ключ', 'Номер документа (сч.ф)', 'Дата проводки']]\n",
        "  sap_exp_three = sap_exp_three.drop_duplicates()\n",
        "\n",
        "  # соединяем по ключам итоговый на третьем шаге датафрейм\n",
        "  df_step_three = df_step_three.merge(sap_exp_three, how='left', on='Ключ')\n",
        "\n",
        "  # сч.ф., которые найти не получилось, будем искать на дальнейших итерациях\n",
        "  df_step_three = df_step_three[~df_step_three['Номер документа (сч.ф)'].isna()]\n",
        "\n",
        "  # # удаляем ключи с Nan на конце\n",
        "  df_step_three = df_step_three[~df_step_three['Ключ'].str.lower().str.endswith('none')]\n",
        "\n",
        "  # выводим индексы с найденными ключами для строки из поиска\n",
        "  df_step_three = df_step_three[~df_step_three['Фильтр'].isin(filter)]\n",
        "\n",
        "  # дополняем список отработанных значений-фильтров\n",
        "  filter += list(df_step_three['Фильтр'])\n",
        "\n",
        "  print('Длина полученного датафрейма, ключ - договор + приложение + номер трекера:', len(df_step_three))\n",
        "\n",
        "  # кол-во задействованных на шаге индексов\n",
        "  third_step_len = df_step_three['Индекс перевозки'].nunique()\n",
        "  # кол-во задействованных накопительным итогом индексов\n",
        "  sum_len += third_step_len\n",
        "\n",
        "  # тип соединения\n",
        "  df_step_three['Тип соединения'] = 'по договору + приложению + номеру трекера'\n",
        "\n",
        "  # кол-во найденных на первой итерации уникальных сч.ф.\n",
        "  num_three = df_step_three['Номер документа (сч.ф)'].nunique()\n",
        "\n",
        "  print('Кол-во использованных индексов:', third_step_len)\n",
        "  print('Кол-во найденных сч.ф.:', num_three)\n",
        "  print('Кол-во строк, которые осталось найти:', len(fca)-sum_len)\n",
        "  print('Кол-во найденных строк накопительным итогом:', sum_len)\n",
        "  print('% нахождения накопительным итогом:', round(sum_len / len(fca) * 100, 2))\n",
        "  print('\\033[1m----------------------------------------\\033[0m')\n",
        "\n",
        "  # шаг 4 - ищем соответствие по договору + приложению + номер ТС\n",
        "  print('\\033[1mШаг четвертый:\\033[0m')\n",
        "\n",
        "  # копируем исходные реестры во избежание изменений в них\n",
        "  df_step_four = df_fca.copy()\n",
        "  sap_exp_four = df_sap.copy()\n",
        "\n",
        "  # форматируем датафрейм FCA\n",
        "  df_step_four = df_step_four.copy()\n",
        "  df_step_four.loc[:, 'Ключ'] = df_step_four.apply(\n",
        "      lambda row: generate_keys(\n",
        "          contracts_processing(row['Договор']),\n",
        "          app_nums_processing(row['Номер приложения']),\n",
        "          transport_number(row['Номер ТС / накладной'])\n",
        "          ),\n",
        "      axis=1\n",
        "      )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  df_step_four = df_step_four.explode('Ключ').reset_index(drop=True)\n",
        "\n",
        "  # добавляем номер ключа\n",
        "  df_step_four['Номер ключа'] = df_step_four.groupby('Индекс перевозки').cumcount() + 1\n",
        "\n",
        "  # добавляем возможность фильтрации ключей\n",
        "  df_step_four['Фильтр'] = df_step_four['Индекс перевозки'].astype(str) + '_' + df_step_four['Номер ключа'].astype(str)\n",
        "\n",
        "  # считаем для каждой строки кол-во раз, которое встречается ключ по ней в таблице\n",
        "  df_step_four['Маркер Y'] = df_step_four['Ключ'].map(df_step_four['Ключ'].value_counts())\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  df_step_four = df_step_four[['Индекс перевозки', 'Ключ', 'Номер ключа', 'Фильтр', 'Маркер Y']]\n",
        "  df_step_four = df_step_four.drop_duplicates()\n",
        "\n",
        "  # форматируем копию датафрейма SAP, созданную для четвертого шага\n",
        "  sap_exp_four.loc[:, 'Ключ'] = sap_exp_four.apply(\n",
        "      lambda row: [\n",
        "          key for val in [transport_number(row[col]) for col in ['ТС: №ТранспСр-ва', 'ТС: №ТранспДок']]\n",
        "          for key in generate_keys(\n",
        "              contracts_processing(row['ЮрНомер договора на поставку']),\n",
        "              app_nums_processing(row['№ приложения к договору']),\n",
        "              val\n",
        "          )\n",
        "      ],\n",
        "      axis=1\n",
        "      )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  sap_exp_four = sap_exp_four.explode('Ключ')\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  sap_exp_four = sap_exp_four[['Ключ', 'Номер документа (сч.ф)', 'Дата проводки']]\n",
        "  sap_exp_four = sap_exp_four.drop_duplicates()\n",
        "\n",
        "  # соединяем по ключам итоговый на четвертом шаге датафрейм\n",
        "  df_step_four = df_step_four.merge(sap_exp_four, how='left', on='Ключ')\n",
        "\n",
        "  # сч.ф., которые найти не получилось, будем искать на дальнейших итерациях\n",
        "  df_step_four = df_step_four[~df_step_four['Номер документа (сч.ф)'].isna()]\n",
        "\n",
        "  # # удаляем ключи с Nan на конце\n",
        "  df_step_four = df_step_four[~df_step_four['Ключ'].str.lower().str.endswith('none')]\n",
        "\n",
        "  # выводим индексы с найденными ключами для строки из поиска\n",
        "  df_step_four = df_step_four[~df_step_four['Фильтр'].isin(filter)]\n",
        "\n",
        "  # дополняем список отработанных значений-фильтров\n",
        "  filter += list(df_step_four['Фильтр'])\n",
        "\n",
        "  print('Длина полученного датафрейма, ключ - договор + приложение + номер ТС:', len(df_step_four))\n",
        "\n",
        "  # кол-во задействованных на шаге индексов\n",
        "  fourth_step_len = df_step_four['Индекс перевозки'].nunique()\n",
        "  # кол-во задействованных накопительным итогом индексов\n",
        "  sum_len += fourth_step_len\n",
        "\n",
        "  # тип соединения\n",
        "  df_step_four['Тип соединения'] = 'по договору + приложению + номеру ТС'\n",
        "\n",
        "  # кол-во найденных на четвертой итерации уникальных сч.ф.\n",
        "  num_four = df_step_four['Номер документа (сч.ф)'].nunique()\n",
        "\n",
        "  print('Кол-во использованных индексов:', fourth_step_len)\n",
        "  print('Кол-во найденных сч.ф.:', num_four)\n",
        "  print('Кол-во строк, которые осталось найти:', len(fca)-sum_len)\n",
        "  print('Кол-во найденных строк накопительным итогом:', sum_len)\n",
        "  print('% нахождения накопительным итогом:', round(sum_len / len(fca) * 100, 2))\n",
        "  print('\\033[1m----------------------------------------\\033[0m')\n",
        "\n",
        "  # шаг 5 - ищем соответствие по договору + приложению + дата отправки ТС\n",
        "  print('\\033[1mШаг пятый:\\033[0m')\n",
        "\n",
        "  # копируем исходные реестры во избежание изменений в них\n",
        "  df_step_five = df_fca.copy()\n",
        "  sap_exp_five = df_sap.copy()\n",
        "\n",
        "  # форматируем датафрейм FCA\n",
        "  df_step_five = df_step_five.copy()\n",
        "  df_step_five.loc[:, 'Ключ'] = df_step_five.apply(\n",
        "      lambda row: generate_keys(\n",
        "          contracts_processing(row['Договор']),\n",
        "          app_nums_processing(row['Номер приложения']),\n",
        "          row['Дата отгрузки ФАКТ']\n",
        "          ),\n",
        "      axis=1\n",
        "      )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  df_step_five = df_step_five.explode('Ключ').reset_index(drop=True)\n",
        "\n",
        "  # добавляем номер ключа\n",
        "  df_step_five['Номер ключа'] = df_step_five.groupby('Индекс перевозки').cumcount() + 1\n",
        "\n",
        "  # добавляем возможность фильтрации ключей\n",
        "  df_step_five['Фильтр'] = df_step_five['Индекс перевозки'].astype(str) + '_' + df_step_five['Номер ключа'].astype(str)\n",
        "\n",
        "  # считаем для каждой строки кол-во раз, которое встречается ключ по ней в таблице\n",
        "  df_step_five['Маркер Y'] = df_step_five['Ключ'].map(df_step_five['Ключ'].value_counts())\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  df_step_five = df_step_five[['Индекс перевозки', 'Ключ', 'Номер ключа', 'Фильтр', 'Маркер Y']]\n",
        "  df_step_five = df_step_five.drop_duplicates()\n",
        "\n",
        "  # форматируем копию датафрейма SAP, созданную для пятого шага\n",
        "  sap_exp_five.loc[:, 'Ключ'] = sap_exp_five.apply(\n",
        "      lambda row: generate_keys(\n",
        "          contracts_processing(row['ЮрНомер договора на поставку']),\n",
        "          app_nums_processing(row['№ приложения к договору']),\n",
        "          row['ТС: Дата отправки']\n",
        "          ),\n",
        "      axis=1\n",
        "      )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  sap_exp_five = sap_exp_five.explode('Ключ')\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  sap_exp_five = sap_exp_five[['Ключ', 'Номер документа (сч.ф)', 'Дата проводки']]\n",
        "  sap_exp_five = sap_exp_five.drop_duplicates()\n",
        "\n",
        "  # соединяем по ключам итоговый на пятом шаге датафрейм\n",
        "  df_step_five = df_step_five.merge(sap_exp_five, how='left', on='Ключ')\n",
        "\n",
        "  # удаляем ключи с Nan на конце\n",
        "  df_step_five = df_step_five[~df_step_five['Ключ'].str.lower().str.endswith('none')]\n",
        "\n",
        "  # выводим индексы с найденными ключами для строки из поиска\n",
        "  df_step_five = df_step_five[~df_step_five['Фильтр'].isin(filter)]\n",
        "\n",
        "  # дополняем список отработанных значений-фильтров\n",
        "  filter += list(df_step_five['Фильтр'])\n",
        "\n",
        "  print('Длина полученного датафрейма, ключ - договор + приложение + дата отправки ТС:', len(df_step_five))\n",
        "\n",
        "  # кол-во задействованных на шаге индексов\n",
        "  fifth_step_len = df_step_five.loc[df_step_five['Номер документа (сч.ф)'].notna(), 'Индекс перевозки'].nunique()\n",
        "  # кол-во задействованных накопительным итогом индексов\n",
        "  sum_len += fifth_step_len\n",
        "\n",
        "  # тип соединения\n",
        "  df_step_five['Тип соединения'] = 'по договору + приложению + дате отправки ТС'\n",
        "\n",
        "  # кол-во найденных на пятой итерации уникальных сч.ф.\n",
        "  num_five = df_step_five['Номер документа (сч.ф)'].nunique()\n",
        "\n",
        "  print('Кол-во использованных индексов:', fifth_step_len)\n",
        "  print('Кол-во найденных сч.ф.:', num_five)\n",
        "  print('Кол-во строк, которые осталось найти:', len(fca)-sum_len)\n",
        "  print('Кол-во найденных строк накопительным итогом:', sum_len)\n",
        "  print('% нахождения накопительным итогом:', round(sum_len / len(fca) * 100, 2))\n",
        "  print('\\033[1m----------------------------------------\\033[0m')\n",
        "\n",
        "  print('\\033[1mИТОГО:\\033[0m')\n",
        "\n",
        "  # соединяем найденные на предыдущих шагах датафреймы\n",
        "  res = pd.concat([df_step_one, df_step_two, df_step_three, df_step_four, df_step_five], axis=0, ignore_index=True)\n",
        "\n",
        "  # сортируем по индексам строк и индексам ключей в строках для корректного порядке при нахождении сч.ф.\n",
        "  res = res.sort_values(by=['Индекс перевозки', 'Номер ключа'])\n",
        "\n",
        "  # смотрим по каким ключам сколько соединилось строк\n",
        "  print(\n",
        "      res.groupby('Тип соединения')['Номер документа (сч.ф)']\n",
        "       .size()\n",
        "       .reset_index(name='Кол-во строк')\n",
        "       .sort_values(by='Кол-во строк', ascending=False)\n",
        "       .reset_index(drop=True)\n",
        "       )\n",
        "\n",
        "\n",
        "  # создаем таблицу с индексами и сч.ф., которую будем цеплять к исходному реестру FCA, попутно меняет float на int\n",
        "  res = res.groupby(['Индекс перевозки', 'Маркер Y'], sort=False).agg({\n",
        "    'Номер документа (сч.ф)': lambda x: [int(val) if pd.notna(val) else val for val in x],\n",
        "    'Дата проводки': 'max'\n",
        "    }).reset_index()\n",
        "\n",
        "  # окончательно схлопываем строки (из наличия маркера Y некоторые строки задублировались)\n",
        "  res = res.groupby('Индекс перевозки').agg({\n",
        "    'Маркер Y': 'sum',  # сумма по повтору\n",
        "    'Номер документа (сч.ф)': 'sum',  # объединение списков\n",
        "    'Дата проводки': 'max' # дата самой поздней СФ для расчета месяца оприходования поставки\n",
        "    }).reset_index()\n",
        "\n",
        "  # переименовываем столбец последней проводки\n",
        "  res = res.rename(columns={'Дата проводки': 'Дата последней проводки'})\n",
        "\n",
        "  # цепляем к реестру FCA найденные сч.ф.\n",
        "  result = df_fca_start.merge(res, how='left', on='Индекс перевозки')\n",
        "\n",
        "  print('\\033[1m----------------------------------------\\033[0m')\n",
        "\n",
        "  # общее кол-во найденных сч.ф.\n",
        "  invoices = res.explode('Номер документа (сч.ф)')\n",
        "  n = invoices['Номер документа (сч.ф)'].nunique()\n",
        "  print(f'\\033[1mОбщее кол-во найденных сч.ф.:\\033[0m {n}')\n",
        "  print(f'\\033[1m% найденных строк\\033[0m {round(sum_len / len(fca) * 100, 2)}')\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "qs9fAkraRLyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка и предобработка данных"
      ],
      "metadata": {
        "id": "FfquPgt__ufo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка данных"
      ],
      "metadata": {
        "id": "XpxLWai147-9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYTIdF-W_jbe",
        "outputId": "df4f5830-0a2a-4ffd-a334-d39628b08e22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Длина FCA: 1932\n",
            "Длина SAP 519: 3229\n",
            "Длина SAP 519 ЭД: 8184\n"
          ]
        }
      ],
      "source": [
        "# загрузка данных\n",
        "fca = pd.read_excel('Реестр май FCA АТС 2025.xlsx', usecols=[\n",
        "    'Код',\n",
        "    'Дата отгрузки ФАКТ',\n",
        "    'Номер приложения',\n",
        "    'Договор',\n",
        "    'Номер ТС / накладной',\n",
        "    'Номер трекера',\n",
        "    'Ставка перевозчика с НДС, руб',\n",
        "    '№ТН'\n",
        "    ])\n",
        "\n",
        "sap_519 = pd.read_excel('май 519.XLSX', usecols = [\n",
        "# sap_519 = pd.read_excel('EXPORT 519 FULL.XLSX', usecols = [\n",
        "    'ЮрНомер договора на поставку',\n",
        "    '№ приложения к договору',\n",
        "    'Номер документа (сч.ф)',\n",
        "    'ТС: №ТранспСр-ва',\n",
        "    'ТС: №ТранспДок',\n",
        "    'ТС: Дата отправки',\n",
        "    'ТС: №ЕдОбр',\n",
        "    'Поставка',\n",
        "    'Статус документа счета',\n",
        "    'Дата поступл.ТМЦ',\n",
        "    'Документы проверены',\n",
        "    'Дата создания СчФ',\n",
        "    'Дата ввода',\n",
        "    'Дата проводки'\n",
        "    ])\n",
        "\n",
        "sap_519_ed = pd.read_excel('май 519 ЭД.XLSX', usecols=[\n",
        "    'ЮрНомер договора на поставку',\n",
        "    '№ приложения к договору',\n",
        "    'Номер документа (сч.ф)',\n",
        "    'ТС: №ТранспСр-ва',\n",
        "    'ТС: №ТранспДок',\n",
        "    'ТС: Дата отправки',\n",
        "    'ТС: №ЕдОбр',\n",
        "    'Счет-фактура',\n",
        "    'Поставка',\n",
        "    'Статус документа счета',\n",
        "    'Дата поступл.ТМЦ',\n",
        "    'Документы проверены',\n",
        "    'Дата создания СчФ',\n",
        "    'Дата ввода',\n",
        "    'Дата проводки'\n",
        "])\n",
        "\n",
        "sap_521 = pd.read_excel('май 521.XLSX')\n",
        "\n",
        "logs = pd.read_excel('Логи_Май.xlsx')\n",
        "\n",
        "print('Длина FCA:', len(fca))\n",
        "print('Длина SAP 519:', len(sap_519))\n",
        "print('Длина SAP 519 ЭД:', len(sap_519_ed))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выбор периода для расчета"
      ],
      "metadata": {
        "id": "WqFXzxzoe5sP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# строго\n",
        "period = input('Выберите период формирования файлов (введите МЕСЯЦ или ГОД): ').strip().lower()\n",
        "\n",
        "# контроль\n",
        "if period == 'год':\n",
        "  print('Выбранный период - ГОД')\n",
        "elif period == 'месяц':\n",
        "  print('ВЫбранный период - Месяц')\n",
        "else:\n",
        "  raise ValueError(f'❌ Неизвестный период: {period}. Допустимые значения: МЕСЯЦ, ГОД')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWKJDNNeYtRj",
        "outputId": "b150ab7d-0c98-4da7-90d2-1a18151accbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Выберите период формирования файлов (введите МЕСЯЦ или ГОД): год\n",
            "Выбранный период - ГОД\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# выбор месяца (при необходимости)\n",
        "if period == 'месяц':\n",
        "  month = input('Выберите МЕСЯЦ: ').strip().lower()\n",
        "\n",
        "  if month == 'январь':\n",
        "    mm = '02'\n",
        "  elif month == 'февраль':\n",
        "    mm = '03'\n",
        "  elif month == 'март':\n",
        "    mm = '04'\n",
        "  elif month == 'апрель':\n",
        "    mm = '05'\n",
        "  elif month == 'май':\n",
        "    mm = '06'\n",
        "  elif month == 'июнь':\n",
        "    mm = '07'\n",
        "  elif month == 'июль':\n",
        "    mm = '08'\n",
        "  elif month == 'август':\n",
        "    mm = '09'\n",
        "  elif month == 'сентябрь':\n",
        "    mm = '10'\n",
        "  elif month == 'октябрь':\n",
        "    mm = '11'\n",
        "  elif month == 'ноябрь':\n",
        "    mm = '12'\n",
        "  elif month == 'декабрь':\n",
        "    mm = '01'\n",
        "  else:\n",
        "    raise ValueError(f'❌ Ошибка при выборе месяца: {month}. Необходимо полностью и корректно ввести месяц')\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "eLWjExb0fT4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'месяц':\n",
        "\n",
        "  # исключаем данные за следующий месяц\n",
        "  fca = fca[~(fca['Код'].str[2:4] == mm)]\n",
        "  print('Длина после перепроверки FCA:', len(fca))\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "-Lfo-Q4Vg49Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# добавляем индекс каждой строке реестра FCA\n",
        "fca.insert(0, 'Индекс перевозки', np.arange(0, len(fca)))"
      ],
      "metadata": {
        "id": "35qoERFy9ZPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# поля, которые блок FCA должен заполнить данными\n",
        "cols_revision = [\n",
        "    'Код',\n",
        "    'Договор',\n",
        "    'Номер приложения',\n",
        "    'Дата отгрузки ФАКТ',\n",
        "    'Ставка перевозчика с НДС, руб'\n",
        "    ]\n",
        "\n",
        "# таблица, которая будет направлена блоку FCA на дозаполнение\n",
        "fca_revision = fca[fca[cols_revision].isnull().any(axis=1)]"
      ],
      "metadata": {
        "id": "FekeWxie6X9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преобразование выгрузки SAP 519"
      ],
      "metadata": {
        "id": "5LqfUpcqHEjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# корректировка сч.ф. в выгрузке SAP 519 ЭД\n",
        "mask = sap_519_ed['Номер документа (сч.ф)'] == 1\n",
        "sap_519_ed.loc[mask, 'Номер документа (сч.ф)'] = sap_519_ed.loc[mask, 'Счет-фактура']\n",
        "\n",
        "# данный столбец более не нужен, удаляем его\n",
        "sap_519_ed = sap_519_ed.drop('Счет-фактура', axis=1)\n",
        "\n",
        "# приводим в единый вид выгрузки SAP 519 и SAP 519 ЭД, должен соблюдаться порядок столбцов\n",
        "sap_519 = sap_519[[\n",
        "    'ЮрНомер договора на поставку',\n",
        "    '№ приложения к договору',\n",
        "    'ТС: Дата отправки',\n",
        "    'Номер документа (сч.ф)',\n",
        "    'ТС: №ЕдОбр',\n",
        "    'ТС: №ТранспДок',\n",
        "    'ТС: №ТранспСр-ва',\n",
        "    'Поставка',\n",
        "    'Статус документа счета',\n",
        "    'Дата поступл.ТМЦ',\n",
        "    'Документы проверены',\n",
        "    'Дата создания СчФ',\n",
        "    'Дата ввода',\n",
        "    'Дата проводки'\n",
        "    ]]\n",
        "\n",
        "sap_519_ed = sap_519_ed[[\n",
        "    'ЮрНомер договора на поставку',\n",
        "    '№ приложения к договору',\n",
        "    'ТС: Дата отправки',\n",
        "    'Номер документа (сч.ф)',\n",
        "    'ТС: №ЕдОбр',\n",
        "    'ТС: №ТранспДок',\n",
        "    'ТС: №ТранспСр-ва',\n",
        "    'Поставка',\n",
        "    'Статус документа счета',\n",
        "    'Дата поступл.ТМЦ',\n",
        "    'Документы проверены',\n",
        "    'Дата создания СчФ',\n",
        "    'Дата ввода',\n",
        "    'Дата проводки'\n",
        "    ]]\n",
        "\n",
        "# соединяем реестры SAP по вертикали\n",
        "sap_519_full = pd.concat([sap_519, sap_519_ed], axis=0, ignore_index=True)\n",
        "\n",
        "# избавляемся от всех строк SAP 519, где нет СФ\n",
        "sap_519_full = sap_519_full[sap_519_full['Номер документа (сч.ф)'].notna()]\n",
        "\n",
        "# добавляем статус проводки\n",
        "sap_519_full['Статус проводки СФ'] = sap_519_full.apply(colors, axis=1)\n",
        "\n",
        "# приводим столбец статуса документов в единый регистр\n",
        "sap_519_full['Документы проверены'] = sap_519_full['Документы проверены'].str.lower()\n",
        "\n",
        "# меняем тип данных на текстовый\n",
        "# это дополнительная мера, т.к. тип данных в любом случае меняется внутри функций\n",
        "cols_fca_str = ['Номер ТС / накладной', 'Номер приложения', 'Номер трекера', '№ТН']\n",
        "for col in cols_fca_str:\n",
        "  fca[col] = fca[col].where(fca[col].isna(), fca[col].astype('str'))\n",
        "\n",
        "cols_sap_str = [\n",
        "    'ТС: №ТранспСр-ва',\n",
        "    'ТС: №ТранспДок',\n",
        "    'ТС: №ЕдОбр',\n",
        "    'ЮрНомер договора на поставку',\n",
        "    '№ приложения к договору',\n",
        "    ]\n",
        "for col in cols_sap_str:\n",
        "  sap_519_full[col] = sap_519_full[col].where(sap_519_full[col].isna(), sap_519_full[col].astype('str'))\n",
        "\n",
        "# на всякий случай присваиваем СФ тип данных int\n",
        "sap_519_full['Номер документа (сч.ф)'] = sap_519_full['Номер документа (сч.ф)'].astype(int)\n",
        "\n",
        "# будущий ключ SAP 519 приводим к целочисленному типу данных\n",
        "sap_519_full['Поставка'] = pd.to_numeric(sap_519_full['Поставка'], errors='coerce')\n",
        "sap_519_full['Поставка'] = sap_519_full['Поставка'].astype('Int64')\n",
        "\n",
        "# избавляемся от лишних скобок в поле id\n",
        "fca['Код'] = fca['Код'].str.replace(r'[{}]', '', regex=True)\n",
        "\n",
        "# преобразуем поля из текствого формата в списки\n",
        "col_list = ['ТС: №ТранспСр-ва', 'ТС: №ТранспДок', 'ТС: №ЕдОбр']\n",
        "sap_519_full[col_list] = sap_519_full[col_list].applymap(\n",
        "    lambda x: [item.strip() for item in x.split(',')] if pd.notna(x) else []\n",
        ")\n",
        "\n",
        "# растаскиваем по строкам\n",
        "sap_519_exp = sap_519_full.explode('ТС: №ТранспСр-ва').explode('ТС: №ТранспДок').explode('ТС: №ЕдОбр')\n",
        "\n",
        "# чистим столбцы\n",
        "for col in col_list:\n",
        "    mask = sap_519_exp[col].str.lower() == 'нет данных'\n",
        "    sap_519_exp.loc[mask, col] = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlYFiM9S_453",
        "outputId": "14ac9324-2297-48d1-a9b8-096603e111f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-205175834.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  sap_519_ed.loc[mask, 'Номер документа (сч.ф)'] = sap_519_ed.loc[mask, 'Счет-фактура']\n",
            "/tmp/ipython-input-205175834.py:83: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  sap_519_full[col_list] = sap_519_full[col_list].applymap(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преобразование выгрузки SAP 521"
      ],
      "metadata": {
        "id": "gR0qgRo7HJ4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# избавляемся от строк без необходимого в дальнейшем ключа\n",
        "sap_521 = sap_521[sap_521['№ приходного ордера'].notna()]\n",
        "\n",
        "# будущий ключ SAP 521 приводим к типу данных float\n",
        "sap_521['№ приходного ордера'] = pd.to_numeric(sap_521['№ приходного ордера'], errors='coerce')\n",
        "\n",
        "# Прямое преобразование в int (без промежуточного float)\n",
        "sap_521['№ приходного ордера'] = sap_521['№ приходного ордера'].astype('Int64')"
      ],
      "metadata": {
        "id": "LWkAh-8MHNna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преобразование логов"
      ],
      "metadata": {
        "id": "c_4iLRkvuwUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# во избежание присоединения лишних строк из логов выделяем самые поздние для каждой СФ\n",
        "logs = logs.groupby('№ докум.')['ДатаИзм'].max().reset_index()"
      ],
      "metadata": {
        "id": "mnEHCsDquuZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# исключаем часть реестра FCA, отправленную на доработку\n",
        "fca_clean = fca[~fca['Индекс перевозки'].isin(fca_revision['Индекс перевозки'])]"
      ],
      "metadata": {
        "id": "hqTXAIFp-x3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# соединяем реестры\n",
        "df_res = dfs_merge(fca, fca_clean, sap_519_exp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28lMBpI6nlF8",
        "outputId": "023da6d1-502a-46a9-8693-cee066b7a731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mШаг первый:\u001b[0m\n",
            "Длина полученного датафрейма, ключ - id: 556\n",
            "Кол-во использованных индексов: 470\n",
            "Кол-во найденных сч.ф.: 548\n",
            "Кол-во строк, которые осталось найти: 1462\n",
            "Кол-во найденных строк накопительным итогом: 470\n",
            "% нахождения накопительным итогом: 24.33\n",
            "\u001b[1m----------------------------------------\u001b[0m\n",
            "\u001b[1mШаг второй:\u001b[0m\n",
            "Длина полученного датафрейма, ключ - договор + приложение + ТТН: 21\n",
            "Кол-во использованных индексов: 20\n",
            "Кол-во найденных сч.ф.: 21\n",
            "Кол-во строк, которые осталось найти: 1442\n",
            "Кол-во найденных строк накопительным итогом: 490\n",
            "% нахождения накопительным итогом: 25.36\n",
            "\u001b[1m----------------------------------------\u001b[0m\n",
            "\u001b[1mШаг третий:\u001b[0m\n",
            "Длина полученного датафрейма, ключ - договор + приложение + номер трекера: 91\n",
            "Кол-во использованных индексов: 57\n",
            "Кол-во найденных сч.ф.: 91\n",
            "Кол-во строк, которые осталось найти: 1385\n",
            "Кол-во найденных строк накопительным итогом: 547\n",
            "% нахождения накопительным итогом: 28.31\n",
            "\u001b[1m----------------------------------------\u001b[0m\n",
            "\u001b[1mШаг четвертый:\u001b[0m\n",
            "Длина полученного датафрейма, ключ - договор + приложение + номер ТС: 267\n",
            "Кол-во использованных индексов: 187\n",
            "Кол-во найденных сч.ф.: 220\n",
            "Кол-во строк, которые осталось найти: 1198\n",
            "Кол-во найденных строк накопительным итогом: 734\n",
            "% нахождения накопительным итогом: 37.99\n",
            "\u001b[1m----------------------------------------\u001b[0m\n",
            "\u001b[1mШаг пятый:\u001b[0m\n",
            "Длина полученного датафрейма, ключ - договор + приложение + дата отправки ТС: 1927\n",
            "Кол-во использованных индексов: 744\n",
            "Кол-во найденных сч.ф.: 835\n",
            "Кол-во строк, которые осталось найти: 454\n",
            "Кол-во найденных строк накопительным итогом: 1478\n",
            "% нахождения накопительным итогом: 76.5\n",
            "\u001b[1m----------------------------------------\u001b[0m\n",
            "\u001b[1mИТОГО:\u001b[0m\n",
            "                                Тип соединения  Кол-во строк\n",
            "0  по договору + приложению + дате отправки ТС          1927\n",
            "1                по договору + приложению + id           556\n",
            "2         по договору + приложению + номеру ТС           267\n",
            "3    по договору + приложению + номеру трекера            91\n",
            "4               по договору + приложению + ТТН            21\n",
            "\u001b[1m----------------------------------------\u001b[0m\n",
            "\u001b[1mОбщее кол-во найденных сч.ф.:\u001b[0m 1676\n",
            "\u001b[1m% найденных строк\u001b[0m 76.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Преобразование полученных данных"
      ],
      "metadata": {
        "id": "v_yawGLwhbFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# маркер Y\n",
        "\n",
        "# это метка для случая, когда M одинаковых ключей и N сч.ф.\n",
        "# т.е. проблема, что нельзя установить точное соответствие между сч.ф. и ключом\n",
        "# в идеале такое должно быть только на итерациях 4 и 5 - по номеру ТС и дате отправки\n",
        "df_res['Маркер Y'] = np.where((df_res['Маркер Y'] == 1) | (df_res['Маркер Y'].isna()), 'N', 'Y')"
      ],
      "metadata": {
        "id": "7QIjcjGjhsHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# маркер X\n",
        "\n",
        "# это проверка того, найдены ли все сч.ф. или нет\n",
        "df_res['Маркер X'] = df_res['Номер документа (сч.ф)'].apply(analyze_list)\n",
        "\n",
        "# корректируем маркер Y - не будем помечать им строки без сч.ф.\n",
        "df_res.loc[df_res['Маркер X'] == 'Не найдено ни одной сч.ф.', 'Маркер Y'] = 'N'"
      ],
      "metadata": {
        "id": "p8NHDOE8p0WW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# найденные в FCA перевозки\n",
        "df_res['Зарегистрировано'] = np.where(df_res['Маркер X'] == 'Не найдено ни одной сч.ф.', 0, 1)\n",
        "\n",
        "# не найденные в FCA перевозки\n",
        "df_res['Не найдено / Не зарегистрировано'] = np.where(df_res['Маркер X'] == 'Не найдено ни одной сч.ф.', 1, 0)"
      ],
      "metadata": {
        "id": "9ZM_DXSEXHd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# соединяем найденные СФ с выгрузками SAP 519 и SAP 521\n",
        "inv_reg = reg(df_res, sap_519_full, sap_521)"
      ],
      "metadata": {
        "id": "tz8nOWE4aJRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# оприходована ли поставка (найдены все СФ)\n",
        "df_res['Оприходование поставки'] = np.where(df_res['Маркер X'] == 'Найдены все сч.ф.', 1, 0)\n",
        "\n",
        "# указываем статус перевозки в FCA\n",
        "df_res['Статус перевозки'] = np.where(\n",
        "    df_res['Не найдено / Не зарегистрировано'] == 1,\n",
        "    'Не найдено / Не зарегистрировано',\n",
        "    np.where(df_res['Оприходование поставки'] == 1, 'Оприходовано', 'Не оприходовано')\n",
        "    )"
      ],
      "metadata": {
        "id": "Wzk8Z0dDam-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# указываем месяц реестра FCA\n",
        "df_res['Месяц'] = df_res['Дата отгрузки ФАКТ'].dt.month\n",
        "\n",
        "# словарь соответствия\n",
        "month_dict = {\n",
        "    1: 'Январь', 2: 'Февраль', 3: 'Март', 4: 'Апрель',\n",
        "    5: 'Май', 6: 'Июнь', 7: 'Июль', 8: 'Август',\n",
        "    9: 'Сентябрь', 10: 'Октябрь', 11: 'Ноябрь', 12: 'Декабрь'\n",
        "}\n",
        "\n",
        "# указываем наименование месяца реестра FCA\n",
        "df_res['Месяц наименование'] = df_res['Месяц'].map(month_dict)"
      ],
      "metadata": {
        "id": "XICvCOK267MS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# цепляем логи к списку найденных СФ\n",
        "inv_log = inv_reg.merge(logs, how='left', left_on='Номер документа (сч.ф)', right_on='№ докум.')"
      ],
      "metadata": {
        "id": "nhX3WtltcKYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# рассчитываем время проверки документов в днях\n",
        "inv_log['Время проверки документов'] = np.where(\n",
        "    inv_log['ДатаИзм'].isna(),\n",
        "    (inv_log['Дата создания СчФ'] - inv_log['ТС: Дата отправки']).dt.days,\n",
        "    (inv_log['ДатаИзм'] - inv_log['ТС: Дата отправки']).dt.days\n",
        "    ).astype(int)"
      ],
      "metadata": {
        "id": "sb3jVbWDcYmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# рассчитываем время проводки документов в днях\n",
        "inv_log['Время проводки документов'] = np.where(\n",
        "    inv_log['ДатаИзм'].isna(),\n",
        "    (inv_log['Дата ввода'] - inv_log['Дата создания СчФ']).dt.days,\n",
        "    (inv_log['Дата ввода'] - inv_log['ДатаИзм']).dt.days\n",
        "    ).astype(int)"
      ],
      "metadata": {
        "id": "1QuSgd0AcmtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# факт оприходования СФ\n",
        "inv_log['Оприходование СФ факт'] = np.where(inv_log['Оприходование СФ'].isin(['Физический склад', 'Виртуальный склад']), 1, 0)"
      ],
      "metadata": {
        "id": "_m-zctZpWPMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# виртуальный склад (да/нет)\n",
        "inv_log['Виртуальный склад'] = np.where(inv_log['Оприходование СФ'] == 'Виртуальный склад', 1, 0)\n",
        "\n",
        "# физический склад (да/нет)\n",
        "inv_log['Физический склад'] = np.where(inv_log['Оприходование СФ'] == 'Физический склад', 1, 0)"
      ],
      "metadata": {
        "id": "aTfBmX114R_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Дополнительно проверяем корректность указания id в реестре FCA"
      ],
      "metadata": {
        "id": "H8d4K3Cv33YW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# побочные датафреймы для отлавливания ошибок\n",
        "for_errors_df_one = fca_clean.copy()\n",
        "for_errors_sap_one = sap_519_exp.copy()\n",
        "\n",
        "# форматируем побочный датафрейм, по которому будем искать разночтения по id\n",
        "# на данном шаге можно использовать merge по полю \"Код\"\n",
        "# но для получения одинакого кол-ва полей у побочных датафреймов лучше использовать функцию\n",
        "for_errors_df_one['Ключ'] = for_errors_df_one.apply(\n",
        "    lambda row: generate_keys(\n",
        "        contracts_processing(row['Код']),\n",
        "        app_nums_processing(row['Код']),\n",
        "        row['Код']\n",
        "        ), axis=1\n",
        "    )\n",
        "\n",
        "# растаскиваем по строкам\n",
        "for_errors_df_one = for_errors_df_one.explode('Ключ')\n",
        "\n",
        "# форматируем побочный датафрейм, по которому будем искать разночтения по id\n",
        "for_errors_sap_one['Ключ'] = for_errors_sap_one.apply(\n",
        "    lambda row: [\n",
        "        key for val in [extract_code(row[col]) for col in ['ТС: №ТранспДок', 'ТС: №ТранспСр-ва', 'ТС: №ЕдОбр']]\n",
        "        for key in generate_keys(\n",
        "            val,\n",
        "            val,\n",
        "            val\n",
        "        )\n",
        "    ],\n",
        "    axis=1\n",
        "    )\n",
        "\n",
        "# растаскиваем по строкам\n",
        "for_errors_sap_one = for_errors_sap_one.explode('Ключ')\n",
        "\n",
        "# соединяем по ключам датафреймы для поиска ошибок\n",
        "for_errors_df_one = for_errors_df_one.merge(for_errors_sap_one, how='inner', on='Ключ')\n",
        "\n",
        "# удаляем ключи с Nan на конце\n",
        "for_errors_df_one = for_errors_df_one[~for_errors_df_one['Ключ'].str.lower().str.endswith('none')]"
      ],
      "metadata": {
        "id": "Pz-Ty_8J2Ej-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Сохраняем результат**"
      ],
      "metadata": {
        "id": "I2gZR99mj28k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# создаем в локальной директории excel-файл с финальными данными, откуда его можно будет скачать\n",
        "df_final = [df_res]\n",
        "sheet_names = ['Данные']\n",
        "excel_filename = 'Модель данных.xlsx'\n",
        "with pd.ExcelWriter(excel_filename) as writer:\n",
        "  for data, sheet in zip(df_final, sheet_names):\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_excel(writer, sheet_name=sheet, header=True)"
      ],
      "metadata": {
        "id": "19HNbKlur4uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Формирование дополнительного реестра на проверку FCA"
      ],
      "metadata": {
        "id": "fvmbKYsRuHRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ищем строки с одинаковым id и разными номерами договора\n",
        "erros_df = for_errors_df_one[\n",
        "    (for_errors_df_one['Договор'].str.strip() != for_errors_df_one['ЮрНомер договора на поставку'].str.strip()) &\n",
        "    (~for_errors_df_one['ЮрНомер договора на поставку'].fillna('').str.contains(r'[\\;\\,\\/\\\\]')) &\n",
        "    (for_errors_df_one['ЮрНомер договора на поставку'].str.count('Д') < 2) &\n",
        "    (~for_errors_df_one['Договор'].str.contains(r'[\\;\\,\\/\\\\]')) &\n",
        "    (for_errors_df_one['Договор'].str.count('Д') < 2)\n",
        "    ]\n",
        "\n",
        "erros_df = erros_df[[\n",
        "    'Договор',\n",
        "    'Номер приложения',\n",
        "    'ЮрНомер договора на поставку',\n",
        "    '№ приложения к договору'\n",
        "    ]].drop_duplicates()"
      ],
      "metadata": {
        "id": "VAvAzrD9uH6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Формирование Excel-файла на доработку FCA"
      ],
      "metadata": {
        "id": "1jflyR4TheSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# формируем файл для возврата на проверку блоку FCA\n",
        "# первый лист - не до конца заполненные обязательные данные\n",
        "# второй лист - строки, сцепившиеся по одному id, но с разными номерами договоров и приложениями; это на уточнение\n",
        "\n",
        "datasets = [fca_revision, erros_df]\n",
        "sheet_names = ['Нет данных', 'На уточнение']\n",
        "excel_filename = 'FCA реестр на проверку.xlsx'\n",
        "\n",
        "with pd.ExcelWriter(excel_filename) as writer:\n",
        "  for data, sheet in zip(datasets, sheet_names):\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_excel(writer, sheet_name=sheet, header=True, index=False)"
      ],
      "metadata": {
        "id": "w-qRiIx9fUAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Расчеты для первой страницы дашборда \"МТР в пути\" (месяц)"
      ],
      "metadata": {
        "id": "zvY0SC9RtxqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Информация о перевозках за соответствующий месяц**"
      ],
      "metadata": {
        "id": "_wXexRx4Vbev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'месяц':\n",
        "\n",
        "  # кол-во найденных перевозок\n",
        "  fnd_tr = sum(df_res['Зарегистрировано'])\n",
        "\n",
        "  # кол-во не найденных перевозок\n",
        "  nt_fnd_tr = sum(df_res['Не найдено / Не зарегистрировано'])\n",
        "\n",
        "  print(f'Общее кол-во перевозок FCA: {len(fca)} шт.;')\n",
        "  print(f'Возвращено на доработку: {len(fca_revision)} шт., {round(len(fca_revision) / len(fca) * 100, 2)} %;')\n",
        "  print('')\n",
        "  print(f'Зарегистрировано: {fnd_tr} шт., {round(fnd_tr / len(fca) * 100, 2)} %;')\n",
        "  print(f'Не найдено / Не зарегистрировано: {nt_fnd_tr} шт., {round(nt_fnd_tr / len(fca) * 100, 2)} %;')\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "rsOeI4JaVcA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Определение категории оприходования СФ**"
      ],
      "metadata": {
        "id": "Xnv3BtN1-aai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'месяц':\n",
        "\n",
        "  # статусы оприходования по СФ\n",
        "  print(inv_log.groupby('Оприходование СФ')['Номер документа (сч.ф)'].nunique().reset_index(name='Кол-во СФ'))\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "Vg_FfzpRvB1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Статусы СФ по документам зарегистрированных в SAP поставок**"
      ],
      "metadata": {
        "id": "ZRsKRvXsSCUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'месяц':\n",
        "\n",
        "  # фиксируем получение статусов проверки документов для отражения в дашборде\n",
        "  print(inv_log.groupby('Документы проверены')['Номер документа (сч.ф)'].nunique().reset_index(name='Кол-во СФ'))\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "B3EplaHhR6kW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Расчет стоимости перевозок по оприходованным МТР**"
      ],
      "metadata": {
        "id": "6-TMWWUTcBsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'месяц':\n",
        "\n",
        "  # суммарная стоимость перевозок, руб\n",
        "  print(\n",
        "      df_res.groupby('Статус перевозки')['Ставка перевозчика с НДС, руб'].sum().apply(\n",
        "          lambda x: f'{x:,.0f}'.replace(',', ' ')).reset_index(name='Суммарная стоимость перевозок (с НДС), руб'\n",
        "          )\n",
        "      )\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "3muNtsq0TbWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Определение категорий времени для СФ с проверенными документами (с момента отправки ТС)**"
      ],
      "metadata": {
        "id": "ugd6ScjMNU7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'месяц':\n",
        "\n",
        "  # прописываем категории для времени проверки документов\n",
        "  choices_check = ['1.До 5 дней', '2.От 6 до 10 дней', '3.От 11 до 14 дней', '4.Более 14 дней']\n",
        "\n",
        "  # прописываем условия для определения СФ в конкретную категорию времени проверки документов\n",
        "  conditions_check = [\n",
        "      inv_log['Время проверки документов'] <= 5,\n",
        "      (inv_log['Время проверки документов'] <= 10) & (inv_log['Время проверки документов'] > 5),\n",
        "      (inv_log['Время проверки документов'] <= 14) & (inv_log['Время проверки документов'] > 10),\n",
        "      inv_log['Время проверки документов'] > 14\n",
        "  ]\n",
        "\n",
        "  # формируем признак категории для СФ\n",
        "  inv_log['Время проверки документов (группы)'] = np.select(conditions_check, choices_check, default='ПРОВЕРИТЬ!!!')\n",
        "\n",
        "  print(\n",
        "      inv_log.groupby('Время проверки документов (группы)')['Номер документа (сч.ф)'].nunique()\n",
        "  )\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "bpg3XB89C8Is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Определение категорий времени для оприходованных СФ (на склад с момента проверки документов)**"
      ],
      "metadata": {
        "id": "r6-gjZcLOBRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'месяц':\n",
        "\n",
        "  # прописываем категории для времени проводки документов\n",
        "  choices_post = ['1.Без задержек', '2.От 1 до 3 дней', '3.От 4 до 5 дней', '4.От 6 до 10 дней', '5.От 11 до 14 дней', '6.Более 14 дней']\n",
        "\n",
        "  # прописываем условия для определения СФ в конкретную категорию времени проводки документов\n",
        "  conditions_post = [\n",
        "      inv_log['Время проводки документов'] <= 0,\n",
        "      (inv_log['Время проводки документов'] <= 3) & (inv_log['Время проводки документов'] > 0),\n",
        "      (inv_log['Время проводки документов'] <= 5) & (inv_log['Время проводки документов'] > 3),\n",
        "      (inv_log['Время проводки документов'] <= 10) & (inv_log['Время проводки документов'] > 5),\n",
        "      (inv_log['Время проводки документов'] <= 14) & (inv_log['Время проводки документов'] > 10),\n",
        "      inv_log['Время проводки документов'] > 14\n",
        "  ]\n",
        "\n",
        "  # формируем признак категории для СФ\n",
        "  inv_log['Время проводки документов (группы)'] = np.select(conditions_post, choices_post, default='ПРОВЕРИТЬ!!!')\n",
        "\n",
        "  print(\n",
        "      inv_log.groupby('Время проводки документов (группы)')['Номер документа (сч.ф)'].nunique()\n",
        "  )\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "Nx7g9VHaN5p6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Сохранение результатов (месяц)**"
      ],
      "metadata": {
        "id": "MLtTl8Ju5jFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'месяц':\n",
        "\n",
        "  datasets = [df_res, inv_log]\n",
        "  sheet_names = ['FCA мес', 'SAP мес']\n",
        "  excel_filename = 'Модель данных месяц.xlsx'\n",
        "\n",
        "  with pd.ExcelWriter(excel_filename) as writer:\n",
        "    for data, sheet in zip(datasets, sheet_names):\n",
        "      df = pd.DataFrame(data)\n",
        "      df.to_excel(writer, sheet_name=sheet, header=True, index=False)\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "P4C0hGnp5mGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Расчеты для второй страницы дашборда \"МТР в пути\" (год)"
      ],
      "metadata": {
        "id": "4LL8T8-_zNoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Динамика оприходования перевозок после закрытия месяца**"
      ],
      "metadata": {
        "id": "BK-FLsSDeGiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'год':\n",
        "\n",
        "  # категории оприходования\n",
        "  fca_cat = ['В рамках месяца', 'После закрытия месяца', 'Не оприходовано']\n",
        "\n",
        "  # условия для категорий оприходования\n",
        "  fca_cond = [\n",
        "      (df_res['Оприходование поставки'] == 1) & (\n",
        "          (df_res['Дата последней проводки'].dt.month - df_res['Месяц'] == 0) | (\n",
        "              (df_res['Дата последней проводки'].dt.month - df_res['Месяц'] == 1) & (df_res['Дата последней проводки'].dt.day <= 6)\n",
        "          )\n",
        "          ),\n",
        "      (df_res['Оприходование поставки'] == 1) & (\n",
        "          (\n",
        "              (df_res['Дата последней проводки'].dt.month - df_res['Месяц'] == 1) & (df_res['Дата последней проводки'].dt.day > 6)\n",
        "              ) |\n",
        "              (df_res['Дата последней проводки'].dt.month - df_res['Месяц'] > 1)\n",
        "              ),\n",
        "      (df_res['Оприходование поставки'] == 0)\n",
        "      ]\n",
        "\n",
        "  # данный столбец нужен для определения своевременности оприходования поставки в рамках года\n",
        "  df_res['Категория оприходования'] = np.select(fca_cond, fca_cat, default='ПРОВЕРИТЬ!!!')\n",
        "\n",
        "  # в рамках месяца (да/нет)\n",
        "  df_res['В рамках месяца'] = np.where(df_res['Категория оприходования'] == 'В рамках месяца', 1, 0)\n",
        "\n",
        "  # после закрытия месяца (да/нет)\n",
        "  df_res['После закрытия месяца'] = np.where(df_res['Категория оприходования'] == 'После закрытия месяца', 1, 0)\n",
        "\n",
        "  print(\n",
        "      df_res.groupby(['Месяц наименование', 'Категория оприходования'])['Индекс перевозки'].nunique()\n",
        "  )\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "u8dvfB9BS8Qp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0baf4fb7-e00b-4876-c0b0-ce9db4754419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Месяц наименование  Категория оприходования\n",
            "Май                 В рамках месяца            999\n",
            "                    Не оприходовано            505\n",
            "                    После закрытия месяца      428\n",
            "Name: Индекс перевозки, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Стоимость перевозок по оприходованным МТР**"
      ],
      "metadata": {
        "id": "9DtsMCrieRcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'год':\n",
        "\n",
        "  # суммарная стоимость перевозок, руб\n",
        "  print(\n",
        "      df_res.groupby('Категория оприходования')['Ставка перевозчика с НДС, руб'].sum().apply(\n",
        "          lambda x: f'{x:,.0f}'.replace(',', ' ')).reset_index(name='Суммарная стоимость перевозок (с НДС), руб'\n",
        "          )\n",
        "      )\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "cduKK0WUS-OL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567a781a-f01d-4114-c1c1-c0d979e26623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Категория оприходования Суммарная стоимость перевозок (с НДС), руб\n",
            "0         В рамках месяца                                 97 915 094\n",
            "1         Не оприходовано                                 74 350 832\n",
            "2   После закрытия месяца                                 53 734 093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Оприходованные перевозки (на склад с момента отправки ТС)**"
      ],
      "metadata": {
        "id": "REgs9N2WeWJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'год':\n",
        "\n",
        "  # прописываем категории для времени оприходования перевозки\n",
        "  choices_post = ['1.До 5 дней', '2.6-10 дней', '3.11-20 дней', '4.21-30 дней', '5.Более 30 дней']\n",
        "\n",
        "  # прописываем условия для определения СФ в конкретную категорию времени проводки документов\n",
        "  conditions_post = [\n",
        "      (df_res['Дата последней проводки'] - df_res['Дата отгрузки ФАКТ']).dt.days <= 5,\n",
        "      ((df_res['Дата последней проводки'] - df_res['Дата отгрузки ФАКТ']).dt.days <= 10) & ((df_res['Дата последней проводки'] - df_res['Дата отгрузки ФАКТ']).dt.days > 5),\n",
        "      ((df_res['Дата последней проводки'] - df_res['Дата отгрузки ФАКТ']).dt.days <= 20) & ((df_res['Дата последней проводки'] - df_res['Дата отгрузки ФАКТ']).dt.days > 10),\n",
        "      ((df_res['Дата последней проводки'] - df_res['Дата отгрузки ФАКТ']).dt.days <= 30) & ((df_res['Дата последней проводки'] - df_res['Дата отгрузки ФАКТ']).dt.days > 20),\n",
        "      (df_res['Дата последней проводки'] - df_res['Дата отгрузки ФАКТ']).dt.days > 30\n",
        "  ]\n",
        "\n",
        "  # формируем признак категории для СФ\n",
        "  df_res['Оприходование поставки (категории)'] = np.select(conditions_post, choices_post, default='Не оприходовано')\n",
        "\n",
        "  print(\n",
        "      df_res.groupby('Оприходование поставки (категории)')['Оприходование поставки'].sum()\n",
        "  )\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "YUKSXUa5TC7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf4df246-67f3-4025-9db6-665557946653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Оприходование поставки (категории)\n",
            "1.До 5 дней        470\n",
            "2.6-10 дней        284\n",
            "3.11-20 дней       303\n",
            "4.21-30 дней       151\n",
            "5.Более 30 дней    219\n",
            "Не оприходовано      0\n",
            "Name: Оприходование поставки, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Оприходованные СФ (на склад с момента проверки документов)**"
      ],
      "metadata": {
        "id": "vhZO13dBebfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'год':\n",
        "\n",
        "  # прописываем категории для времени проводки документов\n",
        "  choices_post = ['1.До 5 дней', '2.6-10 дней', '3.11-20 дней', '4.21-30 дней', '5.Более 30 дней']\n",
        "\n",
        "  # прописываем условия для определения СФ в конкретную категорию времени проводки документов\n",
        "  conditions_post = [\n",
        "      inv_log['Время проводки документов'] <= 5,\n",
        "      (inv_log['Время проводки документов'] <= 10) & (inv_log['Время проводки документов'] > 5),\n",
        "      (inv_log['Время проводки документов'] <= 20) & (inv_log['Время проводки документов'] > 10),\n",
        "      (inv_log['Время проводки документов'] <= 30) & (inv_log['Время проводки документов'] > 20),\n",
        "      inv_log['Время проводки документов'] > 30\n",
        "  ]\n",
        "\n",
        "  # формируем признак категории для СФ\n",
        "  inv_log['Время проводки документов (группы)'] = np.select(conditions_post, choices_post, default='Не оприходовано')\n",
        "\n",
        "  print(\n",
        "      inv_log[inv_log['Оприходование СФ'] != 'Не оприходовано'].groupby(['Время проводки документов (группы)', 'Оприходование СФ'])['Номер документа (сч.ф)'].nunique()\n",
        "  )\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "VVUAipmlTDpz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3ad66e2-cd35-45c6-f7ef-ae1baa29e7b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время проводки документов (группы)  Оприходование СФ \n",
            "1.До 5 дней                         Виртуальный склад    124\n",
            "                                    Физический склад     376\n",
            "2.6-10 дней                         Виртуальный склад     39\n",
            "                                    Физический склад     286\n",
            "3.11-20 дней                        Виртуальный склад     23\n",
            "                                    Физический склад     374\n",
            "4.21-30 дней                        Виртуальный склад      5\n",
            "                                    Физический склад     169\n",
            "5.Более 30 дней                     Физический склад     171\n",
            "Name: Номер документа (сч.ф), dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Сохранение результатов (год)**"
      ],
      "metadata": {
        "id": "AxQl8-KWerv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if period == 'год':\n",
        "\n",
        "  datasets = [df_res, inv_log]\n",
        "  sheet_names = ['FCA год', 'SAP год']\n",
        "  excel_filename = 'Модель данных год.xlsx'\n",
        "\n",
        "  with pd.ExcelWriter(excel_filename) as writer:\n",
        "    for data, sheet in zip(datasets, sheet_names):\n",
        "      df = pd.DataFrame(data)\n",
        "      df.to_excel(writer, sheet_name=sheet, header=True, index=False)\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "DX3lVQaFTEMK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}