{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Romqa41/GPN/blob/main/%D0%A3%D0%BF%D1%80%D0%BE%D1%89%D0%B5%D0%BD%D0%BD%D1%8B%D0%B9_%D1%80%D0%B5%D0%B5%D1%81%D1%82%D1%80_FCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIyzBxXx5Kw7"
      },
      "source": [
        "# Блок импорта библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfVeNnTIAC9p"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btzjtJAk_6f0"
      },
      "source": [
        "# Блок функций"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN4r78igJTNN"
      },
      "source": [
        "Функция замены латинских букв на кириллические"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDcZPWEjGcku"
      },
      "outputs": [],
      "source": [
        "def replace_letters(text):\n",
        "  # создаем словарь соответствия латинских букв и кириллицы\n",
        "  mapping = {\n",
        "      'A': 'А',  # пример: латинская A -> кириллическая А\n",
        "      'E': 'Е',\n",
        "      'K': 'К',\n",
        "      'M': 'М',\n",
        "      'O': 'О',\n",
        "      'T': 'Т',\n",
        "      'C': 'С',\n",
        "      'P': 'Р',\n",
        "      'X': 'Х'\n",
        "      }\n",
        "  # заменяем каждую букву из текста, если она есть в словаре\n",
        "  return ''.join(mapping.get(char, char) for char in text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbA4HToMANe7"
      },
      "source": [
        "Функция для поиска автомобильных номеров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CZ6dRRF7L6E"
      },
      "outputs": [],
      "source": [
        "def transport_number(text):\n",
        "  # проверка на наличие данных\n",
        "  if pd.notna(text):\n",
        "    text = str(text)\n",
        "\n",
        "    # корректировка номеров ТС - удаление пробелов, (, ) и /, приведение к верхнему регистру\n",
        "    processed_text = re.sub(r'[\\s\\(\\)\\/\\-\\\\]', '', str(text)).upper()\n",
        "\n",
        "    processed_text = replace_letters(processed_text)\n",
        "\n",
        "    # паттерн для автомобильного номера\n",
        "    pattern = r'[А-ЯA-Z]\\d{3}[А-ЯA-Z]{2}\\d{0,3}'\n",
        "\n",
        "    # ищем совпадение по паттерну, если находим - функция возвращает весь номер\n",
        "    res = re.search(pattern, processed_text)\n",
        "    return res.group() if res else None\n",
        "\n",
        "  # в случае отсутствия искомого паттерна функция ничего не возвращает\n",
        "  return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PWp5SayARH_"
      },
      "source": [
        "Функция для поиска транспортных накладных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvE79c7c-oOe"
      },
      "outputs": [],
      "source": [
        "def transport_invoice(text):\n",
        "  # проверка на наличие данных\n",
        "  if pd.notna(text):\n",
        "    text = str(text)\n",
        "\n",
        "    # удаляем id\n",
        "    text = re.sub(r'\\{\\d{10}\\}', '', text)\n",
        "    # удаляем пробелы внутри текста\n",
        "    text = re.sub(r'\\s+', '', text)\n",
        "    # удаляем {}\n",
        "    text = re.sub(r'[{}]', '', text)\n",
        "    # удаляем слово \"Накладная\", учитываем оба регистра\n",
        "    text = re.sub(r'накладная', '', text, flags=re.I)\n",
        "    # удаляем слово \"ТТН\", учитываем оба регистра\n",
        "    text = re.sub(r'ттн', '', text, flags=re.I)\n",
        "\n",
        "    # возвращаем данные без пробелов в верхнем регистре\n",
        "    if text == '':\n",
        "      return None\n",
        "    if text:\n",
        "      return text.upper()\n",
        "\n",
        "  # если не нашлось данных - возвращаем пустое значение\n",
        "  return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lon4tZYXWwA_"
      },
      "source": [
        "Функция для поиска номера трекера"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5zJgRffU79h"
      },
      "outputs": [],
      "source": [
        "def tracker_number(text):\n",
        "  # проверка на наличие данных\n",
        "  if pd.notna(text):\n",
        "    text = str(text)\n",
        "\n",
        "    # убираем лишний текст (\" от ДД.ММ.ГГГГ\")\n",
        "    text = re.sub(r'\\s+[Оо][Тт].*$', '', text)\n",
        "    # удаляем id\n",
        "    text = re.sub(r'\\{\\d{10}\\}', '', text)\n",
        "    # удаляем слово \"ТТН\", учитываем оба регистра\n",
        "    text = re.sub(r'ттн', '', text, flags=re.I)\n",
        "    # удаляем тире\n",
        "    text = re.sub('-', '', text)\n",
        "    # удаляем пробелы\n",
        "    text = re.sub(r'\\s+', '', text)\n",
        "    # удаляем {}\n",
        "    text = re.sub(r'[{}]', '', text)\n",
        "\n",
        "    # если текста фактически не осталось - возвращаем пустое значение\n",
        "    if text == '':\n",
        "      return None\n",
        "\n",
        "    # возвращаем очищенный текст в верхнем регистре\n",
        "    return text.upper()\n",
        "\n",
        "  # заглушка\n",
        "  return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHm6XGPVAWkH"
      },
      "source": [
        "Функция преобразования приложений к договорам"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjfrI1jf_-pH"
      },
      "outputs": [],
      "source": [
        "def app_nums_processing(text):\n",
        "  # проверка на наличие данных\n",
        "  if pd.isna(text):\n",
        "    return text\n",
        "\n",
        "  # удаляем символ номера\n",
        "  text = text.replace('№', '').strip()\n",
        "\n",
        "  # функция ничего не выводит, если аргумент отсутствует\n",
        "  if not text:\n",
        "    return text\n",
        "\n",
        "  # сначала разбиваем на группы по точке с запятой\n",
        "  groups = [group.strip() for group in text.split(';') if group.strip()]\n",
        "\n",
        "  result_groups = []\n",
        "\n",
        "  for group in groups:\n",
        "    # внутри группы разбиваем по запятым\n",
        "    numbers = [num.strip() for num in group.split(',') if num.strip()]\n",
        "\n",
        "    # берем только первую часть до пробела для каждого номера\n",
        "    processed_numbers = []\n",
        "    for num in numbers:\n",
        "      # берем первую часть до пробела, если есть пробел\n",
        "      first_part = num.split()[0] if ' ' in num else num\n",
        "      processed_numbers.append(first_part)\n",
        "\n",
        "    # cобираем группу обратно через запятые\n",
        "    result_groups.append(', '.join(processed_numbers))\n",
        "\n",
        "  # cобираем все группы через точку с запятой\n",
        "  return '; '.join(result_groups)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7sm6n-UAcK7"
      },
      "source": [
        "Функция преобразования договоров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzJrMz7u_-bh"
      },
      "outputs": [],
      "source": [
        "def contracts_processing(text):\n",
        "  # проверка на наличие данных\n",
        "  if pd.isna(text):\n",
        "    return text\n",
        "\n",
        "  # удаляем лишнюю часть договора, представляющую собой номер приложения\n",
        "  text = re.sub(r'_СП\\d+', '', text)\n",
        "\n",
        "  # приводим данные к строковому типу и к верхнему регистру\n",
        "  text = str(text).upper().strip()\n",
        "\n",
        "  # функция ничего не выводит, если аргумент отсутствует\n",
        "  if not text:\n",
        "    return text\n",
        "\n",
        "  # удаляем символ номера и точки, заменяем все возможные разделители на ;\n",
        "  text = text.replace('№', '').replace('.', '').replace('\\\\', ';').replace(',', ';')\n",
        "\n",
        "  # удаляем буквенную часть договора\n",
        "  text = text.replace('ДП_', '').replace('Д_', '').replace('_Р', ' ')\n",
        "\n",
        "  # заменяем двойные разделители на одинарные\n",
        "  while ';;' in text:\n",
        "    text = text.replace(';;', ';')\n",
        "\n",
        "  # разделяем по точке с запятой\n",
        "  contracts = [contract.strip() for contract in text.split(';') if contract.strip()]\n",
        "\n",
        "  # берем только первую часть до пробела для каждого договора\n",
        "  processed_contracts = []\n",
        "  for contract in contracts:\n",
        "    # берем первую часть до пробела, если есть пробел\n",
        "    first_part = contract.split()[0] if ' ' in contract else contract\n",
        "    # удаляем слеши, если остались\n",
        "    first_part = first_part.replace('/', '')\n",
        "    # проверяем, что строка не пустая\n",
        "    if first_part:\n",
        "      processed_contracts.append(first_part)\n",
        "\n",
        "  # собираем все договоры через точку с запятой\n",
        "  return '; '.join(processed_contracts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usHSBdNoAh1Z"
      },
      "source": [
        "Функция извлечения кода с учетом приоритетов столбцов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHMsvzkwAf5d"
      },
      "outputs": [],
      "source": [
        "def extract_code(text):\n",
        "\n",
        "  # проверка на наличие данных в ячейке столбца - это необходимо для дальнейшего использования в лямбда-функции\n",
        "  if pd.notna(text):\n",
        "    text = str(text)\n",
        "\n",
        "    # поиск кода в тексте - извлекается группа из одной или более цифры подряд из скобок {}\n",
        "    res = re.search(r'\\{(\\d+)\\}', text)\n",
        "    if res:\n",
        "      # в случае нахождения совпадений возвращается первая извлеченная из скобок группа цифр\n",
        "      return res.group(1)\n",
        "\n",
        "    # поиск кода в тексте - извлекается группа из ровно 10 цифр подряд без скобок {}\n",
        "    res = re.search(r'\\b(\\d{10})\\b', text)\n",
        "    if res:\n",
        "      # в случае нахождения совпадений возвращается первая извлеченная из скобок группа цифр\n",
        "      return res.group(1)\n",
        "\n",
        "  # в случае отсутствия искомого паттерна функция ничего не возвращает\n",
        "  return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJFWI3LctuMs"
      },
      "source": [
        "Функция подсчета СФ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9eb7s1Rtti1"
      },
      "outputs": [],
      "source": [
        "def analyze_list(lst):\n",
        "\n",
        "  # обеспечиваем, что lst — список\n",
        "  if not isinstance(lst, list):\n",
        "    lst = [lst]\n",
        "\n",
        "  # по умолчанию ставим метку False на наличие значений и пропусков\n",
        "  has_nan = False\n",
        "  has_values = False\n",
        "\n",
        "  # проверяем наличие и отсутствие пропусков\n",
        "  for item in lst:\n",
        "    if item is None or (isinstance(item, float) and np.isnan(item)):\n",
        "      has_nan = True\n",
        "    elif item is not None:\n",
        "      has_values = True\n",
        "\n",
        "  # найдены и пропуски и значения\n",
        "  if has_nan and has_values:\n",
        "    return 'Сч.ф. найдены частично'\n",
        "  # найдены только пропуски\n",
        "  elif has_nan and not has_values:\n",
        "    return 'Не найдено ни одной сч.ф.'\n",
        "  # найдены только значения\n",
        "  elif not has_nan:\n",
        "    return 'Найдены все сч.ф.'\n",
        "\n",
        "  # заглушка\n",
        "  return 'Найдены все сч.ф.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqT1yCG8-kV_"
      },
      "source": [
        "Функция создания ключей с логикой разделения через \";\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bt6xzmcnGLz"
      },
      "outputs": [],
      "source": [
        "def generate_keys(contracts, applications, another):\n",
        "\n",
        "  # приводим данные к строчному типу\n",
        "  contracts = str(contracts)\n",
        "  applications = str(applications)\n",
        "\n",
        "  # убираем пробелы\n",
        "  contracts = contracts.replace(' ', '')#.replace(';', ',')\n",
        "  applications = applications.replace(' ', '').replace('.', ';')\n",
        "\n",
        "  # формируем списки\n",
        "  contracts = contracts.split(';')\n",
        "  applications = applications.split(';')\n",
        "\n",
        "  # формируем список с группами приложений (каждая группа - список, т.е. получаем список списков)\n",
        "  app_list = [[str(num.strip()) for num in lst.split(',')] for lst in applications]\n",
        "\n",
        "  # это третий аргумент для любого столбца, ячейки которого содержат одно значение\n",
        "  another_value = str(another).strip()\n",
        "\n",
        "  # сюда будем складывать найденные ключи\n",
        "  keys = []\n",
        "\n",
        "  # случай 1: кол-во договоров = кол-во групп приложений\n",
        "  if len(contracts) == len(app_list):\n",
        "    for contract, group_apps in zip(contracts, app_list):\n",
        "      for app in group_apps:\n",
        "        key = f'{contract}_{app}_{another_value}'\n",
        "        keys.append(key)\n",
        "\n",
        "  # случай 2: 1 договор и >= 1 групп приложений\n",
        "  elif len(contracts) == 1 and len(app_list) >= 1:\n",
        "    contract = contracts[0]\n",
        "    apps = sum(app_list, [])\n",
        "    for app in apps:\n",
        "      key = f'{contract}_{app}_{another_value}'\n",
        "      keys.append(key)\n",
        "\n",
        "  # случай 3: > 1 договоров и >= 1 групп приложений, при этом кол-во договоров != кол-во групп приложений\n",
        "  # таких случаев быть не должно, т.к. кол-во договоров должно соответствовать кол-ву групп приложений\n",
        "  # если такой случай выявлен, то запускается первый сценарий - соответствие будет идти по меньшему кол-ву Д или групп П\n",
        "  else:\n",
        "    for contract, group_apps in zip(contracts, app_list):\n",
        "      for app in group_apps:\n",
        "        key = f'{contract}_{app}_{another_value}'\n",
        "        keys.append(key)\n",
        "\n",
        "\n",
        "  return keys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jISPQtv3RM4M"
      },
      "source": [
        "Функция соединения данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qs9fAkraRLyD"
      },
      "outputs": [],
      "source": [
        "def dfs_merge(df_fca_start, df_fca, df_sap):\n",
        "\n",
        "  # шаг 1 - ищем соответствие по id\n",
        "  print('\\033[1mШаг первый:\\033[0m')\n",
        "\n",
        "  # копируем исходные реестры во избежание изменений в них\n",
        "  df_step_one = df_fca.copy()\n",
        "  sap_exp_one = df_sap.copy()\n",
        "\n",
        "  # комбинация ключа Д + П + id, попутно форматирование\n",
        "  df_step_one.loc[:, 'Ключ'] = df_step_one.apply(\n",
        "      lambda row: generate_keys(\n",
        "          contracts_processing(row['Договор']),\n",
        "          app_nums_processing(row['Номер приложения']),\n",
        "          row['Код']\n",
        "          ),\n",
        "      axis=1\n",
        "      )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  df_step_one = df_step_one.explode('Ключ').reset_index(drop=True)\n",
        "\n",
        "  # добавляем номер ключа\n",
        "  df_step_one['Номер ключа'] = df_step_one.groupby('Индекс перевозки').cumcount() + 1\n",
        "\n",
        "  # добавляем возможность фильтрации ключей\n",
        "  df_step_one['Фильтр'] = df_step_one['Индекс перевозки'].astype(str) + '_' + df_step_one['Номер ключа'].astype(str)\n",
        "\n",
        "  # считаем для каждой строки кол-во раз, которое встречается ключ по ней в таблице\n",
        "  df_step_one['Маркер Y'] = df_step_one['Ключ'].map(df_step_one['Ключ'].value_counts())\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  df_step_one = df_step_one[[\n",
        "      'Индекс перевозки',\n",
        "      'Код',\n",
        "      'Дата отгрузки ФАКТ',\n",
        "      'Стоимость материала, без НДС',\n",
        "      'Номер приложения',\n",
        "      'Договор',\n",
        "      'Номер ТС / накладной',\n",
        "      'Номер трекера',\n",
        "      '№ТН',\n",
        "      'Ключ',\n",
        "      'Номер ключа',\n",
        "      'Фильтр',\n",
        "      'Маркер Y'\n",
        "      ]]\n",
        "  df_step_one = df_step_one.drop_duplicates()\n",
        "\n",
        "  # комбинация ключа Д + П + id, попутно форматирование\n",
        "  sap_exp_one.loc[:, 'Ключ'] = sap_exp_one.apply(\n",
        "      lambda row: [\n",
        "          key for val in [extract_code(row[col]) for col in ['ТС: №ТранспДок', 'ТС: №ТранспСр-ва',\n",
        "                                                             'ТС: №ЕдОбр']]\n",
        "          for key in generate_keys(\n",
        "              contracts_processing(row['ЮрНомер договора на поставку']),\n",
        "              app_nums_processing(row['№ приложения к договору']),\n",
        "              val\n",
        "          )\n",
        "      ],\n",
        "      axis=1\n",
        "  )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  sap_exp_one = sap_exp_one.explode('Ключ')\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  sap_exp_one = sap_exp_one[['Ключ', 'Номер документа (сч.ф)', 'ЮрНомер договора на поставку', '№ приложения к договору']]\n",
        "  sap_exp_one = sap_exp_one.drop_duplicates()\n",
        "\n",
        "  # соединяем по ключам итоговый на первом шаге датафрейм\n",
        "  df_step_one = df_step_one.merge(sap_exp_one, how='left', on='Ключ')\n",
        "\n",
        "  # сч.ф., которые найти не получилось, будем искать на дальнейших итерациях\n",
        "  df_step_one = df_step_one[~df_step_one['Номер документа (сч.ф)'].isna()]\n",
        "\n",
        "  # удаляем ключи с Nan на конце\n",
        "  df_step_one = df_step_one[~df_step_one['Ключ'].str.lower().str.endswith('none')]\n",
        "\n",
        "  # создаем список отработанных значений-фильтров\n",
        "  # это значит, что такие индексы ключа для каждой строки больше не будут проверяться, т.к. была найдена сч.ф.\n",
        "  filter = list(df_step_one['Фильтр'])\n",
        "\n",
        "  print('Длина полученного датафрейма, ключ - id:', len(df_step_one))\n",
        "\n",
        "  # кол-во задействованных на шаге индексов\n",
        "  first_step_len = df_step_one['Индекс перевозки'].nunique()\n",
        "  # кол-во задействованных накопительным итогом индексов\n",
        "  sum_len = first_step_len\n",
        "\n",
        "  # тип соединения\n",
        "  df_step_one['Тип соединения'] = 'по договору + приложению + id'\n",
        "\n",
        "  # кол-во найденных на первой итерации уникальных сч.ф.\n",
        "  num_one = df_step_one['Номер документа (сч.ф)'].nunique()\n",
        "\n",
        "  print('Кол-во использованных индексов:', first_step_len)\n",
        "  print('Кол-во найденных сч.ф.:', num_one)\n",
        "  print('Кол-во строк, которые осталось найти:', len(fca)-sum_len)\n",
        "  print('Кол-во найденных строк накопительным итогом:', sum_len)\n",
        "  print('% нахождения накопительным итогом:', round(sum_len / len(fca) * 100, 2))\n",
        "  print('\\033[1m----------------------------------------\\033[0m')\n",
        "\n",
        "  # шаг 2 - ищем соответствие по договору + приложению + ТТН\n",
        "  print('\\033[1mШаг второй:\\033[0m')\n",
        "\n",
        "  # копируем исходные реестры во избежание изменений в них\n",
        "  df_step_two = df_fca.copy()\n",
        "  sap_exp_two = df_sap.copy()\n",
        "\n",
        "  # форматируем датафрейм FCA\n",
        "  df_step_two.loc[:, 'Ключ'] = df_step_two.apply(\n",
        "      lambda row: generate_keys(\n",
        "          contracts_processing(row['Договор']),\n",
        "          app_nums_processing(row['Номер приложения']),\n",
        "          transport_invoice(row['№ТН'])\n",
        "          ),\n",
        "      axis=1\n",
        "      )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  df_step_two = df_step_two.explode('Ключ').reset_index(drop=True)\n",
        "\n",
        "  # добавляем номер ключа\n",
        "  df_step_two['Номер ключа'] = df_step_two.groupby('Индекс перевозки').cumcount() + 1\n",
        "\n",
        "  # добавляем возможность фильтрации ключей\n",
        "  df_step_two['Фильтр'] = df_step_two['Индекс перевозки'].astype(str) + '_' + df_step_two['Номер ключа'].astype(str)\n",
        "\n",
        "  # считаем для каждой строки кол-во раз, которое встречается ключ по ней в таблице\n",
        "  df_step_two['Маркер Y'] = df_step_two['Ключ'].map(df_step_two['Ключ'].value_counts())\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  df_step_two = df_step_two[[\n",
        "      'Индекс перевозки',\n",
        "      'Код',\n",
        "      'Дата отгрузки ФАКТ',\n",
        "      'Стоимость материала, без НДС',\n",
        "      'Номер приложения',\n",
        "      'Договор',\n",
        "      'Номер ТС / накладной',\n",
        "      'Номер трекера',\n",
        "      '№ТН',\n",
        "      'Ключ',\n",
        "      'Номер ключа',\n",
        "      'Фильтр',\n",
        "      'Маркер Y'\n",
        "      ]]\n",
        "  df_step_two = df_step_two.drop_duplicates()\n",
        "\n",
        "  # форматируем копию датафрейма SAP, созданную для второго шага\n",
        "  sap_exp_two.loc[:, 'Ключ'] = sap_exp_two.apply(\n",
        "      lambda row: [\n",
        "          key for val in [transport_invoice(row[col]) for col in ['ТС: №ТранспДок', 'ТС: №ТранспСр-ва']]\n",
        "          for key in generate_keys(\n",
        "              contracts_processing(row['ЮрНомер договора на поставку']),\n",
        "              app_nums_processing(row['№ приложения к договору']),\n",
        "              val\n",
        "          )\n",
        "      ],\n",
        "      axis=1\n",
        "  )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  sap_exp_two = sap_exp_two.explode('Ключ')\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  sap_exp_two = sap_exp_two[['Ключ', 'Номер документа (сч.ф)', 'ЮрНомер договора на поставку', '№ приложения к договору']]\n",
        "  sap_exp_two = sap_exp_two.drop_duplicates()\n",
        "\n",
        "  # соединяем по ключам итоговый на втором шаге датафрейм\n",
        "  df_step_two = df_step_two.merge(sap_exp_two, how='left', on='Ключ')\n",
        "\n",
        "  # сч.ф., которые найти не получилось, будем искать на дальнейших итерациях\n",
        "  df_step_two = df_step_two[~df_step_two['Номер документа (сч.ф)'].isna()]\n",
        "\n",
        "  # удаляем ключи с Nan на конце\n",
        "  df_step_two = df_step_two[~df_step_two['Ключ'].str.lower().str.endswith('none')]\n",
        "\n",
        "  # выводим индексы с найденными ключами для строки из поиска\n",
        "  df_step_two = df_step_two[~df_step_two['Фильтр'].isin(filter)]\n",
        "\n",
        "  # дополняем список отработанных значений-фильтров\n",
        "  filter += list(df_step_two['Фильтр'])\n",
        "\n",
        "  print('Длина полученного датафрейма, ключ - договор + приложение + ТТН:', len(df_step_two))\n",
        "\n",
        "  # кол-во задействованных на шаге индексов\n",
        "  second_step_len = df_step_two['Индекс перевозки'].nunique()\n",
        "  # кол-во задействованных накопительным итогом индексов\n",
        "  sum_len += second_step_len\n",
        "\n",
        "  # тип соединения\n",
        "  df_step_two['Тип соединения'] = 'по договору + приложению + ТТН'\n",
        "\n",
        "  # кол-во найденных на первой итерации уникальных сч.ф.\n",
        "  num_two = df_step_two['Номер документа (сч.ф)'].nunique()\n",
        "\n",
        "  print('Кол-во использованных индексов:', second_step_len)\n",
        "  print('Кол-во найденных сч.ф.:', num_two)\n",
        "  print('Кол-во строк, которые осталось найти:', len(fca)-sum_len)\n",
        "  print('Кол-во найденных строк накопительным итогом:', sum_len)\n",
        "  print('% нахождения накопительным итогом:', round(sum_len / len(fca) * 100, 2))\n",
        "  print('\\033[1m----------------------------------------\\033[0m')\n",
        "\n",
        "  # шаг 3 - ищем соответствие по договору + приложению + номер трекера\n",
        "  print('\\033[1mШаг третий:\\033[0m')\n",
        "\n",
        "  # копируем исходные реестры во избежание изменений в них\n",
        "  df_step_three = df_fca.copy()\n",
        "  sap_exp_three = df_sap.copy()\n",
        "\n",
        "  # форматируем датафрейм FCA\n",
        "  df_step_three = df_step_three.copy()\n",
        "  df_step_three.loc[:, 'Ключ'] = df_step_three.apply(\n",
        "      lambda row: generate_keys(\n",
        "          contracts_processing(row['Договор']),\n",
        "          app_nums_processing(row['Номер приложения']),\n",
        "          tracker_number(row['Номер трекера'])\n",
        "          ),\n",
        "      axis=1\n",
        "      )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  df_step_three = df_step_three.explode('Ключ').reset_index(drop=True)\n",
        "\n",
        "  # добавляем номер ключа\n",
        "  df_step_three['Номер ключа'] = df_step_three.groupby('Индекс перевозки').cumcount() + 1\n",
        "\n",
        "  # добавляем возможность фильтрации ключей\n",
        "  df_step_three['Фильтр'] = df_step_three['Индекс перевозки'].astype(str) + '_' + df_step_three['Номер ключа'].astype(str)\n",
        "\n",
        "  # считаем для каждой строки кол-во раз, которое встречается ключ по ней в таблице\n",
        "  df_step_three['Маркер Y'] = df_step_three['Ключ'].map(df_step_three['Ключ'].value_counts())\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  df_step_three = df_step_three[[\n",
        "      'Индекс перевозки',\n",
        "      'Код',\n",
        "      'Дата отгрузки ФАКТ',\n",
        "      'Стоимость материала, без НДС',\n",
        "      'Номер приложения',\n",
        "      'Договор',\n",
        "      'Номер ТС / накладной',\n",
        "      'Номер трекера',\n",
        "      '№ТН',\n",
        "      'Ключ',\n",
        "      'Номер ключа',\n",
        "      'Фильтр',\n",
        "      'Маркер Y'\n",
        "      ]]\n",
        "  df_step_three = df_step_three.drop_duplicates()\n",
        "\n",
        "  # форматируем копию датафрейма SAP, созданную для третьего шага\n",
        "  sap_exp_three.loc[:, 'Ключ'] = sap_exp_three.apply(\n",
        "      lambda row: [\n",
        "          key for val in [tracker_number(row[col]) for col in ['ТС: №ТранспСр-ва', 'ТС: №ТранспДок', 'ТС: №ЕдОбр']]\n",
        "          for key in generate_keys(\n",
        "              contracts_processing(row['ЮрНомер договора на поставку']),\n",
        "              app_nums_processing(row['№ приложения к договору']),\n",
        "              val\n",
        "          )\n",
        "      ],\n",
        "      axis=1\n",
        "  )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  sap_exp_three = sap_exp_three.explode('Ключ')\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  sap_exp_three = sap_exp_three[['Ключ', 'Номер документа (сч.ф)', 'ЮрНомер договора на поставку', '№ приложения к договору']]\n",
        "  sap_exp_three = sap_exp_three.drop_duplicates()\n",
        "\n",
        "  # соединяем по ключам итоговый на третьем шаге датафрейм\n",
        "  df_step_three = df_step_three.merge(sap_exp_three, how='left', on='Ключ')\n",
        "\n",
        "  # сч.ф., которые найти не получилось, будем искать на дальнейших итерациях\n",
        "  df_step_three = df_step_three[~df_step_three['Номер документа (сч.ф)'].isna()]\n",
        "\n",
        "  # # удаляем ключи с Nan на конце\n",
        "  df_step_three = df_step_three[~df_step_three['Ключ'].str.lower().str.endswith('none')]\n",
        "\n",
        "  # выводим индексы с найденными ключами для строки из поиска\n",
        "  df_step_three = df_step_three[~df_step_three['Фильтр'].isin(filter)]\n",
        "\n",
        "  # дополняем список отработанных значений-фильтров\n",
        "  filter += list(df_step_three['Фильтр'])\n",
        "\n",
        "  print('Длина полученного датафрейма, ключ - договор + приложение + номер трекера:', len(df_step_three))\n",
        "\n",
        "  # кол-во задействованных на шаге индексов\n",
        "  third_step_len = df_step_three['Индекс перевозки'].nunique()\n",
        "  # кол-во задействованных накопительным итогом индексов\n",
        "  sum_len += third_step_len\n",
        "\n",
        "  # тип соединения\n",
        "  df_step_three['Тип соединения'] = 'по договору + приложению + номеру трекера'\n",
        "\n",
        "  # кол-во найденных на первой итерации уникальных сч.ф.\n",
        "  num_three = df_step_three['Номер документа (сч.ф)'].nunique()\n",
        "\n",
        "  print('Кол-во использованных индексов:', third_step_len)\n",
        "  print('Кол-во найденных сч.ф.:', num_three)\n",
        "  print('Кол-во строк, которые осталось найти:', len(fca)-sum_len)\n",
        "  print('Кол-во найденных строк накопительным итогом:', sum_len)\n",
        "  print('% нахождения накопительным итогом:', round(sum_len / len(fca) * 100, 2))\n",
        "  print('\\033[1m----------------------------------------\\033[0m')\n",
        "\n",
        "  # шаг 4 - ищем соответствие по договору + приложению + номер ТС\n",
        "  print('\\033[1mШаг четвертый:\\033[0m')\n",
        "\n",
        "  # копируем исходные реестры во избежание изменений в них\n",
        "  df_step_four = df_fca.copy()\n",
        "  sap_exp_four = df_sap.copy()\n",
        "\n",
        "  # форматируем датафрейм FCA\n",
        "  df_step_four = df_step_four.copy()\n",
        "  df_step_four.loc[:, 'Ключ'] = df_step_four.apply(\n",
        "      lambda row: generate_keys(\n",
        "          contracts_processing(row['Договор']),\n",
        "          app_nums_processing(row['Номер приложения']),\n",
        "          transport_number(row['Номер ТС / накладной'])\n",
        "          ),\n",
        "      axis=1\n",
        "      )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  df_step_four = df_step_four.explode('Ключ').reset_index(drop=True)\n",
        "\n",
        "  # добавляем номер ключа\n",
        "  df_step_four['Номер ключа'] = df_step_four.groupby('Индекс перевозки').cumcount() + 1\n",
        "\n",
        "  # добавляем возможность фильтрации ключей\n",
        "  df_step_four['Фильтр'] = df_step_four['Индекс перевозки'].astype(str) + '_' + df_step_four['Номер ключа'].astype(str)\n",
        "\n",
        "  # считаем для каждой строки кол-во раз, которое встречается ключ по ней в таблице\n",
        "  df_step_four['Маркер Y'] = df_step_four['Ключ'].map(df_step_four['Ключ'].value_counts())\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  df_step_four = df_step_four[[\n",
        "      'Индекс перевозки',\n",
        "      'Код',\n",
        "      'Дата отгрузки ФАКТ',\n",
        "      'Стоимость материала, без НДС',\n",
        "      'Номер приложения',\n",
        "      'Договор',\n",
        "      'Номер ТС / накладной',\n",
        "      'Номер трекера',\n",
        "      '№ТН',\n",
        "      'Ключ',\n",
        "      'Номер ключа',\n",
        "      'Фильтр',\n",
        "      'Маркер Y'\n",
        "      ]]\n",
        "  df_step_four = df_step_four.drop_duplicates()\n",
        "\n",
        "  # форматируем копию датафрейма SAP, созданную для четвертого шага\n",
        "  sap_exp_four.loc[:, 'Ключ'] = sap_exp_four.apply(\n",
        "      lambda row: [\n",
        "          key for val in [transport_number(row[col]) for col in ['ТС: №ТранспСр-ва', 'ТС: №ТранспДок']]\n",
        "          for key in generate_keys(\n",
        "              contracts_processing(row['ЮрНомер договора на поставку']),\n",
        "              app_nums_processing(row['№ приложения к договору']),\n",
        "              val\n",
        "          )\n",
        "      ],\n",
        "      axis=1\n",
        "      )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  sap_exp_four = sap_exp_four.explode('Ключ')\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  sap_exp_four = sap_exp_four[['Ключ', 'Номер документа (сч.ф)', 'ЮрНомер договора на поставку', '№ приложения к договору']]\n",
        "  sap_exp_four = sap_exp_four.drop_duplicates()\n",
        "\n",
        "  # соединяем по ключам итоговый на четвертом шаге датафрейм\n",
        "  df_step_four = df_step_four.merge(sap_exp_four, how='left', on='Ключ')\n",
        "\n",
        "  # сч.ф., которые найти не получилось, будем искать на дальнейших итерациях\n",
        "  df_step_four = df_step_four[~df_step_four['Номер документа (сч.ф)'].isna()]\n",
        "\n",
        "  # удаляем ключи с Nan на конце\n",
        "  df_step_four = df_step_four[~df_step_four['Ключ'].str.lower().str.endswith('none')]\n",
        "\n",
        "  # выводим индексы с найденными ключами для строки из поиска\n",
        "  df_step_four = df_step_four[~df_step_four['Фильтр'].isin(filter)]\n",
        "\n",
        "  # дополняем список отработанных значений-фильтров\n",
        "  filter += list(df_step_four['Фильтр'])\n",
        "\n",
        "  print('Длина полученного датафрейма, ключ - договор + приложение + номер ТС:', len(df_step_four))\n",
        "\n",
        "  # кол-во задействованных на шаге индексов\n",
        "  fourth_step_len = df_step_four['Индекс перевозки'].nunique()\n",
        "  # кол-во задействованных накопительным итогом индексов\n",
        "  sum_len += fourth_step_len\n",
        "\n",
        "  # тип соединения\n",
        "  df_step_four['Тип соединения'] = 'по договору + приложению + номеру ТС'\n",
        "\n",
        "  # кол-во найденных на четвертой итерации уникальных сч.ф.\n",
        "  num_four = df_step_four['Номер документа (сч.ф)'].nunique()\n",
        "\n",
        "  print('Кол-во использованных индексов:', fourth_step_len)\n",
        "  print('Кол-во найденных сч.ф.:', num_four)\n",
        "  print('Кол-во строк, которые осталось найти:', len(fca)-sum_len)\n",
        "  print('Кол-во найденных строк накопительным итогом:', sum_len)\n",
        "  print('% нахождения накопительным итогом:', round(sum_len / len(fca) * 100, 2))\n",
        "  print('\\033[1m----------------------------------------\\033[0m')\n",
        "\n",
        "  # шаг 5 - ищем соответствие по договору + приложению + дата отправки ТС\n",
        "  print('\\033[1mШаг пятый:\\033[0m')\n",
        "\n",
        "  # копируем исходные реестры во избежание изменений в них\n",
        "  df_step_five = df_fca.copy()\n",
        "  sap_exp_five = df_sap.copy()\n",
        "\n",
        "  # форматируем датафрейм FCA\n",
        "  df_step_five = df_step_five.copy()\n",
        "  df_step_five.loc[:, 'Ключ'] = df_step_five.apply(\n",
        "      lambda row: generate_keys(\n",
        "          contracts_processing(row['Договор']),\n",
        "          app_nums_processing(row['Номер приложения']),\n",
        "          row['Дата отгрузки ФАКТ']\n",
        "          ),\n",
        "      axis=1\n",
        "      )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  df_step_five = df_step_five.explode('Ключ').reset_index(drop=True)\n",
        "\n",
        "  # добавляем номер ключа\n",
        "  df_step_five['Номер ключа'] = df_step_five.groupby('Индекс перевозки').cumcount() + 1\n",
        "\n",
        "  # добавляем возможность фильтрации ключей\n",
        "  df_step_five['Фильтр'] = df_step_five['Индекс перевозки'].astype(str) + '_' + df_step_five['Номер ключа'].astype(str)\n",
        "\n",
        "  # считаем для каждой строки кол-во раз, которое встречается ключ по ней в таблице\n",
        "  df_step_five['Маркер Y'] = df_step_five['Ключ'].map(df_step_five['Ключ'].value_counts())\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  df_step_five = df_step_five[[\n",
        "      'Индекс перевозки',\n",
        "      'Код',\n",
        "      'Дата отгрузки ФАКТ',\n",
        "      'Стоимость материала, без НДС',\n",
        "      'Номер приложения',\n",
        "      'Договор',\n",
        "      'Номер ТС / накладной',\n",
        "      'Номер трекера',\n",
        "      '№ТН',\n",
        "      'Ключ',\n",
        "      'Номер ключа',\n",
        "      'Фильтр',\n",
        "      'Маркер Y'\n",
        "      ]]\n",
        "  df_step_five = df_step_five.drop_duplicates()\n",
        "\n",
        "  # форматируем копию датафрейма SAP, созданную для пятого шага\n",
        "  sap_exp_five.loc[:, 'Ключ'] = sap_exp_five.apply(\n",
        "      lambda row: generate_keys(\n",
        "          contracts_processing(row['ЮрНомер договора на поставку']),\n",
        "          app_nums_processing(row['№ приложения к договору']),\n",
        "          row['ТС: Дата отправки']\n",
        "          ),\n",
        "      axis=1\n",
        "      )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  sap_exp_five = sap_exp_five.explode('Ключ')\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  sap_exp_five = sap_exp_five[['Ключ', 'Номер документа (сч.ф)', 'ЮрНомер договора на поставку', '№ приложения к договору']]\n",
        "  sap_exp_five = sap_exp_five.drop_duplicates()\n",
        "\n",
        "  # соединяем по ключам итоговый на пятом шаге датафрейм\n",
        "  df_step_five = df_step_five.merge(sap_exp_five, how='left', on='Ключ')\n",
        "\n",
        "  # сч.ф., которые найти не получилось, будем искать на дальнейших итерациях\n",
        "  df_step_five = df_step_five[~df_step_five['Номер документа (сч.ф)'].isna()]\n",
        "\n",
        "  # удаляем ключи с Nan на конце\n",
        "  df_step_five = df_step_five[~df_step_five['Ключ'].str.lower().str.endswith('none')]\n",
        "\n",
        "  # выводим индексы с найденными ключами для строки из поиска\n",
        "  df_step_five = df_step_five[~df_step_five['Фильтр'].isin(filter)]\n",
        "\n",
        "  # дополняем список отработанных значений-фильтров\n",
        "  filter += list(df_step_five['Фильтр'])\n",
        "\n",
        "  print('Длина полученного датафрейма, ключ - договор + приложение + дата отправки ТС:', len(df_step_five))\n",
        "\n",
        "  # кол-во задействованных на шаге индексов\n",
        "  fifth_step_len = df_step_five.loc[df_step_five['Номер документа (сч.ф)'].notna(), 'Индекс перевозки'].nunique()\n",
        "  # кол-во задействованных накопительным итогом индексов\n",
        "  sum_len += fifth_step_len\n",
        "\n",
        "  # тип соединения\n",
        "  df_step_five['Тип соединения'] = 'по договору + приложению + дате отправки ТС'\n",
        "\n",
        "  # кол-во найденных на пятой итерации уникальных сч.ф.\n",
        "  num_five = df_step_five['Номер документа (сч.ф)'].nunique()\n",
        "\n",
        "  print('Кол-во использованных индексов:', fifth_step_len)\n",
        "  print('Кол-во найденных сч.ф.:', num_five)\n",
        "  print('Кол-во строк, которые осталось найти:', len(fca)-sum_len)\n",
        "  print('Кол-во найденных строк накопительным итогом:', sum_len)\n",
        "  print('% нахождения накопительным итогом:', round(sum_len / len(fca) * 100, 2))\n",
        "  print('\\033[1m----------------------------------------\\033[0m')\n",
        "\n",
        "  # шаг 6 - ищем соответствие по договору + приложению + стоимости материала\n",
        "  print('\\033[1mШаг шестой:\\033[0m')\n",
        "\n",
        "  # копируем исходные реестры во избежание изменений в них\n",
        "  df_step_six = df_fca.copy()\n",
        "  sap_exp_six = df_sap.copy()\n",
        "\n",
        "  # форматируем датафрейм FCA\n",
        "  df_step_six = df_step_six.copy()\n",
        "  df_step_six.loc[:, 'Ключ'] = df_step_six.apply(\n",
        "      lambda row: generate_keys(\n",
        "          contracts_processing(row['Договор']),\n",
        "          app_nums_processing(row['Номер приложения']),\n",
        "          str(round(row['Стоимость материала, без НДС'] * 1.2, 2))\n",
        "          ),\n",
        "      axis=1\n",
        "      )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  df_step_six = df_step_six.explode('Ключ').reset_index(drop=True)\n",
        "\n",
        "  # добавляем номер ключа\n",
        "  df_step_six['Номер ключа'] = df_step_six.groupby('Индекс перевозки').cumcount() + 1\n",
        "\n",
        "  # добавляем возможность фильтрации ключей\n",
        "  df_step_six['Фильтр'] = df_step_six['Индекс перевозки'].astype(str) + '_' + df_step_six['Номер ключа'].astype(str)\n",
        "\n",
        "  # считаем для каждой строки кол-во раз, которое встречается ключ по ней в таблице\n",
        "  df_step_six['Маркер Y'] = df_step_six['Ключ'].map(df_step_six['Ключ'].value_counts())\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  df_step_six = df_step_six[[\n",
        "      'Индекс перевозки',\n",
        "      'Код',\n",
        "      'Дата отгрузки ФАКТ',\n",
        "      'Стоимость материала, без НДС',\n",
        "      'Номер приложения',\n",
        "      'Договор',\n",
        "      'Номер ТС / накладной',\n",
        "      'Номер трекера',\n",
        "      '№ТН',\n",
        "      'Ключ',\n",
        "      'Номер ключа',\n",
        "      'Фильтр',\n",
        "      'Маркер Y'\n",
        "      ]]\n",
        "  df_step_six = df_step_six.drop_duplicates()\n",
        "\n",
        "  # форматируем копию датафрейма SAP, созданную для шестого шага\n",
        "  sap_exp_six.loc[:, 'Ключ'] = sap_exp_six.apply(\n",
        "      lambda row: generate_keys(\n",
        "          contracts_processing(row['ЮрНомер договора на поставку']),\n",
        "          app_nums_processing(row['№ приложения к договору']),\n",
        "          str(round(row['Сумма брутто'], 2))\n",
        "          ),\n",
        "      axis=1\n",
        "      )\n",
        "\n",
        "  # растаскиваем по строкам\n",
        "  sap_exp_six = sap_exp_six.explode('Ключ')\n",
        "\n",
        "  # удаляем лишние поля и затем дубликаты\n",
        "  sap_exp_six = sap_exp_six[['Ключ', 'Номер документа (сч.ф)', 'ЮрНомер договора на поставку', '№ приложения к договору']]\n",
        "  sap_exp_six = sap_exp_six.drop_duplicates()\n",
        "\n",
        "  # соединяем по ключам итоговый на шестом шаге датафрейм\n",
        "  df_step_six = df_step_six.merge(sap_exp_six, how='left', on='Ключ')\n",
        "\n",
        "  # удаляем ключи с Nan на конце\n",
        "  df_step_six = df_step_six[~df_step_six['Ключ'].str.lower().str.endswith('none')]\n",
        "\n",
        "  # выводим индексы с найденными ключами для строки из поиска\n",
        "  df_step_six = df_step_six[~df_step_six['Фильтр'].isin(filter)]\n",
        "\n",
        "  # дополняем список отработанных значений-фильтров\n",
        "  filter += list(df_step_six['Фильтр'])\n",
        "\n",
        "  print('Длина полученного датафрейма, ключ - договор + приложение + стоимость материала:', len(df_step_six))\n",
        "\n",
        "  # кол-во задействованных на шаге индексов\n",
        "  sixth_step_len = df_step_six.loc[df_step_six['Номер документа (сч.ф)'].notna(), 'Индекс перевозки'].nunique()\n",
        "  # кол-во задействованных накопительным итогом индексов\n",
        "  sum_len += sixth_step_len\n",
        "\n",
        "  # тип соединения\n",
        "  df_step_six['Тип соединения'] = 'по договору + приложению + стоимости материала'\n",
        "\n",
        "  # кол-во найденных на шестой итерации уникальных сч.ф.\n",
        "  num_six = df_step_six['Номер документа (сч.ф)'].nunique()\n",
        "\n",
        "  print('Кол-во использованных индексов:', sixth_step_len)\n",
        "  print('Кол-во найденных сч.ф.:', num_six)\n",
        "  print('Кол-во строк, которые осталось найти:', len(fca)-sum_len)\n",
        "  print('Кол-во найденных строк накопительным итогом:', sum_len)\n",
        "  print('% нахождения накопительным итогом:', round(sum_len / len(fca) * 100, 2))\n",
        "  print('\\033[1m----------------------------------------\\033[0m')\n",
        "\n",
        "  print('\\033[1mИТОГО:\\033[0m')\n",
        "\n",
        "  # соединяем найденные на предыдущих шагах датафреймы\n",
        "  res = pd.concat([df_step_one, df_step_two, df_step_three, df_step_four, df_step_five, df_step_six], axis=0, ignore_index=True)\n",
        "\n",
        "  # удаляем строки с не найденными СФ\n",
        "  res = res[res['Номер документа (сч.ф)'].notna()]\n",
        "\n",
        "  # сортируем по индексам строк и индексам ключей в строках для корректного порядке при нахождении сч.ф.\n",
        "  res = res.sort_values(by=['Индекс перевозки', 'Номер ключа'])\n",
        "\n",
        "  # оставляем только основные столбцы\n",
        "  res = res[[\n",
        "      'Индекс перевозки',\n",
        "      'Код',\n",
        "      'Дата отгрузки ФАКТ',\n",
        "      'Стоимость материала, без НДС',\n",
        "      '№ приложения к договору',\n",
        "      'ЮрНомер договора на поставку',\n",
        "      'Номер ТС / накладной',\n",
        "      'Номер трекера',\n",
        "      '№ТН',\n",
        "      'Маркер Y',\n",
        "      'Номер документа (сч.ф)'\n",
        "  ]]\n",
        "\n",
        "  return res\n",
        "\n",
        "  # # смотрим по каким ключам сколько соединилось строк\n",
        "  # print(\n",
        "  #     res.groupby('Тип соединения')['Номер документа (сч.ф)']\n",
        "  #      .size()\n",
        "  #      .reset_index(name='Кол-во строк')\n",
        "  #      .sort_values(by='Кол-во строк', ascending=False)\n",
        "  #      .reset_index(drop=True)\n",
        "  #      )\n",
        "\n",
        "  # # создаем таблицу с индексами и сч.ф., которую будем цеплять к исходному реестру FCA, попутно меняет float на int\n",
        "  # res = res.groupby(['Индекс перевозки', 'Маркер Y'], sort=False).agg({\n",
        "  #   'Номер документа (сч.ф)': lambda x: [int(val) if pd.notna(val) else val for val in x]\n",
        "  #   }).reset_index()\n",
        "\n",
        "  # # окончательно схлопываем строки (из наличия маркера Y некоторые строки задублировались)\n",
        "  # res = res.groupby('Индекс перевозки').agg({\n",
        "  #   'Маркер Y': 'sum',  # сумма по повтору\n",
        "  #   'Номер документа (сч.ф)': 'sum',  # объединение списков\n",
        "  #   }).reset_index()\n",
        "\n",
        "  # # цепляем к реестру FCA найденные сч.ф.\n",
        "  # result = df_fca_start.merge(res, how='left', on='Индекс перевозки')\n",
        "\n",
        "  # print('\\033[1m----------------------------------------\\033[0m')\n",
        "\n",
        "  # # общее кол-во найденных сч.ф.\n",
        "  # invoices = res.explode('Номер документа (сч.ф)')\n",
        "  # n = invoices['Номер документа (сч.ф)'].nunique()\n",
        "  # print(f'\\033[1mОбщее кол-во найденных сч.ф.:\\033[0m {n}')\n",
        "  # print(f'\\033[1m% найденных строк\\033[0m {round(sum_len / len(fca) * 100, 2)}')\n",
        "\n",
        "  # return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfquPgt__ufo"
      },
      "source": [
        "# Загрузка и предобработка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpxLWai147-9"
      },
      "source": [
        "Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYTIdF-W_jbe",
        "outputId": "96df9095-6083-4fa3-9a9a-fc45cc32c0eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Длина FCA: 1690\n",
            "Длина SAP 519: 3671\n"
          ]
        }
      ],
      "source": [
        "# загрузка данных\n",
        "fca = pd.read_excel('Ноябрь 2025.xlsx', usecols=[\n",
        "    'Код',\n",
        "    'Дата отгрузки ФАКТ',\n",
        "    'Номер приложения',\n",
        "    'Договор',\n",
        "    'Номер ТС / накладной',\n",
        "    'Номер трекера',\n",
        "    '№ТН',\n",
        "    'Стоимость материала, без НДС',\n",
        "    ])\n",
        "\n",
        "sap_519 = pd.read_excel('519 мес.XLSX', usecols = [\n",
        "    'ЮрНомер договора на поставку',\n",
        "    '№ приложения к договору',\n",
        "    'Номер документа (сч.ф)',\n",
        "    'ТС: №ТранспСр-ва',\n",
        "    'ТС: №ТранспДок',\n",
        "    'ТС: Дата отправки',\n",
        "    'ТС: №ЕдОбр',\n",
        "    'Сумма брутто'\n",
        "    ], dtype={'№ приложения к договору': str})\n",
        "\n",
        "print('Длина FCA:', len(fca))\n",
        "print('Длина SAP 519:', len(sap_519))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35qoERFy9ZPD"
      },
      "outputs": [],
      "source": [
        "# добавляем индекс каждой строке реестра FCA\n",
        "fca.insert(0, 'Индекс перевозки', np.arange(0, len(fca)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FekeWxie6X9l"
      },
      "outputs": [],
      "source": [
        "# поля, которые блок FCA должен заполнить данными\n",
        "cols_revision = [\n",
        "    'Код',\n",
        "    'Договор',\n",
        "    'Номер приложения',\n",
        "    'Дата отгрузки ФАКТ',\n",
        "    ]\n",
        "\n",
        "# таблица, которая будет направлена блоку FCA на дозаполнение\n",
        "fca_revision = fca[fca[cols_revision].isnull().any(axis=1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzMJFYZEX3nH"
      },
      "source": [
        "Преобразование реестра FCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWqjsQ5lX7bF"
      },
      "outputs": [],
      "source": [
        "# избавляемся от лишних скобок в поле id, ограничиваем длину id 10 символами\n",
        "fca['Код'] = fca['Код'].str.replace(r'[{}]', '', regex=True).str[:10]\n",
        "\n",
        "# приводим данные по стоимостям в текстовый тип данных (техническое решение, чтобы привести цифры в единый вид)\n",
        "fca['Стоимость материала, без НДС'] = fca['Стоимость материала, без НДС'].astype(str)\n",
        "\n",
        "# избавляемся от лишних пробелов и приводим цифры в единый вид\n",
        "fca['Стоимость материала, без НДС'] = fca['Стоимость материала, без НДС'].str.replace(',', '.').str.replace(r'\\s+', '', regex=True).str.replace(r'[^\\d.]+', '', regex=True)\n",
        "\n",
        "# меняем тип данных на числовой\n",
        "fca['Стоимость материала, без НДС'] = pd.to_numeric(fca['Стоимость материала, без НДС'], errors='coerce')\n",
        "\n",
        "# подстраховка\n",
        "fca['Стоимость материала, без НДС'] = fca['Стоимость материала, без НДС'].astype(float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LqfUpcqHEjN"
      },
      "source": [
        "Преобразование выгрузки SAP 519"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlYFiM9S_453",
        "outputId": "7422bf8c-e18a-4b48-da09-9e8598decfb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1086859690.py:26: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  sap_519[col_list] = sap_519[col_list].applymap(\n"
          ]
        }
      ],
      "source": [
        "# избавляемся от всех строк SAP 519, где нет СФ\n",
        "sap_519 = sap_519[sap_519['Номер документа (сч.ф)'].notna()]\n",
        "\n",
        "\n",
        "# меняем тип данных на текстовый\n",
        "# это дополнительная мера, т.к. тип данных в любом случае меняется внутри функций\n",
        "cols_fca_str = ['Номер ТС / накладной', 'Номер приложения', 'Номер трекера', '№ТН']\n",
        "for col in cols_fca_str:\n",
        "  fca[col] = fca[col].where(fca[col].isna(), fca[col].astype('str'))\n",
        "\n",
        "cols_sap_str = [\n",
        "    'ТС: №ТранспСр-ва',\n",
        "    'ТС: №ТранспДок',\n",
        "    'ТС: №ЕдОбр',\n",
        "    'ЮрНомер договора на поставку',\n",
        "    '№ приложения к договору',\n",
        "    ]\n",
        "for col in cols_sap_str:\n",
        "  sap_519[col] = sap_519[col].where(sap_519[col].isna(), sap_519[col].astype('str'))\n",
        "\n",
        "# на всякий случай присваиваем СФ тип данных int\n",
        "sap_519['Номер документа (сч.ф)'] = sap_519['Номер документа (сч.ф)'].astype(int)\n",
        "\n",
        "# преобразуем поля из текствого формата в списки\n",
        "col_list = ['ТС: №ТранспСр-ва', 'ТС: №ТранспДок', 'ТС: №ЕдОбр']\n",
        "sap_519[col_list] = sap_519[col_list].applymap(\n",
        "    lambda x: [item.strip() for item in x.split(',')] if pd.notna(x) else []\n",
        ")\n",
        "\n",
        "# растаскиваем по строкам\n",
        "sap_519_exp = sap_519.explode('ТС: №ТранспСр-ва').explode('ТС: №ТранспДок').explode('ТС: №ЕдОбр')\n",
        "\n",
        "# приводим данные по стоимостям в текстовый тип данных (техническое решение, чтобы привести цифры в единый вид)\n",
        "sap_519_exp['Сумма брутто'] = sap_519_exp['Сумма брутто'].astype(str)\n",
        "\n",
        "# избавляемся от лишних пробелов и приводим цифры в единый вид\n",
        "sap_519_exp['Сумма брутто'] = sap_519_exp['Сумма брутто'].str.replace(',', '.').str.replace(r'\\s+', '', regex=True).str.replace(r'[^\\d.]+', '', regex=True)\n",
        "\n",
        "# меняем тип данных на числовой\n",
        "sap_519_exp['Сумма брутто'] = pd.to_numeric(sap_519_exp['Сумма брутто'], errors='coerce')\n",
        "\n",
        "# подстраховка\n",
        "sap_519_exp['Сумма брутто'] = sap_519_exp['Сумма брутто'].astype(float)\n",
        "\n",
        "# чистим столбцы\n",
        "for col in col_list:\n",
        "    mask = sap_519_exp[col].str.lower() == 'нет данных'\n",
        "    sap_519_exp.loc[mask, col] = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqTXAIFp-x3F"
      },
      "outputs": [],
      "source": [
        "# исключаем часть реестра FCA, отправленную на доработку\n",
        "fca_clean = fca[~fca['Индекс перевозки'].isin(fca_revision['Индекс перевозки'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28lMBpI6nlF8",
        "outputId": "730e1a88-e784-48cd-84fc-c8deb3091b1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mШаг первый:\u001b[0m\n",
            "Длина полученного датафрейма, ключ - id: 617\n",
            "Кол-во использованных индексов: 504\n",
            "Кол-во найденных сч.ф.: 615\n",
            "Кол-во строк, которые осталось найти: 1186\n",
            "Кол-во найденных строк накопительным итогом: 504\n",
            "% нахождения накопительным итогом: 29.82\n",
            "\u001b[1m----------------------------------------\u001b[0m\n",
            "\u001b[1mШаг второй:\u001b[0m\n",
            "Длина полученного датафрейма, ключ - договор + приложение + ТТН: 16\n",
            "Кол-во использованных индексов: 9\n",
            "Кол-во найденных сч.ф.: 16\n",
            "Кол-во строк, которые осталось найти: 1177\n",
            "Кол-во найденных строк накопительным итогом: 513\n",
            "% нахождения накопительным итогом: 30.36\n",
            "\u001b[1m----------------------------------------\u001b[0m\n",
            "\u001b[1mШаг третий:\u001b[0m\n",
            "Длина полученного датафрейма, ключ - договор + приложение + номер трекера: 32\n",
            "Кол-во использованных индексов: 23\n",
            "Кол-во найденных сч.ф.: 32\n",
            "Кол-во строк, которые осталось найти: 1154\n",
            "Кол-во найденных строк накопительным итогом: 536\n",
            "% нахождения накопительным итогом: 31.72\n",
            "\u001b[1m----------------------------------------\u001b[0m\n",
            "\u001b[1mШаг четвертый:\u001b[0m\n",
            "Длина полученного датафрейма, ключ - договор + приложение + номер ТС: 270\n",
            "Кол-во использованных индексов: 202\n",
            "Кол-во найденных сч.ф.: 254\n",
            "Кол-во строк, которые осталось найти: 952\n",
            "Кол-во найденных строк накопительным итогом: 738\n",
            "% нахождения накопительным итогом: 43.67\n",
            "\u001b[1m----------------------------------------\u001b[0m\n",
            "\u001b[1mШаг пятый:\u001b[0m\n",
            "Длина полученного датафрейма, ключ - договор + приложение + дата отправки ТС: 763\n",
            "Кол-во использованных индексов: 536\n",
            "Кол-во найденных сч.ф.: 643\n",
            "Кол-во строк, которые осталось найти: 416\n",
            "Кол-во найденных строк накопительным итогом: 1274\n",
            "% нахождения накопительным итогом: 75.38\n",
            "\u001b[1m----------------------------------------\u001b[0m\n",
            "\u001b[1mШаг шестой:\u001b[0m\n",
            "Длина полученного датафрейма, ключ - договор + приложение + стоимость материала: 510\n",
            "Кол-во использованных индексов: 47\n",
            "Кол-во найденных сч.ф.: 51\n",
            "Кол-во строк, которые осталось найти: 369\n",
            "Кол-во найденных строк накопительным итогом: 1321\n",
            "% нахождения накопительным итогом: 78.17\n",
            "\u001b[1m----------------------------------------\u001b[0m\n",
            "\u001b[1mИТОГО:\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# соединяем реестры\n",
        "df_res = dfs_merge(fca, fca_clean, sap_519_exp)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# переименовываем столбцы\n",
        "df_res = df_res.rename(columns={'ЮрНомер договора на поставку':'Договор', '№ приложения к договору':'Номер приложения'})"
      ],
      "metadata": {
        "id": "LQwsI7yEq8g1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_yawGLwhbFD"
      },
      "source": [
        "# Преобразование полученных данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QIjcjGjhsHR"
      },
      "outputs": [],
      "source": [
        "# маркер Y\n",
        "\n",
        "# это метка для случая, когда M одинаковых ключей и N сч.ф.\n",
        "# т.е. проблема, что нельзя установить точное соответствие между сч.ф. и ключом\n",
        "# в идеале такое должно быть только на итерациях 4 и 5 - по номеру ТС и дате отправки\n",
        "df_res['Маркер Y'] = np.where((df_res['Маркер Y'] == 1) | (df_res['Маркер Y'].isna()), 'N', 'Y')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8NHDOE8p0WW"
      },
      "outputs": [],
      "source": [
        "# маркер X\n",
        "\n",
        "# это проверка того, найдены ли все сч.ф. или нет\n",
        "df_res['Маркер X'] = df_res['Номер документа (сч.ф)'].apply(analyze_list)\n",
        "\n",
        "# корректируем маркер Y - не будем помечать им строки без сч.ф.\n",
        "df_res.loc[df_res['Маркер X'] == 'Не найдено ни одной сч.ф.', 'Маркер Y'] = 'N'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# функция возвращения фигурных скобок\n",
        "def curly_brace(id):\n",
        "  return '{' + str(id) + '}'\n",
        "\n",
        "# возвращаем фигурные скобки\n",
        "df_res['Код'] = df_res['Код'].apply(curly_brace)"
      ],
      "metadata": {
        "id": "jmVtmvpL2NPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# добавляем дополнительный уникальный идентификатор\n",
        "df_res.insert(loc=2, column='Дополнительный id', value=(df_res['Код'] + '_' + df_res['Договор'] + '_' + df_res['Номер приложения']))"
      ],
      "metadata": {
        "id": "S-rfhFYC4Xy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# удаляем промежуточный столбец \"Маркер Х\"\n",
        "df_res = df_res.drop('Маркер X', axis=1)"
      ],
      "metadata": {
        "id": "Vl1hJ0dx0wAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLtTl8Ju5jFi"
      },
      "source": [
        "**Сохранение результатов**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4C0hGnp5mGC"
      },
      "outputs": [],
      "source": [
        "datasets = [df_res]\n",
        "sheet_names = ['FCA']\n",
        "excel_filename = 'Модель данных.xlsx'\n",
        "\n",
        "with pd.ExcelWriter(excel_filename) as writer:\n",
        "  for data, sheet in zip(datasets, sheet_names):\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_excel(writer, sheet_name=sheet, header=True, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOn9iXycvpRRsc67FWT4uyE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}